{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from APES import *\n",
    "from time import time\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ticks_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=15, weight='normal', stretch='normal')\n",
    "legend_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=12, weight='normal', stretch='normal')\n",
    "hfont =  {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "csfont = {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "def calculate(val,index):\n",
    "    mean = np.mean(val[:,index,:],axis=0)\n",
    "    std = np.std(val[:,index,:],axis=0)\n",
    "    return mean,std/np.sqrt(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_Reward_Function(agents,foods,rwrdschem,world,AES,Terminated):\n",
    "    \"\"\"Calculate All agents rewards\n",
    "    Args:\n",
    "        * agents: dictionary of agents contain all agents by ID\n",
    "        * foods: dictionary of all foods\n",
    "        * rwrdschem: Reward Schema (More info in World __init__)\n",
    "        * world: World Map\n",
    "        * AES: one element array\n",
    "    TODO:\n",
    "        * copy this function to class or __init__ documentation as example of how to build customer reward function\n",
    "        * Assign Reward To Agents\n",
    "        * Impelent the Food Reward Part depending on the decision of who take the food reward if two \n",
    "          agent exist in food range in same time\n",
    "        * Change All Ranges to .ControlRange not (-1) it's -1 only for testing purpuse\n",
    "        * Change Punish per step to not punish when agent do nothing\"\"\"\n",
    "    # Check Agents in Foods Range\n",
    "    def ResetagentReward(ID):\n",
    "        #Punish for step \n",
    "        agents[ID].CurrentReward= rwrdschem[2] # -1 # rwrdschem[2] if len(agents[ID].NextAction)>0 else 0\n",
    "    for x in agents:\n",
    "        ResetagentReward(x)\n",
    "\n",
    "    AvailableFoods = world[(world>2000)&(world<=3000)]\n",
    "    if len(AvailableFoods)==0:\n",
    "        AES[0]-=1\n",
    "        Terminated[0]= True if AES[0]<=0 else Terminated[0]\n",
    "    for ID in agents.keys():\n",
    "        if agents[ID].IAteFoodID >-1:\n",
    "            agents[ID].CurrentReward+= foods[agents[ID].IAteFoodID].Energy* rwrdschem[1]\n",
    "        agntcenter = World._GetElementCoords(ID,agents[ID].FullEgoCentric)\n",
    "        aborder = World._GetVisionBorders(agntcenter,agents[ID].ControlRange,agents[ID].FullEgoCentric.shape)\n",
    "\n",
    "def SetupEnvironment(Ego=False):\n",
    "    Start = time()\n",
    "    #Add Pictures\n",
    "    Settings.SetBlockSize(20)\n",
    "    Settings.AddImage('Wall','APES/Pics/wall.jpg')\n",
    "    Settings.AddImage('Food','APES/Pics/food.jpg')\n",
    "    #Specify World Size\n",
    "    Settings.WorldSize=(11,11)\n",
    "    #Create Probabilities\n",
    "    obs = np.zeros(Settings.WorldSize)\n",
    "    red_Ag_PM = np.zeros(Settings.WorldSize)\n",
    "    blue_Ag_PM = np.zeros(Settings.WorldSize)\n",
    "    food_PM = np.zeros(Settings.WorldSize)\n",
    "    obs[3:8,5] = 1 \n",
    "    blue_Ag_PM[:,0] =1\n",
    "    red_Ag_PM[3:8,3:8]=1\n",
    "    food_PM[3:8,3:8] = 1\n",
    "    #Add Probabilities to Settings\n",
    "    Settings.AddProbabilityDistribution('Obs',obs)\n",
    "    Settings.AddProbabilityDistribution('red_Ag_PM',red_Ag_PM)\n",
    "    Settings.AddProbabilityDistribution('blue_Ag_PM',blue_Ag_PM)\n",
    "    Settings.AddProbabilityDistribution('food_PM',food_PM)\n",
    "    #Create World Elements\n",
    "    obs = Obstacles('Wall',Shape=np.array([[1],[1],[1],[1]]),PdstName='Obs')\n",
    "    food = Foods('Food',PdstName='food_PM')\n",
    "\n",
    "    blue_Ag = Agent(Fname='APES/Pics/blue.jpg',\n",
    "                    Power=3,\n",
    "                    VisionAngle=180,Range=-1,\n",
    "                    PdstName='blue_Ag_PM',\n",
    "                    ActionMemory=0,\n",
    "                   EgoCentric=Ego)\n",
    "    red_Ag = Agent(Fname='APES/Pics/red.jpg',\n",
    "                   VisionAngle=180,Range=-1,\n",
    "                   Power=10,\n",
    "                   ControlRange=1,\n",
    "                   PdstName='red_Ag_PM')\n",
    "    print(blue_Ag.ID,red_Ag.ID)\n",
    "    game=World(RewardsScheme=[0,1000,-0.1],StepsLimit=100,RewardFunction=New_Reward_Function)\n",
    "    #Agents added first has priority of executing there actions first.\n",
    "    #game.AddAgents([ragnt])\n",
    "    game.AddAgents([red_Ag,blue_Ag])\n",
    "    #game.AddObstacles([obs])\n",
    "    game.AddFoods([food])\n",
    "    Start = time()-Start\n",
    "    print ('Taken:',Start)\n",
    "    return game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 1002\n",
      "Taken: 0.6422829627990723\n"
     ]
    }
   ],
   "source": [
    "Ego = True\n",
    "game = SetupEnvironment(Ego)\n",
    "\n",
    "AIAgent = game.agents[1001]\n",
    "DAgent = game.agents[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 21, 5) 5 (4,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "input size :\n",
    "Worldsize*(Agents Count+3)+Agents Count *4\n",
    "worldsize*(Agents count +3(food,observed,obstacles)) + Agents count *4 (orintation per agent)\n",
    "'''\n",
    "game.GenerateWorld()\n",
    "game.Step()\n",
    "if Ego:\n",
    "    conv_size=(Settings.WorldSize[0]*2-1,Settings.WorldSize[1]*2-1,5,)\n",
    "    rest_size=(0*5+4,)\n",
    "else:\n",
    "    conv_size=(Settings.WorldSize[0],Settings.WorldSize[1],5,)\n",
    "    rest_size=(0*5+8,)\n",
    "naction =  Settings.PossibleActions.shape[0]\n",
    "\n",
    "print(conv_size,naction,rest_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 21, 21, 5) (200000, 4) (200000,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 200000\n",
    "cnn_input= np.zeros((num_samples,conv_size[0],conv_size[1],conv_size[2]))\n",
    "rest_input = np.zeros((num_samples,rest_size[0]))\n",
    "y = np.zeros(num_samples)\n",
    "print(cnn_input.shape,rest_input.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_samples):\n",
    "    if (i%1000)==0:\n",
    "        print(i)\n",
    "    game.GenerateWorld()\n",
    "    AIAgent.Direction='E'\n",
    "    game.Step()\n",
    "    cnn_input[i],rest_input[i]= AIAgent.Convlutional_output()\n",
    "    \n",
    "    ## Watch output \n",
    "    I_C_DOM = game.agents[1001].NNFeed['agentpos1002'].sum() #I see Dominante \n",
    "    I_C_FOOD = game.agents[1001].NNFeed['food'].sum() # I See Food\n",
    "    DOM_C_FOOD=game.agents[1002].NNFeed['food'].sum() # Dominant See Food.\n",
    "    ## VIP: True should avoid, False should eat\n",
    "    y[i] = I_C_DOM and I_C_FOOD and DOM_C_FOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('ego:{}_simulation_{}_E'.format(Ego,num_samples),cnn_input=cnn_input,rest_input=rest_input,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = np.load('ego:False_simulation_200000_E.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = aaa['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 83655, 116345])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(np.array(aaa,dtype=np.int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocentric decision test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data unique Allocentric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 21, 5) 5 (4,)\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "(26389, 21, 21, 5) (26389, 4) (26389, 1)\n"
     ]
    }
   ],
   "source": [
    "Ego = True\n",
    "if Ego:\n",
    "    conv_size=(Settings.WorldSize[0]*2-1,Settings.WorldSize[1]*2-1,5,)\n",
    "    rest_size=(0*5+4,)\n",
    "else:\n",
    "    conv_size=(Settings.WorldSize[0],Settings.WorldSize[1],5,)\n",
    "    rest_size=(0*5+8,)\n",
    "naction =  Settings.PossibleActions.shape[0]\n",
    "\n",
    "print(conv_size,naction,rest_size)\n",
    "all_simu = np.load('ego:{}_simulation_200000_E.npz'.format(Ego))\n",
    "\n",
    "cnn_input= all_simu['cnn_input']\n",
    "rest_input = all_simu['rest_input']\n",
    "y = all_simu['y']\n",
    "\n",
    "cnn_flatten = cnn_input.reshape((cnn_input.shape[0],-1))\n",
    "\n",
    "y = y.reshape(y.shape[0],1)\n",
    "\n",
    "all_input = np.concatenate([cnn_flatten,rest_input,y],axis=1)\n",
    "\n",
    "all_data ={}\n",
    "\n",
    "i=0\n",
    "for row in all_input:\n",
    "    i+=1\n",
    "    if (i%10000)==0:\n",
    "        print(i)\n",
    "    key = tuple(row)\n",
    "    all_data[key] = all_data.get(key,0)+1\n",
    "    \n",
    "data = np.array(list(all_data.keys()))\n",
    "\n",
    "if Ego:\n",
    "    data = np.array(list(all_data.keys()))\n",
    "    cnn_input = data[:,:2205]\n",
    "    rest_input = data[:,2205:2209]\n",
    "    y = data[:,2209]\n",
    "    cnn_input = cnn_input.reshape((data.shape[0],21,21,5))\n",
    "    rest_input = rest_input.reshape((data.shape[0],4))\n",
    "else:\n",
    "    cnn_input = data[:,:605]\n",
    "    rest_input = data[:,605:613]\n",
    "    y = data[:,613]\n",
    "    cnn_input = cnn_input.reshape((data.shape[0],11,11,5))\n",
    "    rest_input = rest_input.reshape((data.shape[0],8))\n",
    "    \n",
    "y = y.reshape((data.shape[0],1))\n",
    "\n",
    "print(cnn_input.shape,rest_input.shape,y.shape)\n",
    "num_samples=data.shape[0]\n",
    "np.savez('ego:{}_simulation_{}_unique_E'.format(Ego,num_samples),cnn_input=cnn_input,rest_input=rest_input,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,convolutional,Flatten,merge,Dense\n",
    "from keras.models import load_model,Model\n",
    "from APES import *\n",
    "from time import time\n",
    "\n",
    "def createLayers(insize,in_conv,naction):\n",
    "    c = Input(shape=in_conv)\n",
    "    con_process = c\n",
    "    con_process = convolutional.Conv2D(filters=6,kernel_size=(3,3),activation=\"relu\",padding=\"same\",strides=1)(con_process)\n",
    "    con_process = Flatten()(con_process)\n",
    "    x = Input(shape=insize)#env.observation_space.shape)\n",
    "    h = merge([con_process,x],mode=\"concat\")\n",
    "    h = Dense(32, activation='tanh')(h)\n",
    "    h = Dense(32, activation='tanh')(h)\n",
    "    z = Dense(1, activation='sigmoid')(h)\n",
    "    return c,x, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Allocentric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 5) 5 (8,)\n"
     ]
    }
   ],
   "source": [
    "Ego = False\n",
    "if Ego:\n",
    "    conv_size=(Settings.WorldSize[0]*2-1,Settings.WorldSize[1]*2-1,5,)\n",
    "    rest_size=(0*5+4,)\n",
    "else:\n",
    "    conv_size=(Settings.WorldSize[0],Settings.WorldSize[1],5,)\n",
    "    rest_size=(0*5+8,)\n",
    "naction =  Settings.PossibleActions.shape[0]\n",
    "\n",
    "print(conv_size,naction,rest_size)\n",
    "all_simu = np.load('ego:{}_simulation_26388_unique_E.npz'.format(Ego))\n",
    "cnn_input= all_simu['cnn_input']\n",
    "rest_input = all_simu['rest_input']\n",
    "y = all_simu['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/labash/miniconda3/envs/PT/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/gpfs/hpchome/labash/miniconda3/envs/PT/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 11, 11, 6)    276         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 726)          0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 734)          0           flatten_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           23520       merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1056        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            33          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 154us/step - loss: 0.6827 - acc: 0.5781 - val_loss: 0.6790 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 4s 174us/step - loss: 0.6627 - acc: 0.5976 - val_loss: 0.5714 - val_acc: 0.7149\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.3566 - acc: 0.8814 - val_loss: 0.1765 - val_acc: 0.9765\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0969 - acc: 0.9970 - val_loss: 0.0499 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 190us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 9.3294e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 7.8854e-04 - acc: 1.0000 - val_loss: 7.2447e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 6.1721e-04 - acc: 1.0000 - val_loss: 5.5513e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 4.8789e-04 - acc: 1.0000 - val_loss: 4.4608e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 190us/step - loss: 3.8960e-04 - acc: 1.0000 - val_loss: 3.5750e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 3.1315e-04 - acc: 1.0000 - val_loss: 2.9263e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 2.5380e-04 - acc: 1.0000 - val_loss: 2.3289e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 3s 163us/step - loss: 2.0681e-04 - acc: 1.0000 - val_loss: 1.9036e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 11, 11, 6)    276         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 726)          0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 734)          0           flatten_2[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           23520       merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           1056        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            33          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 147us/step - loss: 0.6823 - acc: 0.5785 - val_loss: 0.6791 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 4s 178us/step - loss: 0.6793 - acc: 0.5829 - val_loss: 0.6748 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 187us/step - loss: 0.5091 - acc: 0.7655 - val_loss: 0.2489 - val_acc: 0.9608\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.1369 - acc: 0.9828 - val_loss: 0.0732 - val_acc: 0.9966\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 184us/step - loss: 0.0462 - acc: 0.9991 - val_loss: 0.0288 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 185us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 176us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 189us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 9.1075e-04 - acc: 1.0000 - val_loss: 9.2475e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 6.9159e-04 - acc: 1.0000 - val_loss: 6.3221e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 5.2748e-04 - acc: 1.0000 - val_loss: 4.8161e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 4.0743e-04 - acc: 1.0000 - val_loss: 3.7384e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 3.1834e-04 - acc: 1.0000 - val_loss: 2.9295e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 2.5089e-04 - acc: 1.0000 - val_loss: 2.3770e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 1.9803e-04 - acc: 1.0000 - val_loss: 1.8535e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 189us/step - loss: 1.5816e-04 - acc: 1.0000 - val_loss: 1.4902e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 11, 11, 6)    276         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 726)          0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 734)          0           flatten_3[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           23520       merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           1056        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            33          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 142us/step - loss: 0.6827 - acc: 0.5806 - val_loss: 0.6788 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 157us/step - loss: 0.6813 - acc: 0.5829 - val_loss: 0.6784 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 170us/step - loss: 0.6804 - acc: 0.5829 - val_loss: 0.6784 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.6022 - acc: 0.6808 - val_loss: 0.3975 - val_acc: 0.8880\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.2133 - acc: 0.9724 - val_loss: 0.0970 - val_acc: 0.9992\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0586 - acc: 0.9997 - val_loss: 0.0355 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 180us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 182us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 169us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 9.4096e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 176us/step - loss: 8.0079e-04 - acc: 1.0000 - val_loss: 7.4734e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 189us/step - loss: 6.3836e-04 - acc: 1.0000 - val_loss: 5.8933e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 5.0852e-04 - acc: 1.0000 - val_loss: 4.7587e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 4.1080e-04 - acc: 1.0000 - val_loss: 3.8054e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 3.3238e-04 - acc: 1.0000 - val_loss: 3.1337e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 11, 11, 6)    276         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 726)          0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_4 (Merge)                 (None, 734)          0           flatten_4[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           23520       merge_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           1056        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            33          dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 133us/step - loss: 0.6824 - acc: 0.5789 - val_loss: 0.6800 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 132us/step - loss: 0.6710 - acc: 0.5914 - val_loss: 0.6007 - val_acc: 0.7378\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 144us/step - loss: 0.4510 - acc: 0.7976 - val_loss: 0.3008 - val_acc: 0.9039\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 3s 166us/step - loss: 0.2050 - acc: 0.9453 - val_loss: 0.1347 - val_acc: 0.9771\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 186us/step - loss: 0.0935 - acc: 0.9874 - val_loss: 0.0632 - val_acc: 0.9956\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0463 - acc: 0.9979 - val_loss: 0.0316 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 187us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 168us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 3s 147us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 9.4674e-04 - acc: 1.0000 - val_loss: 8.5567e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 189us/step - loss: 7.4686e-04 - acc: 1.0000 - val_loss: 6.6823e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 5.9753e-04 - acc: 1.0000 - val_loss: 5.4511e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 185us/step - loss: 4.8154e-04 - acc: 1.0000 - val_loss: 4.3142e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 3.8837e-04 - acc: 1.0000 - val_loss: 3.5355e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 11, 11, 6)    276         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 726)          0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_5 (Merge)                 (None, 734)          0           flatten_5[0][0]                  \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           23520       merge_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 32)           1056        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            33          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 144us/step - loss: 0.6806 - acc: 0.5825 - val_loss: 0.6791 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 138us/step - loss: 0.5156 - acc: 0.7606 - val_loss: 0.2640 - val_acc: 0.9396\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 151us/step - loss: 0.1575 - acc: 0.9722 - val_loss: 0.0875 - val_acc: 0.9943\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 185us/step - loss: 0.0593 - acc: 0.9981 - val_loss: 0.0387 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 188us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 8.7244e-04 - acc: 1.0000 - val_loss: 7.8699e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 6.6252e-04 - acc: 1.0000 - val_loss: 6.0280e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 5.0633e-04 - acc: 1.0000 - val_loss: 4.6421e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 3.9399e-04 - acc: 1.0000 - val_loss: 3.6319e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 3.1247e-04 - acc: 1.0000 - val_loss: 2.9939e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 2.4630e-04 - acc: 1.0000 - val_loss: 2.2980e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 1.9701e-04 - acc: 1.0000 - val_loss: 1.8753e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 1.5813e-04 - acc: 1.0000 - val_loss: 1.5053e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 11, 11, 6)    276         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 726)          0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_6 (Merge)                 (None, 734)          0           flatten_6[0][0]                  \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 32)           23520       merge_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 32)           1056        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            33          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 4s 170us/step - loss: 0.6811 - acc: 0.5823 - val_loss: 0.6788 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 4s 167us/step - loss: 0.6783 - acc: 0.5829 - val_loss: 0.6732 - val_acc: 0.5851\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.5469 - acc: 0.7262 - val_loss: 0.3780 - val_acc: 0.8223\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.2134 - acc: 0.9472 - val_loss: 0.1186 - val_acc: 0.9869\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.0839 - acc: 0.9923 - val_loss: 0.0533 - val_acc: 0.9996\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0387 - acc: 0.9994 - val_loss: 0.0298 - val_acc: 0.9998\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 168us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 183us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 9.5699e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 7.9909e-04 - acc: 1.0000 - val_loss: 7.3509e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 170us/step - loss: 6.1028e-04 - acc: 1.0000 - val_loss: 5.4815e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 4.7186e-04 - acc: 1.0000 - val_loss: 4.5325e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 3.6573e-04 - acc: 1.0000 - val_loss: 3.4776e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 2.8966e-04 - acc: 1.0000 - val_loss: 2.7062e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 2.2801e-04 - acc: 1.0000 - val_loss: 2.1372e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 6)    276         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 726)          0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_7 (Merge)                 (None, 734)          0           flatten_7[0][0]                  \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 32)           23520       merge_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 32)           1056        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            33          dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 137us/step - loss: 0.6802 - acc: 0.5829 - val_loss: 0.6790 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 132us/step - loss: 0.6790 - acc: 0.5829 - val_loss: 0.6768 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 150us/step - loss: 0.6762 - acc: 0.5829 - val_loss: 0.6730 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 171us/step - loss: 0.6738 - acc: 0.5827 - val_loss: 0.6705 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.6734 - acc: 0.5804 - val_loss: 0.6692 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.6726 - acc: 0.5829 - val_loss: 0.6688 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.6722 - acc: 0.5821 - val_loss: 0.6682 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.6722 - acc: 0.5821 - val_loss: 0.6710 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.6717 - acc: 0.5833 - val_loss: 0.6687 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.6716 - acc: 0.5823 - val_loss: 0.6679 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 189us/step - loss: 0.6715 - acc: 0.5825 - val_loss: 0.6675 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.6714 - acc: 0.5822 - val_loss: 0.6702 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.6714 - acc: 0.5827 - val_loss: 0.6676 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.6713 - acc: 0.5820 - val_loss: 0.6673 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.6707 - acc: 0.5859 - val_loss: 0.6670 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.6708 - acc: 0.5848 - val_loss: 0.6678 - val_acc: 0.5650\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.6707 - acc: 0.5830 - val_loss: 0.6671 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.6706 - acc: 0.5842 - val_loss: 0.6693 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 183us/step - loss: 0.6703 - acc: 0.5825 - val_loss: 0.6665 - val_acc: 0.5847\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.6706 - acc: 0.5845 - val_loss: 0.6668 - val_acc: 0.5853\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 11, 11, 6)    276         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 726)          0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_8 (Merge)                 (None, 734)          0           flatten_8[0][0]                  \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           23520       merge_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           1056        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            33          dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 141us/step - loss: 0.6816 - acc: 0.5818 - val_loss: 0.6800 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 2s 118us/step - loss: 0.6801 - acc: 0.5829 - val_loss: 0.6787 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 145us/step - loss: 0.6798 - acc: 0.5829 - val_loss: 0.6793 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 183us/step - loss: 0.6739 - acc: 0.5859 - val_loss: 0.6338 - val_acc: 0.6652\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.3968 - acc: 0.8449 - val_loss: 0.2088 - val_acc: 0.9445\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.1287 - acc: 0.9817 - val_loss: 0.0865 - val_acc: 0.9901\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0616 - acc: 0.9958 - val_loss: 0.0435 - val_acc: 0.9977\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0334 - acc: 0.9990 - val_loss: 0.0279 - val_acc: 0.9992\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 166us/step - loss: 0.0193 - acc: 0.9999 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 3s 164us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 8.5439e-04 - acc: 1.0000 - val_loss: 7.8238e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 6.5516e-04 - acc: 1.0000 - val_loss: 6.3677e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 5.0298e-04 - acc: 1.0000 - val_loss: 5.3504e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 3.8025e-04 - acc: 1.0000 - val_loss: 3.5408e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 11, 11, 6)    276         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 726)          0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_9 (Merge)                 (None, 734)          0           flatten_9[0][0]                  \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 32)           23520       merge_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 32)           1056        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            33          dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 151us/step - loss: 0.6801 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 150us/step - loss: 0.6794 - acc: 0.5829 - val_loss: 0.6775 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 161us/step - loss: 0.6769 - acc: 0.5829 - val_loss: 0.6733 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 180us/step - loss: 0.6716 - acc: 0.5831 - val_loss: 0.6676 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.6672 - acc: 0.5789 - val_loss: 0.6647 - val_acc: 0.5428\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.6650 - acc: 0.5798 - val_loss: 0.6637 - val_acc: 0.5800\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.6641 - acc: 0.5831 - val_loss: 0.6633 - val_acc: 0.5885\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.6633 - acc: 0.5783 - val_loss: 0.6627 - val_acc: 0.5851\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.6635 - acc: 0.5781 - val_loss: 0.6701 - val_acc: 0.5377\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.6631 - acc: 0.5833 - val_loss: 0.6642 - val_acc: 0.5671\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.6626 - acc: 0.5806 - val_loss: 0.6624 - val_acc: 0.5680\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 3s 165us/step - loss: 0.6624 - acc: 0.5833 - val_loss: 0.6612 - val_acc: 0.5881\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 182us/step - loss: 0.6280 - acc: 0.6420 - val_loss: 0.5364 - val_acc: 0.7558\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.4380 - acc: 0.8017 - val_loss: 0.3256 - val_acc: 0.8931\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 0.2115 - acc: 0.9390 - val_loss: 0.1432 - val_acc: 0.9627\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 187us/step - loss: 0.1049 - acc: 0.9781 - val_loss: 0.0791 - val_acc: 0.9867\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 174us/step - loss: 0.0628 - acc: 0.9908 - val_loss: 0.0496 - val_acc: 0.9941\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0409 - acc: 0.9964 - val_loss: 0.0327 - val_acc: 0.9981\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0272 - acc: 0.9987 - val_loss: 0.0244 - val_acc: 0.9979\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0194 - acc: 0.9995 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 11, 11, 6)    276         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 726)          0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_10 (Merge)                (None, 734)          0           flatten_10[0][0]                 \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 32)           23520       merge_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 32)           1056        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1)            33          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 154us/step - loss: 0.6818 - acc: 0.5804 - val_loss: 0.6854 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 154us/step - loss: 0.6823 - acc: 0.5829 - val_loss: 0.6818 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 167us/step - loss: 0.6803 - acc: 0.5829 - val_loss: 0.6790 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 0.6692 - acc: 0.5971 - val_loss: 0.5846 - val_acc: 0.7637\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.3756 - acc: 0.8691 - val_loss: 0.1846 - val_acc: 0.9843\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 188us/step - loss: 0.1163 - acc: 0.9928 - val_loss: 0.0657 - val_acc: 0.9985\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0470 - acc: 0.9996 - val_loss: 0.0308 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 3s 141us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 3s 154us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 175us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 9.1860e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 7.7628e-04 - acc: 1.0000 - val_loss: 6.9904e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 6.1797e-04 - acc: 1.0000 - val_loss: 5.4285e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 4.8557e-04 - acc: 1.0000 - val_loss: 4.3369e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 183us/step - loss: 3.8412e-04 - acc: 1.0000 - val_loss: 3.5475e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 11, 11, 6)    276         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 726)          0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_11 (Merge)                (None, 734)          0           flatten_11[0][0]                 \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 32)           23520       merge_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 32)           1056        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1)            33          dense_32[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 151us/step - loss: 0.6819 - acc: 0.5829 - val_loss: 0.6798 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 138us/step - loss: 0.6801 - acc: 0.5829 - val_loss: 0.6783 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 144us/step - loss: 0.6724 - acc: 0.5925 - val_loss: 0.6076 - val_acc: 0.7137\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 3s 151us/step - loss: 0.4114 - acc: 0.8351 - val_loss: 0.2256 - val_acc: 0.9598\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 180us/step - loss: 0.1351 - acc: 0.9853 - val_loss: 0.0764 - val_acc: 0.9998\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0528 - acc: 0.9984 - val_loss: 0.0337 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 176us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 9.9995e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 8.7202e-04 - acc: 1.0000 - val_loss: 7.9538e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 6.9611e-04 - acc: 1.0000 - val_loss: 6.1893e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 5.4920e-04 - acc: 1.0000 - val_loss: 5.0771e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 4.4345e-04 - acc: 1.0000 - val_loss: 4.1021e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 3.5413e-04 - acc: 1.0000 - val_loss: 3.2549e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 11, 11, 6)    276         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 726)          0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_12 (Merge)                (None, 734)          0           flatten_12[0][0]                 \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 32)           23520       merge_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 32)           1056        dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1)            33          dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 158us/step - loss: 0.6810 - acc: 0.5821 - val_loss: 0.6797 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 120us/step - loss: 0.6563 - acc: 0.6044 - val_loss: 0.5357 - val_acc: 0.7713\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 126us/step - loss: 0.3042 - acc: 0.9126 - val_loss: 0.1456 - val_acc: 0.9767\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 3s 137us/step - loss: 0.0899 - acc: 0.9929 - val_loss: 0.0507 - val_acc: 0.9996\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 168us/step - loss: 0.0354 - acc: 0.9999 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 3s 162us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 9.1291e-04 - acc: 1.0000 - val_loss: 8.3236e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 6.6830e-04 - acc: 1.0000 - val_loss: 5.8311e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 3s 161us/step - loss: 4.9667e-04 - acc: 1.0000 - val_loss: 4.5122e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 3.7510e-04 - acc: 1.0000 - val_loss: 3.4231e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 2.8869e-04 - acc: 1.0000 - val_loss: 2.6015e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 2.2318e-04 - acc: 1.0000 - val_loss: 2.1191e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 1.7408e-04 - acc: 1.0000 - val_loss: 1.6005e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 178us/step - loss: 1.3794e-04 - acc: 1.0000 - val_loss: 1.2740e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 1.0953e-04 - acc: 1.0000 - val_loss: 1.0121e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 11, 11, 6)    276         input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 726)          0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_13 (Merge)                (None, 734)          0           flatten_13[0][0]                 \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 32)           23520       merge_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 32)           1056        dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 1)            33          dense_38[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 147us/step - loss: 0.6834 - acc: 0.5784 - val_loss: 0.6782 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 124us/step - loss: 0.6780 - acc: 0.5832 - val_loss: 0.6706 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 136us/step - loss: 0.4829 - acc: 0.7819 - val_loss: 0.2545 - val_acc: 0.9339\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 3s 147us/step - loss: 0.1600 - acc: 0.9722 - val_loss: 0.0951 - val_acc: 0.9920\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 3s 159us/step - loss: 0.0655 - acc: 0.9973 - val_loss: 0.0437 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 168us/step - loss: 0.0311 - acc: 0.9999 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 175us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 186us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 187us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 9.8270e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 8.0282e-04 - acc: 1.0000 - val_loss: 7.5931e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 6.3606e-04 - acc: 1.0000 - val_loss: 5.9849e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 5.1032e-04 - acc: 1.0000 - val_loss: 4.8824e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 4.1089e-04 - acc: 1.0000 - val_loss: 3.9034e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 3.3109e-04 - acc: 1.0000 - val_loss: 3.1400e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 6)    276         input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 726)          0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_14 (Merge)                (None, 734)          0           flatten_14[0][0]                 \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 32)           23520       merge_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 32)           1056        dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1)            33          dense_41[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 160us/step - loss: 0.6828 - acc: 0.5804 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 131us/step - loss: 0.6801 - acc: 0.5829 - val_loss: 0.6788 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 170us/step - loss: 0.6796 - acc: 0.5829 - val_loss: 0.6789 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 186us/step - loss: 0.6749 - acc: 0.5889 - val_loss: 0.6333 - val_acc: 0.7116\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 181us/step - loss: 0.5182 - acc: 0.7561 - val_loss: 0.3981 - val_acc: 0.8541\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 167us/step - loss: 0.2209 - acc: 0.9459 - val_loss: 0.1220 - val_acc: 0.9812\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 3s 161us/step - loss: 0.0796 - acc: 0.9937 - val_loss: 0.0523 - val_acc: 0.9973\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 190us/step - loss: 0.0376 - acc: 0.9994 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 178us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 190us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 188us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 9.4821e-04 - acc: 1.0000 - val_loss: 9.0013e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 7.5486e-04 - acc: 1.0000 - val_loss: 6.9329e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 5.9452e-04 - acc: 1.0000 - val_loss: 5.4996e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 11, 11, 6)    276         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 726)          0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_15 (Merge)                (None, 734)          0           flatten_15[0][0]                 \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 32)           23520       merge_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 32)           1056        dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1)            33          dense_44[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 145us/step - loss: 0.6822 - acc: 0.5809 - val_loss: 0.6784 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 2s 115us/step - loss: 0.6794 - acc: 0.5829 - val_loss: 0.6779 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 2s 118us/step - loss: 0.6778 - acc: 0.5829 - val_loss: 0.6771 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 3s 125us/step - loss: 0.6343 - acc: 0.6422 - val_loss: 0.5526 - val_acc: 0.7186\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 3s 139us/step - loss: 0.4839 - acc: 0.7618 - val_loss: 0.4009 - val_acc: 0.8121\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 3s 151us/step - loss: 0.2622 - acc: 0.9291 - val_loss: 0.1388 - val_acc: 0.9886\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 169us/step - loss: 0.0832 - acc: 0.9951 - val_loss: 0.0471 - val_acc: 0.9994\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 186us/step - loss: 0.0319 - acc: 0.9998 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 9.8183e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 8.2778e-04 - acc: 1.0000 - val_loss: 7.3354e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 3s 142us/step - loss: 6.3142e-04 - acc: 1.0000 - val_loss: 5.5160e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 3s 148us/step - loss: 4.7702e-04 - acc: 1.0000 - val_loss: 4.3772e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 3.6686e-04 - acc: 1.0000 - val_loss: 3.2781e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 2.8507e-04 - acc: 1.0000 - val_loss: 2.5692e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 6)    276         input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 726)          0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_16 (Merge)                (None, 734)          0           flatten_16[0][0]                 \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 32)           23520       merge_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 32)           1056        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 1)            33          dense_47[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 162us/step - loss: 0.6828 - acc: 0.5769 - val_loss: 0.6785 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 155us/step - loss: 0.6424 - acc: 0.6411 - val_loss: 0.5595 - val_acc: 0.7683\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 186us/step - loss: 0.3902 - acc: 0.8611 - val_loss: 0.1940 - val_acc: 0.9680\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 3s 165us/step - loss: 0.1061 - acc: 0.9940 - val_loss: 0.0572 - val_acc: 0.9998\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0369 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 8.9072e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 7.5351e-04 - acc: 1.0000 - val_loss: 6.7961e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 5.6840e-04 - acc: 1.0000 - val_loss: 5.0698e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 4.3717e-04 - acc: 1.0000 - val_loss: 4.0352e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 3.3788e-04 - acc: 1.0000 - val_loss: 3.1153e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 2.6389e-04 - acc: 1.0000 - val_loss: 2.4034e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 2.0794e-04 - acc: 1.0000 - val_loss: 1.9270e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 1.6473e-04 - acc: 1.0000 - val_loss: 1.5388e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 1.3173e-04 - acc: 1.0000 - val_loss: 1.2388e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 6)    276         input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 726)          0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_17 (Merge)                (None, 734)          0           flatten_17[0][0]                 \n",
      "                                                                 input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 32)           23520       merge_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 32)           1056        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1)            33          dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 148us/step - loss: 0.6801 - acc: 0.5824 - val_loss: 0.6753 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 2s 108us/step - loss: 0.6080 - acc: 0.6655 - val_loss: 0.4999 - val_acc: 0.7573\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 2s 114us/step - loss: 0.4325 - acc: 0.7993 - val_loss: 0.2863 - val_acc: 0.9337\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 3s 131us/step - loss: 0.1822 - acc: 0.9600 - val_loss: 0.1144 - val_acc: 0.9782\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 3s 146us/step - loss: 0.0821 - acc: 0.9912 - val_loss: 0.0574 - val_acc: 0.9966\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 192us/step - loss: 0.0440 - acc: 0.9963 - val_loss: 0.0322 - val_acc: 0.9985\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0262 - acc: 0.9990 - val_loss: 0.0213 - val_acc: 0.9994\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 3s 157us/step - loss: 0.0172 - acc: 0.9996 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 3s 136us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 179us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 3s 144us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 9.8801e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 8.7334e-04 - acc: 1.0000 - val_loss: 7.9589e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 6.8484e-04 - acc: 1.0000 - val_loss: 6.2922e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 193us/step - loss: 5.4659e-04 - acc: 1.0000 - val_loss: 5.0013e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 191us/step - loss: 4.3475e-04 - acc: 1.0000 - val_loss: 4.0858e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 6)    276         input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 726)          0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_18 (Merge)                (None, 734)          0           flatten_18[0][0]                 \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 32)           23520       merge_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 32)           1056        dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 1)            33          dense_53[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 4s 170us/step - loss: 0.6807 - acc: 0.5819 - val_loss: 0.6785 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 141us/step - loss: 0.6773 - acc: 0.5829 - val_loss: 0.6739 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 175us/step - loss: 0.5032 - acc: 0.7690 - val_loss: 0.2761 - val_acc: 0.9284\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 190us/step - loss: 0.1694 - acc: 0.9693 - val_loss: 0.1129 - val_acc: 0.9847\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0793 - acc: 0.9937 - val_loss: 0.0632 - val_acc: 0.9936\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0431 - acc: 0.9983 - val_loss: 0.0316 - val_acc: 0.9998\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0241 - acc: 0.9997 - val_loss: 0.0211 - val_acc: 0.9991\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 202us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 9.4242e-04 - acc: 1.0000 - val_loss: 8.7341e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 7.3490e-04 - acc: 1.0000 - val_loss: 6.6433e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 171us/step - loss: 5.7100e-04 - acc: 1.0000 - val_loss: 5.1911e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 181us/step - loss: 4.5593e-04 - acc: 1.0000 - val_loss: 4.2618e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 3.6679e-04 - acc: 1.0000 - val_loss: 3.3711e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 6)    276         input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 726)          0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_19 (Merge)                (None, 734)          0           flatten_19[0][0]                 \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 32)           23520       merge_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 32)           1056        dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 1)            33          dense_56[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 4s 175us/step - loss: 0.6880 - acc: 0.5737 - val_loss: 0.6793 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 142us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6796 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 3s 161us/step - loss: 0.6464 - acc: 0.6312 - val_loss: 0.5786 - val_acc: 0.7202\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.4629 - acc: 0.7944 - val_loss: 0.2869 - val_acc: 0.9354\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.1679 - acc: 0.9744 - val_loss: 0.1008 - val_acc: 0.9845\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0624 - acc: 0.9973 - val_loss: 0.0381 - val_acc: 0.9998\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0286 - acc: 0.9998 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 194us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 9.8371e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 7.9818e-04 - acc: 1.0000 - val_loss: 7.3116e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 6.0562e-04 - acc: 1.0000 - val_loss: 6.0066e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 4.6718e-04 - acc: 1.0000 - val_loss: 4.4248e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 3.6118e-04 - acc: 1.0000 - val_loss: 3.4541e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 177us/step - loss: 2.8624e-04 - acc: 1.0000 - val_loss: 2.6783e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 2.2826e-04 - acc: 1.0000 - val_loss: 2.1449e-04 - val_acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           (None, 11, 11, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 6)    276         input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 726)          0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_20 (Merge)                (None, 734)          0           flatten_20[0][0]                 \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 32)           23520       merge_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 32)           1056        dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1)            33          dense_59[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,885\n",
      "Trainable params: 24,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 4s 188us/step - loss: 0.6830 - acc: 0.5812 - val_loss: 0.6786 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 3s 156us/step - loss: 0.6793 - acc: 0.5829 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 4s 185us/step - loss: 0.5087 - acc: 0.7466 - val_loss: 0.3015 - val_acc: 0.9026\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.2029 - acc: 0.9558 - val_loss: 0.1307 - val_acc: 0.9892\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0956 - acc: 0.9929 - val_loss: 0.0683 - val_acc: 0.9945\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 4s 196us/step - loss: 0.0501 - acc: 0.9984 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 3s 147us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 4s 184us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 4s 195us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 4s 197us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 4s 198us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 4s 199us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 8.9961e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 4s 202us/step - loss: 8.2181e-04 - acc: 1.0000 - val_loss: 7.2384e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 4s 201us/step - loss: 6.3399e-04 - acc: 1.0000 - val_loss: 5.6950e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 4s 184us/step - loss: 4.9488e-04 - acc: 1.0000 - val_loss: 4.9436e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 4s 200us/step - loss: 3.9411e-04 - acc: 1.0000 - val_loss: 3.5123e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_exper= 20\n",
    "epochs=20\n",
    "info = np.zeros((num_exper,4,epochs))\n",
    "for i in range(num_exper):\n",
    "    c,x,z = createLayers(rest_size,conv_size,naction)\n",
    "\n",
    "    allo_classifier = Model(inputs=[c,x],outputs=z)\n",
    "\n",
    "    allo_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    allo_classifier.summary()\n",
    "\n",
    "    allo_history = allo_classifier.fit([all_simu['cnn_input'],all_simu['rest_input']],\n",
    "                                       all_simu['y'],epochs=epochs,batch_size=64,validation_split=0.2)\n",
    "    \n",
    "    info[i,0,:] = allo_history.history['val_loss']\n",
    "    info[i,1,:] = allo_history.history['val_acc']\n",
    "    info[i,2,:] = allo_history.history['loss']\n",
    "    info[i,3,:] = allo_history.history['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ego centric decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 21, 5) 5 (4,)\n"
     ]
    }
   ],
   "source": [
    "Ego = True\n",
    "if Ego:\n",
    "    conv_size=(Settings.WorldSize[0]*2-1,Settings.WorldSize[1]*2-1,5,)\n",
    "    rest_size=(0*5+4,)\n",
    "else:\n",
    "    conv_size=(Settings.WorldSize[0],Settings.WorldSize[1],5,)\n",
    "    rest_size=(0*5+8,)\n",
    "naction =  Settings.PossibleActions.shape[0]\n",
    "\n",
    "print(conv_size,naction,rest_size)\n",
    "all_simu = np.load('ego:{}_simulation_40629_unique.npz'.format(Ego))\n",
    "#all_simu = np.load('ego:{}_simulation_200000.npz'.format(Ego))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/labash/miniconda3/envs/PT/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/gpfs/hpchome/labash/miniconda3/envs/PT/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 21, 21, 6)    276         input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 2646)         0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_21 (Merge)                (None, 2650)         0           flatten_21[0][0]                 \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 32)           84832       merge_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 32)           1056        dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 1)            33          dense_62[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 12s 359us/step - loss: 0.6822 - acc: 0.5782 - val_loss: 0.6834 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 10s 296us/step - loss: 0.6809 - acc: 0.5788 - val_loss: 0.6827 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.6807 - acc: 0.5789 - val_loss: 0.6815 - val_acc: 0.5751\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 345us/step - loss: 0.6796 - acc: 0.5791 - val_loss: 0.6799 - val_acc: 0.5769\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 11s 347us/step - loss: 0.6748 - acc: 0.5808 - val_loss: 0.6753 - val_acc: 0.5820\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 336us/step - loss: 0.6711 - acc: 0.5832 - val_loss: 0.6757 - val_acc: 0.5710\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 10s 311us/step - loss: 0.6688 - acc: 0.5871 - val_loss: 0.6739 - val_acc: 0.5839\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 10s 322us/step - loss: 0.6674 - acc: 0.5861 - val_loss: 0.6727 - val_acc: 0.5772\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 363us/step - loss: 0.6661 - acc: 0.5883 - val_loss: 0.6740 - val_acc: 0.5786\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.6648 - acc: 0.5856 - val_loss: 0.6733 - val_acc: 0.5679\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 11s 340us/step - loss: 0.6640 - acc: 0.5857 - val_loss: 0.6713 - val_acc: 0.5793\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.6632 - acc: 0.5889 - val_loss: 0.6737 - val_acc: 0.5505\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 373us/step - loss: 0.6626 - acc: 0.5897 - val_loss: 0.6715 - val_acc: 0.5754\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 360us/step - loss: 0.6624 - acc: 0.5890 - val_loss: 0.6717 - val_acc: 0.5823\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 340us/step - loss: 0.6617 - acc: 0.5856 - val_loss: 0.6700 - val_acc: 0.5806\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.6607 - acc: 0.5890 - val_loss: 0.6702 - val_acc: 0.5864\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.6492 - acc: 0.6091 - val_loss: 0.6445 - val_acc: 0.6096\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 366us/step - loss: 0.6177 - acc: 0.6573 - val_loss: 0.6172 - val_acc: 0.6538\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 338us/step - loss: 0.5780 - acc: 0.7006 - val_loss: 0.5592 - val_acc: 0.7184\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 11s 336us/step - loss: 0.5057 - acc: 0.7588 - val_loss: 0.4886 - val_acc: 0.7587\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 21, 21, 6)    276         input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 2646)         0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_22 (Merge)                (None, 2650)         0           flatten_22[0][0]                 \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 32)           84832       merge_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 32)           1056        dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1)            33          dense_65[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 387us/step - loss: 0.6830 - acc: 0.5767 - val_loss: 0.6817 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.6812 - acc: 0.5787 - val_loss: 0.6828 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 335us/step - loss: 0.6624 - acc: 0.6032 - val_loss: 0.5689 - val_acc: 0.7179\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.4153 - acc: 0.8268 - val_loss: 0.2831 - val_acc: 0.8980\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 11s 336us/step - loss: 0.2073 - acc: 0.9349 - val_loss: 0.1474 - val_acc: 0.9601\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 10s 316us/step - loss: 0.1120 - acc: 0.9705 - val_loss: 0.0989 - val_acc: 0.9702\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 11s 342us/step - loss: 0.0649 - acc: 0.9856 - val_loss: 0.0569 - val_acc: 0.9872\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 11s 334us/step - loss: 0.0404 - acc: 0.9923 - val_loss: 0.0421 - val_acc: 0.9892\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 338us/step - loss: 0.0279 - acc: 0.9953 - val_loss: 0.0405 - val_acc: 0.9889\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 335us/step - loss: 0.0213 - acc: 0.9962 - val_loss: 0.0238 - val_acc: 0.9946\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 0.0138 - acc: 0.9982 - val_loss: 0.0195 - val_acc: 0.9956\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.0091 - acc: 0.9990 - val_loss: 0.0179 - val_acc: 0.9957\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 10s 316us/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0145 - val_acc: 0.9975\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 11s 331us/step - loss: 0.0047 - acc: 0.9998 - val_loss: 0.0080 - val_acc: 0.9982\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 323us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0055 - val_acc: 0.9995\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 342us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0308 - val_acc: 0.9895\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 13s 385us/step - loss: 0.0173 - acc: 0.9947 - val_loss: 0.0133 - val_acc: 0.9959\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 11s 352us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.0045 - val_acc: 0.9995\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 343us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9994\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 11s 347us/step - loss: 9.5564e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9995\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_45 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 21, 21, 6)    276         input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 2646)         0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_23 (Merge)                (None, 2650)         0           flatten_23[0][0]                 \n",
      "                                                                 input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 32)           84832       merge_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 32)           1056        dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 1)            33          dense_68[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 392us/step - loss: 0.6820 - acc: 0.5772 - val_loss: 0.6843 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 356us/step - loss: 0.6803 - acc: 0.5787 - val_loss: 0.6807 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 343us/step - loss: 0.6725 - acc: 0.5777 - val_loss: 0.6732 - val_acc: 0.5756\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 327us/step - loss: 0.6666 - acc: 0.5775 - val_loss: 0.6719 - val_acc: 0.5828\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 11s 340us/step - loss: 0.6648 - acc: 0.5787 - val_loss: 0.6718 - val_acc: 0.5692\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 323us/step - loss: 0.6637 - acc: 0.5794 - val_loss: 0.6722 - val_acc: 0.5635\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 360us/step - loss: 0.6634 - acc: 0.5799 - val_loss: 0.6738 - val_acc: 0.5844\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 11s 337us/step - loss: 0.6625 - acc: 0.5815 - val_loss: 0.6723 - val_acc: 0.5653\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 349us/step - loss: 0.6620 - acc: 0.5823 - val_loss: 0.6719 - val_acc: 0.5726\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 334us/step - loss: 0.6615 - acc: 0.5822 - val_loss: 0.6726 - val_acc: 0.5617\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.6580 - acc: 0.5860 - val_loss: 0.6656 - val_acc: 0.5919\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.6061 - acc: 0.6653 - val_loss: 0.5706 - val_acc: 0.7192\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 11s 342us/step - loss: 0.5040 - acc: 0.7751 - val_loss: 0.4552 - val_acc: 0.8129\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 11s 352us/step - loss: 0.3257 - acc: 0.8810 - val_loss: 0.2525 - val_acc: 0.9194\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.1857 - acc: 0.9489 - val_loss: 0.1501 - val_acc: 0.9616\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.1111 - acc: 0.9739 - val_loss: 0.0967 - val_acc: 0.9766\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 11s 331us/step - loss: 0.0715 - acc: 0.9869 - val_loss: 0.0603 - val_acc: 0.9889\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 363us/step - loss: 0.0494 - acc: 0.9906 - val_loss: 0.0426 - val_acc: 0.9929\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.0330 - acc: 0.9946 - val_loss: 0.0317 - val_acc: 0.9935\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 10s 320us/step - loss: 0.0223 - acc: 0.9972 - val_loss: 0.0226 - val_acc: 0.9969\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 21, 21, 6)    276         input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 2646)         0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_24 (Merge)                (None, 2650)         0           flatten_24[0][0]                 \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 32)           84832       merge_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 32)           1056        dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 1)            33          dense_71[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 12s 383us/step - loss: 0.6821 - acc: 0.5783 - val_loss: 0.6824 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 369us/step - loss: 0.6809 - acc: 0.5787 - val_loss: 0.6822 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.6803 - acc: 0.5790 - val_loss: 0.6808 - val_acc: 0.5751\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 365us/step - loss: 0.6745 - acc: 0.5794 - val_loss: 0.6741 - val_acc: 0.5772\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.6670 - acc: 0.5806 - val_loss: 0.6729 - val_acc: 0.5836\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.6635 - acc: 0.5821 - val_loss: 0.6717 - val_acc: 0.5785\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 360us/step - loss: 0.6617 - acc: 0.5832 - val_loss: 0.6730 - val_acc: 0.5727\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.6610 - acc: 0.5837 - val_loss: 0.6717 - val_acc: 0.5682\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.6607 - acc: 0.5854 - val_loss: 0.6726 - val_acc: 0.5790\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.6605 - acc: 0.5814 - val_loss: 0.6759 - val_acc: 0.5746\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 11s 351us/step - loss: 0.6602 - acc: 0.5850 - val_loss: 0.6738 - val_acc: 0.5743\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 343us/step - loss: 0.6600 - acc: 0.5837 - val_loss: 0.6728 - val_acc: 0.5700\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 369us/step - loss: 0.6597 - acc: 0.5851 - val_loss: 0.6721 - val_acc: 0.5788\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 375us/step - loss: 0.6592 - acc: 0.5864 - val_loss: 0.6729 - val_acc: 0.5614\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 324us/step - loss: 0.6571 - acc: 0.5861 - val_loss: 0.6678 - val_acc: 0.5767\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 375us/step - loss: 0.6305 - acc: 0.6292 - val_loss: 0.5980 - val_acc: 0.6821\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 13s 396us/step - loss: 0.5348 - acc: 0.7444 - val_loss: 0.5185 - val_acc: 0.7396\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 13s 392us/step - loss: 0.4750 - acc: 0.7782 - val_loss: 0.4709 - val_acc: 0.7810\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.4135 - acc: 0.8126 - val_loss: 0.3970 - val_acc: 0.8070\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 372us/step - loss: 0.3426 - acc: 0.8384 - val_loss: 0.3220 - val_acc: 0.8464\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_49 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 21, 21, 6)    276         input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 2646)         0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_25 (Merge)                (None, 2650)         0           flatten_25[0][0]                 \n",
      "                                                                 input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 32)           84832       merge_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 32)           1056        dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 1)            33          dense_74[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.6821 - acc: 0.5775 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.6807 - acc: 0.5787 - val_loss: 0.6810 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 343us/step - loss: 0.6766 - acc: 0.5791 - val_loss: 0.6752 - val_acc: 0.5820\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 342us/step - loss: 0.6684 - acc: 0.5819 - val_loss: 0.6777 - val_acc: 0.5383\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 357us/step - loss: 0.6654 - acc: 0.5840 - val_loss: 0.6715 - val_acc: 0.5784\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.6628 - acc: 0.5861 - val_loss: 0.6693 - val_acc: 0.5825\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 11s 328us/step - loss: 0.6611 - acc: 0.5842 - val_loss: 0.6704 - val_acc: 0.5790\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 369us/step - loss: 0.6606 - acc: 0.5826 - val_loss: 0.6712 - val_acc: 0.5743\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.6603 - acc: 0.5811 - val_loss: 0.6745 - val_acc: 0.5880\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 357us/step - loss: 0.6600 - acc: 0.5811 - val_loss: 0.6714 - val_acc: 0.5864\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 0.6591 - acc: 0.5863 - val_loss: 0.6693 - val_acc: 0.5775\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.6585 - acc: 0.5859 - val_loss: 0.6699 - val_acc: 0.5786\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 380us/step - loss: 0.6575 - acc: 0.5845 - val_loss: 0.6677 - val_acc: 0.5818\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.6305 - acc: 0.6356 - val_loss: 0.5706 - val_acc: 0.7171\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 359us/step - loss: 0.5166 - acc: 0.7437 - val_loss: 0.4684 - val_acc: 0.7667\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 345us/step - loss: 0.4056 - acc: 0.8080 - val_loss: 0.3404 - val_acc: 0.8526\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 11s 338us/step - loss: 0.2614 - acc: 0.8963 - val_loss: 0.2097 - val_acc: 0.9239\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 13s 385us/step - loss: 0.1638 - acc: 0.9436 - val_loss: 0.1401 - val_acc: 0.9518\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 363us/step - loss: 0.1213 - acc: 0.9596 - val_loss: 0.1062 - val_acc: 0.9658\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.0976 - acc: 0.9681 - val_loss: 0.0887 - val_acc: 0.9702\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_51 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 21, 21, 6)    276         input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 2646)         0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_26 (Merge)                (None, 2650)         0           flatten_26[0][0]                 \n",
      "                                                                 input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 32)           84832       merge_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 32)           1056        dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 1)            33          dense_77[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 392us/step - loss: 0.6819 - acc: 0.5779 - val_loss: 0.6829 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 10s 295us/step - loss: 0.6772 - acc: 0.5788 - val_loss: 0.6755 - val_acc: 0.5826\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 10s 311us/step - loss: 0.6699 - acc: 0.5806 - val_loss: 0.6732 - val_acc: 0.5788\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 342us/step - loss: 0.6674 - acc: 0.5787 - val_loss: 0.6736 - val_acc: 0.5831\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.6659 - acc: 0.5789 - val_loss: 0.6742 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.6646 - acc: 0.5831 - val_loss: 0.6717 - val_acc: 0.5695\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.6633 - acc: 0.5799 - val_loss: 0.6698 - val_acc: 0.5884\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 11s 330us/step - loss: 0.6620 - acc: 0.5835 - val_loss: 0.6699 - val_acc: 0.5580\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.6611 - acc: 0.5834 - val_loss: 0.6681 - val_acc: 0.5818\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 337us/step - loss: 0.6602 - acc: 0.5849 - val_loss: 0.6672 - val_acc: 0.5844\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 9s 286us/step - loss: 0.6598 - acc: 0.5855 - val_loss: 0.6689 - val_acc: 0.5490\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 328us/step - loss: 0.6592 - acc: 0.5847 - val_loss: 0.6688 - val_acc: 0.5484\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 9s 292us/step - loss: 0.6592 - acc: 0.5832 - val_loss: 0.6673 - val_acc: 0.5731\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 10s 306us/step - loss: 0.6590 - acc: 0.5854 - val_loss: 0.6677 - val_acc: 0.5631\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 336us/step - loss: 0.6586 - acc: 0.5862 - val_loss: 0.6667 - val_acc: 0.5885\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.6584 - acc: 0.5827 - val_loss: 0.6664 - val_acc: 0.5790\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 373us/step - loss: 0.6580 - acc: 0.5857 - val_loss: 0.6716 - val_acc: 0.5815\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.6583 - acc: 0.5839 - val_loss: 0.6700 - val_acc: 0.5393\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 0.6567 - acc: 0.5867 - val_loss: 0.6628 - val_acc: 0.5885\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 365us/step - loss: 0.6358 - acc: 0.6390 - val_loss: 0.6221 - val_acc: 0.6676\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 21, 21, 6)    276         input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 2646)         0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_27 (Merge)                (None, 2650)         0           flatten_27[0][0]                 \n",
      "                                                                 input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 32)           84832       merge_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 32)           1056        dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 1)            33          dense_80[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 12s 377us/step - loss: 0.6829 - acc: 0.5773 - val_loss: 0.6821 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.6808 - acc: 0.5787 - val_loss: 0.6820 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 350us/step - loss: 0.6804 - acc: 0.5787 - val_loss: 0.6810 - val_acc: 0.5749\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.6177 - acc: 0.6479 - val_loss: 0.5003 - val_acc: 0.7519\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 373us/step - loss: 0.3595 - acc: 0.8444 - val_loss: 0.2665 - val_acc: 0.8959\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 356us/step - loss: 0.1823 - acc: 0.9447 - val_loss: 0.1293 - val_acc: 0.9631\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.0905 - acc: 0.9800 - val_loss: 0.0690 - val_acc: 0.9858\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 365us/step - loss: 0.0511 - acc: 0.9912 - val_loss: 0.0409 - val_acc: 0.9936\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.0304 - acc: 0.9957 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 0.0224 - acc: 0.9969 - val_loss: 0.0289 - val_acc: 0.9937\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 0.0152 - acc: 0.9981 - val_loss: 0.0138 - val_acc: 0.9985\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 339us/step - loss: 0.0115 - acc: 0.9983 - val_loss: 0.0134 - val_acc: 0.9978\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 11s 327us/step - loss: 0.0097 - acc: 0.9986 - val_loss: 0.0125 - val_acc: 0.9968\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.0146 - val_acc: 0.9959\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 331us/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0092 - val_acc: 0.9973\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 357us/step - loss: 0.0033 - acc: 0.9998 - val_loss: 0.0042 - val_acc: 0.9995\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 11s 340us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9996\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 11s 349us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9989\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 336us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9998\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0737 - val_acc: 0.9783\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 21, 21, 6)    276         input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 2646)         0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_28 (Merge)                (None, 2650)         0           flatten_28[0][0]                 \n",
      "                                                                 input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 32)           84832       merge_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 32)           1056        dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 1)            33          dense_83[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.6823 - acc: 0.5772 - val_loss: 0.6826 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 345us/step - loss: 0.6812 - acc: 0.5787 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 369us/step - loss: 0.6809 - acc: 0.5787 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.6798 - acc: 0.5788 - val_loss: 0.6795 - val_acc: 0.5751\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 364us/step - loss: 0.6736 - acc: 0.5807 - val_loss: 0.6742 - val_acc: 0.5802\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 352us/step - loss: 0.6678 - acc: 0.5796 - val_loss: 0.6741 - val_acc: 0.5807\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 13s 385us/step - loss: 0.6655 - acc: 0.5797 - val_loss: 0.6716 - val_acc: 0.5809\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.6638 - acc: 0.5791 - val_loss: 0.6715 - val_acc: 0.5614\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 376us/step - loss: 0.6630 - acc: 0.5787 - val_loss: 0.6706 - val_acc: 0.5842\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 331us/step - loss: 0.6621 - acc: 0.5819 - val_loss: 0.6710 - val_acc: 0.5573\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.6617 - acc: 0.5803 - val_loss: 0.6702 - val_acc: 0.5812\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 0.6613 - acc: 0.5819 - val_loss: 0.6709 - val_acc: 0.5812\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.6603 - acc: 0.5836 - val_loss: 0.6741 - val_acc: 0.5357\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 11s 350us/step - loss: 0.6608 - acc: 0.5810 - val_loss: 0.6738 - val_acc: 0.5793\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 13s 395us/step - loss: 0.6600 - acc: 0.5821 - val_loss: 0.6718 - val_acc: 0.5546\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.6599 - acc: 0.5840 - val_loss: 0.6711 - val_acc: 0.5321\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.6597 - acc: 0.5858 - val_loss: 0.6716 - val_acc: 0.5345\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 13s 398us/step - loss: 0.6592 - acc: 0.5847 - val_loss: 0.6723 - val_acc: 0.5721\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.6589 - acc: 0.5848 - val_loss: 0.6714 - val_acc: 0.5761\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 11s 336us/step - loss: 0.6585 - acc: 0.5847 - val_loss: 0.6722 - val_acc: 0.5683\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_57 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 21, 21, 6)    276         input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 2646)         0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_29 (Merge)                (None, 2650)         0           flatten_29[0][0]                 \n",
      "                                                                 input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 32)           84832       merge_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 32)           1056        dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 1)            33          dense_86[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 12s 380us/step - loss: 0.6833 - acc: 0.5761 - val_loss: 0.6829 - val_acc: 0.5752\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 335us/step - loss: 0.6817 - acc: 0.5787 - val_loss: 0.6819 - val_acc: 0.5752\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 356us/step - loss: 0.6811 - acc: 0.5789 - val_loss: 0.6837 - val_acc: 0.5752\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.6808 - acc: 0.5793 - val_loss: 0.6825 - val_acc: 0.5757\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.6808 - acc: 0.5797 - val_loss: 0.6814 - val_acc: 0.5758\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 339us/step - loss: 0.6802 - acc: 0.5805 - val_loss: 0.6855 - val_acc: 0.5689\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.5988 - acc: 0.6670 - val_loss: 0.3864 - val_acc: 0.8490\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.2073 - acc: 0.9403 - val_loss: 0.1129 - val_acc: 0.9767\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.0775 - acc: 0.9874 - val_loss: 0.0533 - val_acc: 0.9910\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 376us/step - loss: 0.0377 - acc: 0.9951 - val_loss: 0.0308 - val_acc: 0.9956\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 377us/step - loss: 0.0204 - acc: 0.9979 - val_loss: 0.0206 - val_acc: 0.9964\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.0117 - acc: 0.9994 - val_loss: 0.0106 - val_acc: 0.9991\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.0065 - acc: 0.9999 - val_loss: 0.0075 - val_acc: 0.9993\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 373us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.0081 - val_acc: 0.9988\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0122 - val_acc: 0.9958\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0037 - val_acc: 0.9995\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9988\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 11s 324us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0027 - val_acc: 0.9995\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 357us/step - loss: 6.3535e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9995\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 11s 348us/step - loss: 4.6319e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9995\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 21, 21, 6)    276         input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 2646)         0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_30 (Merge)                (None, 2650)         0           flatten_30[0][0]                 \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 32)           84832       merge_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 32)           1056        dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 1)            33          dense_89[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 397us/step - loss: 0.6827 - acc: 0.5755 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 365us/step - loss: 0.6807 - acc: 0.5787 - val_loss: 0.6814 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.6776 - acc: 0.5789 - val_loss: 0.6746 - val_acc: 0.5768\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 380us/step - loss: 0.6703 - acc: 0.5811 - val_loss: 0.6736 - val_acc: 0.5831\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 11s 350us/step - loss: 0.6670 - acc: 0.5823 - val_loss: 0.6697 - val_acc: 0.5678\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 13s 386us/step - loss: 0.6654 - acc: 0.5817 - val_loss: 0.6691 - val_acc: 0.5805\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 11s 338us/step - loss: 0.6646 - acc: 0.5818 - val_loss: 0.6701 - val_acc: 0.5764\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 10s 298us/step - loss: 0.6625 - acc: 0.5820 - val_loss: 0.6688 - val_acc: 0.5826\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.6614 - acc: 0.5829 - val_loss: 0.6688 - val_acc: 0.5790\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 345us/step - loss: 0.6609 - acc: 0.5814 - val_loss: 0.6662 - val_acc: 0.5850\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.6610 - acc: 0.5828 - val_loss: 0.6677 - val_acc: 0.5742\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 333us/step - loss: 0.6601 - acc: 0.5850 - val_loss: 0.6672 - val_acc: 0.5694\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 378us/step - loss: 0.6598 - acc: 0.5820 - val_loss: 0.6687 - val_acc: 0.5601\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 372us/step - loss: 0.6593 - acc: 0.5859 - val_loss: 0.6681 - val_acc: 0.5850\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 13s 386us/step - loss: 0.6597 - acc: 0.5826 - val_loss: 0.6681 - val_acc: 0.5820\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 366us/step - loss: 0.6597 - acc: 0.5824 - val_loss: 0.6697 - val_acc: 0.5581\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.6588 - acc: 0.5807 - val_loss: 0.6697 - val_acc: 0.5870\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 359us/step - loss: 0.6586 - acc: 0.5839 - val_loss: 0.6662 - val_acc: 0.5845\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 378us/step - loss: 0.6576 - acc: 0.5849 - val_loss: 0.6656 - val_acc: 0.5674\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 11s 332us/step - loss: 0.6500 - acc: 0.5992 - val_loss: 0.6485 - val_acc: 0.6236\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 21, 21, 6)    276         input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 2646)         0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_31 (Merge)                (None, 2650)         0           flatten_31[0][0]                 \n",
      "                                                                 input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 32)           84832       merge_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 32)           1056        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 1)            33          dense_92[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 400us/step - loss: 0.6828 - acc: 0.5772 - val_loss: 0.6830 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 349us/step - loss: 0.6814 - acc: 0.5788 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 345us/step - loss: 0.6651 - acc: 0.6018 - val_loss: 0.5953 - val_acc: 0.7048\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 366us/step - loss: 0.3983 - acc: 0.8390 - val_loss: 0.2386 - val_acc: 0.9292\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 379us/step - loss: 0.1447 - acc: 0.9662 - val_loss: 0.0880 - val_acc: 0.9847\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.0592 - acc: 0.9904 - val_loss: 0.0474 - val_acc: 0.9906\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 11s 337us/step - loss: 0.0274 - acc: 0.9978 - val_loss: 0.0266 - val_acc: 0.9946\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 11s 326us/step - loss: 0.0156 - acc: 0.9990 - val_loss: 0.0151 - val_acc: 0.9980\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 354us/step - loss: 0.0095 - acc: 0.9994 - val_loss: 0.0166 - val_acc: 0.9959\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 359us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.0118 - val_acc: 0.9978\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0186 - val_acc: 0.9935\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 364us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0052 - val_acc: 0.9990\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9995\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 366us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9994\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 373us/step - loss: 8.4471e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9994\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 13s 397us/step - loss: 6.2307e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9994\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 376us/step - loss: 4.6620e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9995\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 3.5655e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9995\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 2.7137e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9998\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 359us/step - loss: 2.0768e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9995\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 21, 21, 6)    276         input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 2646)         0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_64 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_32 (Merge)                (None, 2650)         0           flatten_32[0][0]                 \n",
      "                                                                 input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 32)           84832       merge_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 32)           1056        dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 1)            33          dense_95[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 387us/step - loss: 0.6820 - acc: 0.5773 - val_loss: 0.6821 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 354us/step - loss: 0.6810 - acc: 0.5787 - val_loss: 0.6818 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 365us/step - loss: 0.6784 - acc: 0.5794 - val_loss: 0.6752 - val_acc: 0.5791\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 325us/step - loss: 0.6697 - acc: 0.5824 - val_loss: 0.6714 - val_acc: 0.5848\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 373us/step - loss: 0.6648 - acc: 0.5800 - val_loss: 0.6709 - val_acc: 0.5836\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.6627 - acc: 0.5842 - val_loss: 0.6732 - val_acc: 0.5817\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 0.6613 - acc: 0.5831 - val_loss: 0.6706 - val_acc: 0.5801\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 383us/step - loss: 0.6601 - acc: 0.5812 - val_loss: 0.6709 - val_acc: 0.5737\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 338us/step - loss: 0.6595 - acc: 0.5823 - val_loss: 0.6753 - val_acc: 0.5850\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.6593 - acc: 0.5827 - val_loss: 0.6707 - val_acc: 0.5539\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.6590 - acc: 0.5819 - val_loss: 0.6713 - val_acc: 0.5796\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.6585 - acc: 0.5854 - val_loss: 0.6707 - val_acc: 0.5587\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 11s 335us/step - loss: 0.6579 - acc: 0.5870 - val_loss: 0.6733 - val_acc: 0.5871\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 10s 304us/step - loss: 0.6538 - acc: 0.6004 - val_loss: 0.6500 - val_acc: 0.6228\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 342us/step - loss: 0.5989 - acc: 0.6798 - val_loss: 0.5721 - val_acc: 0.6933\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 365us/step - loss: 0.5160 - acc: 0.7478 - val_loss: 0.4935 - val_acc: 0.7572\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 372us/step - loss: 0.4471 - acc: 0.7787 - val_loss: 0.4294 - val_acc: 0.7807\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.3555 - acc: 0.8368 - val_loss: 0.2989 - val_acc: 0.8752\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 350us/step - loss: 0.2316 - acc: 0.9134 - val_loss: 0.1948 - val_acc: 0.9319\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.1534 - acc: 0.9479 - val_loss: 0.1367 - val_acc: 0.9566\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 21, 21, 6)    276         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 2646)         0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_66 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_33 (Merge)                (None, 2650)         0           flatten_33[0][0]                 \n",
      "                                                                 input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 32)           84832       merge_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 32)           1056        dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 1)            33          dense_98[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 389us/step - loss: 0.6826 - acc: 0.5776 - val_loss: 0.6821 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 379us/step - loss: 0.6807 - acc: 0.5785 - val_loss: 0.6800 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.5584 - acc: 0.7092 - val_loss: 0.3662 - val_acc: 0.8484\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 10s 318us/step - loss: 0.2145 - acc: 0.9354 - val_loss: 0.1226 - val_acc: 0.9783\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 11s 333us/step - loss: 0.0919 - acc: 0.9830 - val_loss: 0.0702 - val_acc: 0.9862\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.0491 - acc: 0.9924 - val_loss: 0.0383 - val_acc: 0.9940\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 11s 350us/step - loss: 0.0303 - acc: 0.9960 - val_loss: 0.0264 - val_acc: 0.9966\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.0187 - acc: 0.9978 - val_loss: 0.0235 - val_acc: 0.9943\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 13s 391us/step - loss: 0.0136 - acc: 0.9980 - val_loss: 0.0130 - val_acc: 0.9985\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.0130 - acc: 0.9969 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 10s 318us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0066 - val_acc: 0.9991\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 351us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0045 - val_acc: 0.9994\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0646 - val_acc: 0.9782\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 11s 324us/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0040 - val_acc: 0.9994\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9996\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 364us/step - loss: 9.4500e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9998\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 11s 331us/step - loss: 7.0034e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 11s 347us/step - loss: 5.3915e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9998\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 351us/step - loss: 4.1604e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9996\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 11s 353us/step - loss: 3.2576e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 0.9998\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_67 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 21, 21, 6)    276         input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 2646)         0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_68 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_34 (Merge)                (None, 2650)         0           flatten_34[0][0]                 \n",
      "                                                                 input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 32)           84832       merge_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 32)           1056        dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 1)            33          dense_101[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 408us/step - loss: 0.6823 - acc: 0.5779 - val_loss: 0.6842 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 337us/step - loss: 0.6811 - acc: 0.5787 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 376us/step - loss: 0.6806 - acc: 0.5789 - val_loss: 0.6822 - val_acc: 0.5748\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 0.6771 - acc: 0.5793 - val_loss: 0.6751 - val_acc: 0.5752\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 11s 343us/step - loss: 0.6698 - acc: 0.5815 - val_loss: 0.6729 - val_acc: 0.5785\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 363us/step - loss: 0.6661 - acc: 0.5818 - val_loss: 0.6740 - val_acc: 0.5788\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 0.6638 - acc: 0.5806 - val_loss: 0.6744 - val_acc: 0.5465\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 379us/step - loss: 0.6630 - acc: 0.5823 - val_loss: 0.6736 - val_acc: 0.5703\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 323us/step - loss: 0.6624 - acc: 0.5833 - val_loss: 0.6723 - val_acc: 0.5473\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 11s 342us/step - loss: 0.6618 - acc: 0.5806 - val_loss: 0.6714 - val_acc: 0.5767\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.6609 - acc: 0.5824 - val_loss: 0.6720 - val_acc: 0.5800\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 351us/step - loss: 0.6608 - acc: 0.5829 - val_loss: 0.6787 - val_acc: 0.5822\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 0.6604 - acc: 0.5847 - val_loss: 0.6726 - val_acc: 0.5619\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.6604 - acc: 0.5822 - val_loss: 0.6714 - val_acc: 0.5813\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.6600 - acc: 0.5837 - val_loss: 0.6735 - val_acc: 0.5786\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 10s 314us/step - loss: 0.6601 - acc: 0.5839 - val_loss: 0.6727 - val_acc: 0.5780\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.6596 - acc: 0.5837 - val_loss: 0.6704 - val_acc: 0.5841\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 11s 352us/step - loss: 0.6595 - acc: 0.5858 - val_loss: 0.6747 - val_acc: 0.5665\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.6593 - acc: 0.5827 - val_loss: 0.6723 - val_acc: 0.5832\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 11s 337us/step - loss: 0.6573 - acc: 0.5869 - val_loss: 0.6688 - val_acc: 0.5751\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_69 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 21, 21, 6)    276         input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 2646)         0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_70 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_35 (Merge)                (None, 2650)         0           flatten_35[0][0]                 \n",
      "                                                                 input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 32)           84832       merge_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 32)           1056        dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 1)            33          dense_104[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 409us/step - loss: 0.6828 - acc: 0.5778 - val_loss: 0.6817 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 13s 386us/step - loss: 0.6809 - acc: 0.5789 - val_loss: 0.6803 - val_acc: 0.5751\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.6260 - acc: 0.6504 - val_loss: 0.5656 - val_acc: 0.7058\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 377us/step - loss: 0.4298 - acc: 0.8063 - val_loss: 0.2705 - val_acc: 0.9073\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 373us/step - loss: 0.1762 - acc: 0.9577 - val_loss: 0.1155 - val_acc: 0.9825\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 379us/step - loss: 0.0863 - acc: 0.9858 - val_loss: 0.0634 - val_acc: 0.9914\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 378us/step - loss: 0.0492 - acc: 0.9933 - val_loss: 0.0436 - val_acc: 0.9936\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 11s 347us/step - loss: 0.0303 - acc: 0.9958 - val_loss: 0.0249 - val_acc: 0.9959\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 11s 340us/step - loss: 0.0182 - acc: 0.9976 - val_loss: 0.0164 - val_acc: 0.9978\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 369us/step - loss: 0.0135 - acc: 0.9978 - val_loss: 0.0124 - val_acc: 0.9984\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 11s 349us/step - loss: 0.0086 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9983\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 13s 386us/step - loss: 0.0091 - acc: 0.9979 - val_loss: 0.0113 - val_acc: 0.9970\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.0054 - acc: 0.9991 - val_loss: 0.0040 - val_acc: 0.9998\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 13s 388us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.0031 - val_acc: 0.9998\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 365us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9996\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 363us/step - loss: 7.2769e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9999\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 380us/step - loss: 5.4543e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9998\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 380us/step - loss: 3.9191e-04 - acc: 1.0000 - val_loss: 9.6512e-04 - val_acc: 0.9999\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0079 - val_acc: 0.9968\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 21, 21, 6)    276         input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 2646)         0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_72 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_36 (Merge)                (None, 2650)         0           flatten_36[0][0]                 \n",
      "                                                                 input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 32)           84832       merge_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 32)           1056        dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 1)            33          dense_107[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 11s 345us/step - loss: 0.6829 - acc: 0.5764 - val_loss: 0.6830 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 375us/step - loss: 0.6813 - acc: 0.5787 - val_loss: 0.6838 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 380us/step - loss: 0.6809 - acc: 0.5787 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 375us/step - loss: 0.6773 - acc: 0.5789 - val_loss: 0.6765 - val_acc: 0.5780\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 357us/step - loss: 0.6684 - acc: 0.5773 - val_loss: 0.6724 - val_acc: 0.5812\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 13s 390us/step - loss: 0.6652 - acc: 0.5795 - val_loss: 0.6714 - val_acc: 0.5736\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 371us/step - loss: 0.6631 - acc: 0.5787 - val_loss: 0.6712 - val_acc: 0.5763\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.6611 - acc: 0.5824 - val_loss: 0.6700 - val_acc: 0.5672\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 369us/step - loss: 0.6415 - acc: 0.6174 - val_loss: 0.6257 - val_acc: 0.6376\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 364us/step - loss: 0.5310 - acc: 0.7348 - val_loss: 0.4480 - val_acc: 0.7851\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.3650 - acc: 0.8352 - val_loss: 0.2955 - val_acc: 0.8762\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.2125 - acc: 0.9238 - val_loss: 0.1537 - val_acc: 0.9513\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.1058 - acc: 0.9714 - val_loss: 0.0878 - val_acc: 0.9754\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 356us/step - loss: 0.0656 - acc: 0.9836 - val_loss: 0.0613 - val_acc: 0.9840\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 11s 349us/step - loss: 0.0466 - acc: 0.9882 - val_loss: 0.0488 - val_acc: 0.9849\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 12s 362us/step - loss: 0.0368 - acc: 0.9907 - val_loss: 0.0369 - val_acc: 0.9898\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 359us/step - loss: 0.0303 - acc: 0.9921 - val_loss: 0.0332 - val_acc: 0.9899\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.0231 - acc: 0.9940 - val_loss: 0.0316 - val_acc: 0.9893\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 375us/step - loss: 0.0198 - acc: 0.9949 - val_loss: 0.0242 - val_acc: 0.9924\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.0171 - acc: 0.9956 - val_loss: 0.0186 - val_acc: 0.9958\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_73 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 21, 21, 6)    276         input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 2646)         0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_74 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_37 (Merge)                (None, 2650)         0           flatten_37[0][0]                 \n",
      "                                                                 input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 32)           84832       merge_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 32)           1056        dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 1)            33          dense_110[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 399us/step - loss: 0.6826 - acc: 0.5772 - val_loss: 0.6843 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 347us/step - loss: 0.6812 - acc: 0.5787 - val_loss: 0.6818 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 331us/step - loss: 0.6548 - acc: 0.6131 - val_loss: 0.5553 - val_acc: 0.7330\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 366us/step - loss: 0.3364 - acc: 0.8689 - val_loss: 0.1658 - val_acc: 0.9663\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 375us/step - loss: 0.1160 - acc: 0.9768 - val_loss: 0.0833 - val_acc: 0.9846\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 331us/step - loss: 0.0588 - acc: 0.9907 - val_loss: 0.0444 - val_acc: 0.9941\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.0340 - acc: 0.9946 - val_loss: 0.0278 - val_acc: 0.9962\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 367us/step - loss: 0.0200 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 0.9890\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 13s 388us/step - loss: 0.0156 - acc: 0.9970 - val_loss: 0.0129 - val_acc: 0.9982\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 375us/step - loss: 0.0102 - acc: 0.9985 - val_loss: 0.0121 - val_acc: 0.9970\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 13s 389us/step - loss: 0.0134 - acc: 0.9962 - val_loss: 0.0081 - val_acc: 0.9988\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 11s 352us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0070 - val_acc: 0.9990\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 379us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0030 - val_acc: 0.9998\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9998\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9996\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 335us/step - loss: 0.0144 - acc: 0.9953 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 11s 338us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 6.8476e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9996\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 378us/step - loss: 5.3183e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9996\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 4.2011e-04 - acc: 1.0000 - val_loss: 9.8732e-04 - val_acc: 0.9996\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_75 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 21, 21, 6)    276         input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 2646)         0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_76 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_38 (Merge)                (None, 2650)         0           flatten_38[0][0]                 \n",
      "                                                                 input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 32)           84832       merge_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 32)           1056        dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 1)            33          dense_113[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.6820 - acc: 0.5773 - val_loss: 0.6819 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.6811 - acc: 0.5787 - val_loss: 0.6830 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 11s 346us/step - loss: 0.6807 - acc: 0.5787 - val_loss: 0.6821 - val_acc: 0.5748\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 11s 349us/step - loss: 0.6807 - acc: 0.5787 - val_loss: 0.6820 - val_acc: 0.5748\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 356us/step - loss: 0.6781 - acc: 0.5790 - val_loss: 0.6762 - val_acc: 0.5751\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 332us/step - loss: 0.6704 - acc: 0.5793 - val_loss: 0.6726 - val_acc: 0.5795\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 360us/step - loss: 0.6676 - acc: 0.5803 - val_loss: 0.6734 - val_acc: 0.5545\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 0.6661 - acc: 0.5766 - val_loss: 0.6737 - val_acc: 0.5678\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.6651 - acc: 0.5793 - val_loss: 0.6722 - val_acc: 0.5745\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.6639 - acc: 0.5808 - val_loss: 0.6721 - val_acc: 0.5674\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.6634 - acc: 0.5797 - val_loss: 0.6729 - val_acc: 0.5708\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 356us/step - loss: 0.6629 - acc: 0.5795 - val_loss: 0.6770 - val_acc: 0.5805\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 364us/step - loss: 0.6621 - acc: 0.5810 - val_loss: 0.6698 - val_acc: 0.5748\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 12s 376us/step - loss: 0.6609 - acc: 0.5807 - val_loss: 0.6698 - val_acc: 0.5731\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 360us/step - loss: 0.6583 - acc: 0.5779 - val_loss: 0.6620 - val_acc: 0.5847\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 335us/step - loss: 0.6351 - acc: 0.6090 - val_loss: 0.6115 - val_acc: 0.6520\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.5733 - acc: 0.7022 - val_loss: 0.5511 - val_acc: 0.7323\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 11s 352us/step - loss: 0.5199 - acc: 0.7486 - val_loss: 0.4960 - val_acc: 0.7613\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.4684 - acc: 0.7744 - val_loss: 0.4520 - val_acc: 0.7834\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 384us/step - loss: 0.4243 - acc: 0.8031 - val_loss: 0.4113 - val_acc: 0.8107\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_77 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 21, 21, 6)    276         input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 2646)         0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_39 (Merge)                (None, 2650)         0           flatten_39[0][0]                 \n",
      "                                                                 input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 32)           84832       merge_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 32)           1056        dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 1)            33          dense_116[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 13s 392us/step - loss: 0.6833 - acc: 0.5752 - val_loss: 0.6825 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 11s 351us/step - loss: 0.6811 - acc: 0.5787 - val_loss: 0.6822 - val_acc: 0.5748\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 13s 394us/step - loss: 0.6811 - acc: 0.5784 - val_loss: 0.6818 - val_acc: 0.5748\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 376us/step - loss: 0.6790 - acc: 0.5793 - val_loss: 0.6665 - val_acc: 0.5836\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 374us/step - loss: 0.5177 - acc: 0.7432 - val_loss: 0.3677 - val_acc: 0.8395\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 11s 350us/step - loss: 0.2198 - acc: 0.9286 - val_loss: 0.1239 - val_acc: 0.9697\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 355us/step - loss: 0.0809 - acc: 0.9860 - val_loss: 0.0566 - val_acc: 0.9916\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 11s 349us/step - loss: 0.0398 - acc: 0.9956 - val_loss: 0.0307 - val_acc: 0.9962\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 372us/step - loss: 0.0225 - acc: 0.9975 - val_loss: 0.0175 - val_acc: 0.9983\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 364us/step - loss: 0.0137 - acc: 0.9987 - val_loss: 0.0129 - val_acc: 0.9990\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 13s 393us/step - loss: 0.0091 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9996\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 366us/step - loss: 0.0054 - acc: 0.9997 - val_loss: 0.0051 - val_acc: 0.9996\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 11s 338us/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0216 - val_acc: 0.9927\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0033 - val_acc: 0.9998\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9999\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 341us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 10s 302us/step - loss: 9.8107e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9999\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 11s 343us/step - loss: 7.1694e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9999\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0049 - val_acc: 0.9993\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 383us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0012 - val_acc: 0.9998\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_79 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 21, 21, 6)    276         input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 2646)         0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_40 (Merge)                (None, 2650)         0           flatten_40[0][0]                 \n",
      "                                                                 input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 32)           84832       merge_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 32)           1056        dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 1)            33          dense_119[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32503 samples, validate on 8126 samples\n",
      "Epoch 1/20\n",
      "32503/32503 [==============================] - 12s 384us/step - loss: 0.6831 - acc: 0.5770 - val_loss: 0.6822 - val_acc: 0.5748\n",
      "Epoch 2/20\n",
      "32503/32503 [==============================] - 12s 359us/step - loss: 0.6715 - acc: 0.5879 - val_loss: 0.6224 - val_acc: 0.6530\n",
      "Epoch 3/20\n",
      "32503/32503 [==============================] - 12s 377us/step - loss: 0.4799 - acc: 0.7814 - val_loss: 0.3634 - val_acc: 0.8437\n",
      "Epoch 4/20\n",
      "32503/32503 [==============================] - 12s 381us/step - loss: 0.2590 - acc: 0.9078 - val_loss: 0.1911 - val_acc: 0.9380\n",
      "Epoch 5/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.1393 - acc: 0.9615 - val_loss: 0.0982 - val_acc: 0.9782\n",
      "Epoch 6/20\n",
      "32503/32503 [==============================] - 12s 361us/step - loss: 0.0734 - acc: 0.9845 - val_loss: 0.0571 - val_acc: 0.9898\n",
      "Epoch 7/20\n",
      "32503/32503 [==============================] - 12s 363us/step - loss: 0.0429 - acc: 0.9931 - val_loss: 0.0439 - val_acc: 0.9884\n",
      "Epoch 8/20\n",
      "32503/32503 [==============================] - 12s 383us/step - loss: 0.0295 - acc: 0.9948 - val_loss: 0.0286 - val_acc: 0.9940\n",
      "Epoch 9/20\n",
      "32503/32503 [==============================] - 12s 370us/step - loss: 0.0182 - acc: 0.9971 - val_loss: 0.0215 - val_acc: 0.9941\n",
      "Epoch 10/20\n",
      "32503/32503 [==============================] - 12s 357us/step - loss: 0.0130 - acc: 0.9981 - val_loss: 0.0165 - val_acc: 0.9966\n",
      "Epoch 11/20\n",
      "32503/32503 [==============================] - 11s 334us/step - loss: 0.0115 - acc: 0.9980 - val_loss: 0.0302 - val_acc: 0.9899\n",
      "Epoch 12/20\n",
      "32503/32503 [==============================] - 12s 384us/step - loss: 0.0076 - acc: 0.9988 - val_loss: 0.0106 - val_acc: 0.9970\n",
      "Epoch 13/20\n",
      "32503/32503 [==============================] - 12s 368us/step - loss: 0.0059 - acc: 0.9990 - val_loss: 0.0099 - val_acc: 0.9973\n",
      "Epoch 14/20\n",
      "32503/32503 [==============================] - 13s 385us/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9978\n",
      "Epoch 15/20\n",
      "32503/32503 [==============================] - 12s 382us/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0049 - val_acc: 0.9993\n",
      "Epoch 16/20\n",
      "32503/32503 [==============================] - 11s 344us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "Epoch 17/20\n",
      "32503/32503 [==============================] - 12s 358us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0080 - val_acc: 0.9980\n",
      "Epoch 18/20\n",
      "32503/32503 [==============================] - 12s 379us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0031 - val_acc: 0.9994\n",
      "Epoch 19/20\n",
      "32503/32503 [==============================] - 11s 330us/step - loss: 6.9622e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9995\n",
      "Epoch 20/20\n",
      "32503/32503 [==============================] - 12s 376us/step - loss: 4.6016e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9996\n"
     ]
    }
   ],
   "source": [
    "ego_info = np.zeros((num_exper,4,epochs))\n",
    "for i in range(num_exper):\n",
    "    c,x,z = createLayers(rest_size,conv_size,naction)\n",
    "\n",
    "    ego_classifier = Model(inputs=[c,x],outputs=z)\n",
    "\n",
    "    ego_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    ego_classifier.summary()\n",
    "\n",
    "    ego_history = ego_classifier.fit([all_simu['cnn_input'],all_simu['rest_input']],\n",
    "                                       all_simu['y'],epochs=epochs,batch_size=64,validation_split=0.2)\n",
    "    \n",
    "    ego_info[i,0,:] = ego_history.history['val_loss']\n",
    "    ego_info[i,1,:] = ego_history.history['val_acc']\n",
    "    ego_info[i,2,:] = ego_history.history['loss']\n",
    "    ego_info[i,3,:] = ego_history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('val_train_acc_loss_E.npz',allo=info,ego=ego_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = np.load('val_train_acc_loss_E.npz')\n",
    "ego_info = info['ego']\n",
    "info = info['allo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af3b3dcddd8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avlm,avls = calculate(info,0)\n",
    "evlm,evls = calculate(ego_info,0)\n",
    "plt.plot(avlm,color='b',label='allo val loss')\n",
    "plt.fill_between(np.arange(20),avlm+avls,avlm-avls,alpha=0.2)\n",
    "\n",
    "plt.plot(evlm,color='r',label='ego val loss')\n",
    "plt.fill_between(np.arange(20),evlm+evls,evlm-evls,alpha=0.2)\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af39fec09b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avlm,avls = calculate(info,1)\n",
    "evlm,evls = calculate(ego_info,1)\n",
    "ax= plt.subplot(1,1,1)\n",
    "ax.plot(np.arange(20),avlm,color='b',label='allo val loss')\n",
    "ax.fill_between(np.arange(20),avlm+avls,avlm-avls,alpha=0.2)\n",
    "ax.plot(np.arange(20),evlm,color='r',label='ego val loss')\n",
    "ax.fill_between(np.arange(20),evlm+evls,evlm-evls,alpha=0.2)\n",
    "ax.set\n",
    "ax.set_xticks(np.arange(20),minor=True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b2000e8c860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avam,avas = calculate(info,1)\n",
    "evam,evas = calculate(ego_info,1)\n",
    "plt.plot(avam,color='b',label='allo validation accuracy')\n",
    "plt.fill_between(np.arange(20),avam+avas,avam-avas,alpha=0.2)\n",
    "plt.plot(evam,color='r',label='ego validation accuracy')\n",
    "plt.fill_between(np.arange(20),evam+evas,evam-evas,alpha=0.2)\n",
    "atam,avas = calculate(info,3)\n",
    "etam,evas = calculate(ego_info,3)\n",
    "#plt.plot(atam,color='black',label='allo training accuracy')\n",
    "\n",
    "#plt.plot(etam,color='r',label='ego training accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 21, 21, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 21, 21, 6)    276         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 2646)         0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_9 (Merge)                 (None, 2650)         0           flatten_9[0][0]                  \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 32)           84832       merge_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 32)           1056        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            33          dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,197\n",
      "Trainable params: 86,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/labash/miniconda3/envs/PT/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/gpfs/hpchome/labash/miniconda3/envs/PT/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "c,x,z = createLayers(rest_size,conv_size,naction)\n",
    "\n",
    "classifier = Model(inputs=[c,x],outputs=z)\n",
    "\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 319us/step - loss: 0.6840 - acc: 0.5709 - val_loss: 0.6837 - val_acc: 0.5968\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 5s 291us/step - loss: 0.6824 - acc: 0.5741 - val_loss: 0.6772 - val_acc: 0.5972\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 5s 289us/step - loss: 0.6814 - acc: 0.5744 - val_loss: 0.6758 - val_acc: 0.5972\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 5s 294us/step - loss: 0.6785 - acc: 0.5757 - val_loss: 0.6702 - val_acc: 0.6025\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 5s 291us/step - loss: 0.6023 - acc: 0.6862 - val_loss: 0.5476 - val_acc: 0.7272\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 276us/step - loss: 0.4707 - acc: 0.7772 - val_loss: 0.4028 - val_acc: 0.8127\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 270us/step - loss: 0.2964 - acc: 0.8935 - val_loss: 0.2347 - val_acc: 0.9265\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 270us/step - loss: 0.1705 - acc: 0.9550 - val_loss: 0.1446 - val_acc: 0.9617\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 270us/step - loss: 0.1020 - acc: 0.9785 - val_loss: 0.0997 - val_acc: 0.9742\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 271us/step - loss: 0.0678 - acc: 0.9894 - val_loss: 0.0826 - val_acc: 0.9750\n"
     ]
    }
   ],
   "source": [
    "ego_history = classifier.fit([all_simu['cnn_input'][:20000],all_simu['rest_input'][:20000]],all_simu['y'][:20000],epochs=10,batch_size=64,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier attached to the trained network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model,Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/labash/miniconda3/envs/PT/lib/python3.5/site-packages/keras/engine/topology.py:1271: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 5) 5 (8,)\n"
     ]
    }
   ],
   "source": [
    "all_simu = np.load('ego:{}_simulation_200000.npz'.format(Ego))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 11, 11,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 100, 11, 11,  276         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 100, 726)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 100, 8)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 100, 734)     0           time_distributed_2[0][0]         \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 100, 32)      23520       merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 100, 32)      1056        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100, 128)     82432       time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 100, 6)       774         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 100, 5)       0           time_distributed_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 108,058\n",
      "Trainable params: 108,058\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 11, 11,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 100, 11, 11,  276         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 100, 726)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 100, 8)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 100, 734)     0           time_distributed_2[0][0]         \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_mod = Model(inputs=[model.input[0],model.input[1]],outputs=[model.get_layer(index=4).output])\n",
    "conv_mod.summary()\n",
    "cnn_input = all_simu['cnn_input']\n",
    "rest_input = all_simu['rest_input']\n",
    "cnn_zeros = np.zeros((99,11,11,5))\n",
    "rest_zeros = np.zeros((99,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_data = np.zeros((cnn_input.shape[0],734))\n",
    "for i in range(cnn_input.shape[0]):\n",
    "    concated = np.concatenate([cnn_input[i][np.newaxis],cnn_zeros],axis=0)\n",
    "    rest_concated = np.concatenate([rest_input[i][np.newaxis],rest_zeros],axis=0)\n",
    "    conv_row = conv_mod.predict([concated[np.newaxis],rest_concated[np.newaxis]])\n",
    "    conv_data[i] = conv_row[0,0]\n",
    "np.save('conv_data.npy',conv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 11, 11,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 100, 11, 11,  276         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 100, 726)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 100, 8)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 100, 734)     0           time_distributed_2[0][0]         \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 100, 32)      23520       merge_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,796\n",
      "Trainable params: 23,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FC1_mod = Model(inputs=[model.input[0],model.input[1]],outputs=[model.get_layer(index=5).output])\n",
    "FC1_mod.summary()\n",
    "FC1_data = np.zeros((cnn_input.shape[0],32))\n",
    "for i in range(cnn_input.shape[0]):\n",
    "    concated = np.concatenate([cnn_input[i][np.newaxis],cnn_zeros],axis=0)\n",
    "    rest_concated = np.concatenate([rest_input[i][np.newaxis],rest_zeros],axis=0)\n",
    "    conv_row = FC1_mod.predict([concated[np.newaxis],rest_concated[np.newaxis]])\n",
    "    FC1_data[i] = conv_row[0,0]\n",
    "np.save('FC1_data.npy',FC1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 11, 11,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 100, 11, 11,  276         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 100, 726)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 100, 8)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 100, 734)     0           time_distributed_2[0][0]         \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 100, 32)      23520       merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 100, 32)      1056        time_distributed_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 24,852\n",
      "Trainable params: 24,852\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FC2_mod = Model(inputs=[model.input[0],model.input[1]],outputs=[model.get_layer(index=6).output])\n",
    "FC2_mod.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC2_data = np.zeros((cnn_input.shape[0],32))\n",
    "for i in range(cnn_input.shape[0]):\n",
    "    concated = np.concatenate([cnn_input[i][np.newaxis],cnn_zeros],axis=0)\n",
    "    rest_concated = np.concatenate([rest_input[i][np.newaxis],rest_zeros],axis=0)\n",
    "    conv_row = FC2_mod.predict([concated[np.newaxis],rest_concated[np.newaxis]])\n",
    "    FC2_data[i] = conv_row[0,0]\n",
    "np.save('FC2_data.npy',FC1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 11, 11,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 100, 11, 11,  276         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 100, 726)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 100, 8)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 100, 734)     0           time_distributed_2[0][0]         \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 100, 32)      23520       merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 100, 32)      1056        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100, 128)     82432       time_distributed_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 107,284\n",
      "Trainable params: 107,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_mod = Model(inputs=[model.input[0],model.input[1]],outputs=[model.get_layer(index=7).output])\n",
    "LSTM_mod.summary()\n",
    "\n",
    "LSTM_data = np.zeros((cnn_input.shape[0],128))\n",
    "for i in range(cnn_input.shape[0]):\n",
    "    concated = np.concatenate([cnn_input[i][np.newaxis],cnn_zeros],axis=0)\n",
    "    rest_concated = np.concatenate([rest_input[i][np.newaxis],rest_zeros],axis=0)\n",
    "    conv_row = LSTM_mod.predict([concated[np.newaxis],rest_concated[np.newaxis]])\n",
    "    LSTM_data[i] = conv_row[0,0]\n",
    "np.save('LSTM_data.npy',FC1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.zeros((cnn_input.shape[0],5))\n",
    "for i in range(cnn_input.shape[0]):\n",
    "    concated = np.concatenate([cnn_input[i][np.newaxis],cnn_zeros],axis=0)\n",
    "    rest_concated = np.concatenate([rest_input[i][np.newaxis],rest_zeros],axis=0)\n",
    "    conv_row = model.predict([concated[np.newaxis],rest_concated[np.newaxis]])\n",
    "    final_data[i] = conv_row[0,0]\n",
    "np.save('final.npy',final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
