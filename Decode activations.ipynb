{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from APES import *\n",
    "from time import time\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model,load_model\n",
    "%matplotlib inline\n",
    "ticks_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=15, weight='normal', stretch='normal')\n",
    "legend_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=12, weight='normal', stretch='normal')\n",
    "hfont =  {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "csfont = {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "def calculate(val,index):\n",
    "    mean = np.mean(val[:,index,:],axis=0)\n",
    "    std = np.std(val[:,index,:],axis=0)\n",
    "    return mean,std/np.sqrt(20)\n",
    "\n",
    "def Prepare_model(mod=1336):\n",
    "    x = load_model('output/{}/MOD/model.h5'.format(mod))\n",
    "    nm = Model(inputs=[x.layers[i].input for i in [0,3]],\n",
    "               outputs=[x.layers[i].output for i in [2,4,5,6,7,8,9]])\n",
    "    return nm\n",
    "\n",
    "def Get_dataset(Ego=False):\n",
    "    if Ego:\n",
    "        unique_count=26400\n",
    "    else:\n",
    "        unique_count=31200\n",
    "    all_simu = np.load('NPZ/in_out_{}_seq_EGO_{}.npz'.format(unique_count,Ego))\n",
    "\n",
    "    data = all_simu['input_target']\n",
    "    action_sequence = all_simu['action_sequence']\n",
    "\n",
    "    if Ego:\n",
    "        cnn_input = data[:,:693]\n",
    "        rest_input = data[:,693:697]\n",
    "        y = data[:,697]\n",
    "        cnn_input = cnn_input.reshape((data.shape[0],11,21,3))\n",
    "        rest_input = rest_input.reshape((data.shape[0],4))\n",
    "\n",
    "        conv_size=(11,21,3,)\n",
    "        rest_size=(4,)\n",
    "\n",
    "    else:\n",
    "        cnn_input = data[:,:676]\n",
    "        rest_input = data[:,676:684]\n",
    "        y = data[:,684]\n",
    "        cnn_input = cnn_input.reshape((data.shape[0],13,13,4))\n",
    "        rest_input = rest_input.reshape((data.shape[0],8))\n",
    "\n",
    "        conv_size=(13,13,4,)\n",
    "        rest_size=(8,)\n",
    "    \n",
    "    y = y.reshape((data.shape[0],1))\n",
    "    naction =  Settings.PossibleActions.shape[0]\n",
    "    return cnn_input,rest_input,y,conv_size,rest_size,naction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Best models allo/ego with allo/ego actions</h3>\n",
    "<table align=\"left\">\n",
    "  <tr>\n",
    "    <th>Actions\\Vision</th>\n",
    "    <th>Allo</th>\n",
    "    <th>Ego</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Allo</th>\n",
    "    <td>1336</td>\n",
    "    <td>1440</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Ego</th>\n",
    "    <td>1420</td>\n",
    "    <td>1358</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ego actions are :0: Forward, 1:Backword, 2:Right, 3:left,4:nothing\n",
    "#### Allo actions are :0: North, 1:South, 2:West, 3:East, 4:nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31200, 13, 13, 4) (31200, 8) (31200, 1)\n",
      "(13, 13, 4) 5 (8,)\n"
     ]
    }
   ],
   "source": [
    "cnn_input,rest_input,y,conv_size,rest_size,naction = Get_dataset(Ego=False)\n",
    "print(cnn_input.shape,rest_input.shape,y.shape)\n",
    "print(conv_size,naction,rest_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "nm = Prepare_model(1336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputt = np.zeros((cnn_input.shape[0],100,13,13,4),dtype=np.int8)\n",
    "restt = np.zeros((cnn_input.shape[0],100,8),dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputt[:,0] = cnn_input\n",
    "restt[:,0] = rest_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31200, 100, 13, 13, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nm.predict_on_batch([inputt,restt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('activations_model:{}.npz',flatten=tmp[0],merge=tmp[1],FC_1=tmp[2],FC_2=tmp[3],\n",
    "         LSTM = tmp[4],FC_3=tmp[5],output=tmp[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.00963\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n",
      "16.317734\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(np.sum(tmp[0][0,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,convolutional,Flatten,merge,Dense\n",
    "from keras.models import load_model,Model\n",
    "from APES import *\n",
    "from time import time\n",
    "\n",
    "def createLayers(insize,in_conv,naction):\n",
    "    c = Input(shape=in_conv)\n",
    "    con_process = c\n",
    "    con_process = convolutional.Conv2D(filters=6,kernel_size=(3,3),activation=\"relu\",padding=\"same\",strides=1)(con_process)\n",
    "    con_process = Flatten()(con_process)\n",
    "    x = Input(shape=insize)#env.observation_space.shape)\n",
    "    h = merge([con_process,x],mode=\"concat\")\n",
    "    h = Dense(32, activation='tanh')(h)\n",
    "    h = Dense(32, activation='tanh')(h)\n",
    "    z = Dense(1, activation='sigmoid')(h)\n",
    "    return c,x, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Allocentric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpc/home/labash/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 13, 13, 6)     222         input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1014)          0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 1022)          0           flatten_2[0][0]                  \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 32)            32736       merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 32)            1056        dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             33          dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6813 - acc: 0.5838 - val_loss: 0.6776 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.4811 - acc: 0.7877 - val_loss: 0.2120 - val_acc: 0.9697\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.1061 - acc: 0.9908 - val_loss: 0.0616 - val_acc: 0.9947\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0304 - acc: 0.9999 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 8.5629e-04 - acc: 1.0000 - val_loss: 7.9284e-04 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.2868e-04 - acc: 1.0000 - val_loss: 5.7448e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.6976e-04 - acc: 1.0000 - val_loss: 4.4133e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.5471e-04 - acc: 1.0000 - val_loss: 3.3520e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.7103e-04 - acc: 1.0000 - val_loss: 2.5862e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.0897e-04 - acc: 1.0000 - val_loss: 1.9525e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.6210e-04 - acc: 1.0000 - val_loss: 1.5757e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.2603e-04 - acc: 1.0000 - val_loss: 1.2045e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 9.9007e-05 - acc: 1.0000 - val_loss: 9.4792e-05 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 4s - loss: 7.7848e-05 - acc: 1.0000 - val_loss: 7.4104e-05 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 13, 13, 6)     222         input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 1014)          0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 1022)          0           flatten_3[0][0]                  \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 32)            32736       merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 32)            1056        dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             33          dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6820 - acc: 0.5823 - val_loss: 0.6814 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6489 - acc: 0.6261 - val_loss: 0.4928 - val_acc: 0.7776\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.2444 - acc: 0.9531 - val_loss: 0.1323 - val_acc: 0.9915\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0824 - acc: 0.9967 - val_loss: 0.0594 - val_acc: 0.9976\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0406 - acc: 0.9995 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0217 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.4726e-04 - acc: 1.0000 - val_loss: 7.3218e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.4942e-04 - acc: 1.0000 - val_loss: 5.2186e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 4.0837e-04 - acc: 1.0000 - val_loss: 3.9047e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.0787e-04 - acc: 1.0000 - val_loss: 3.0340e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.3416e-04 - acc: 1.0000 - val_loss: 2.3326e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.8201e-04 - acc: 1.0000 - val_loss: 1.7773e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.4164e-04 - acc: 1.0000 - val_loss: 1.3807e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 13, 13, 6)     222         input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 1014)          0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 1022)          0           flatten_4[0][0]                  \n",
      "                                                                   input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 32)            32736       merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 32)            1056        dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             33          dense_11[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6828 - acc: 0.5812 - val_loss: 0.6802 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6803 - acc: 0.5840 - val_loss: 0.6807 - val_acc: 0.5806\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6799 - acc: 0.5840 - val_loss: 0.6807 - val_acc: 0.5806\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6800 - acc: 0.5840 - val_loss: 0.6813 - val_acc: 0.5806\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6795 - acc: 0.5840 - val_loss: 0.6800 - val_acc: 0.5806\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6761 - acc: 0.5884 - val_loss: 0.6249 - val_acc: 0.7014\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.2917 - acc: 0.9161 - val_loss: 0.1318 - val_acc: 0.9843\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0659 - acc: 0.9973 - val_loss: 0.0360 - val_acc: 0.9998\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0215 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 8.7334e-04 - acc: 1.0000 - val_loss: 8.1835e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.6090e-04 - acc: 1.0000 - val_loss: 6.2040e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.0548e-04 - acc: 1.0000 - val_loss: 4.7840e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.9163e-04 - acc: 1.0000 - val_loss: 3.7006e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 4s - loss: 3.0484e-04 - acc: 1.0000 - val_loss: 2.8755e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 13, 13, 6)     222         input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 1014)          0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 1022)          0           flatten_5[0][0]                  \n",
      "                                                                   input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 32)            32736       merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 32)            1056        dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 1)             33          dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6815 - acc: 0.5813 - val_loss: 0.6780 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6601 - acc: 0.6047 - val_loss: 0.5841 - val_acc: 0.7478\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.3230 - acc: 0.9017 - val_loss: 0.1485 - val_acc: 0.9803\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0857 - acc: 0.9933 - val_loss: 0.0527 - val_acc: 0.9981\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0332 - acc: 0.9998 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 4s - loss: 9.0107e-04 - acc: 1.0000 - val_loss: 8.4207e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 4s - loss: 6.7490e-04 - acc: 1.0000 - val_loss: 6.4532e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.1573e-04 - acc: 1.0000 - val_loss: 4.9697e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.9306e-04 - acc: 1.0000 - val_loss: 3.7119e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.0470e-04 - acc: 1.0000 - val_loss: 2.8896e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.3552e-04 - acc: 1.0000 - val_loss: 2.2631e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.8580e-04 - acc: 1.0000 - val_loss: 1.7961e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.4504e-04 - acc: 1.0000 - val_loss: 1.4000e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 13, 13, 6)     222         input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 1014)          0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 1022)          0           flatten_6[0][0]                  \n",
      "                                                                   input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 32)            32736       merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 32)            1056        dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 1)             33          dense_17[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6795 - acc: 0.5811 - val_loss: 0.6724 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5599 - acc: 0.7090 - val_loss: 0.4725 - val_acc: 0.7516\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.3157 - acc: 0.8732 - val_loss: 0.1589 - val_acc: 0.9747\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.1004 - acc: 0.9851 - val_loss: 0.0691 - val_acc: 0.9909\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0477 - acc: 0.9954 - val_loss: 0.0370 - val_acc: 0.9973\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0258 - acc: 0.9982 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0152 - acc: 0.9994 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0091 - acc: 0.9999 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 5s - loss: 9.3047e-04 - acc: 1.0000 - val_loss: 8.4074e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.8432e-04 - acc: 1.0000 - val_loss: 6.5439e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 5.0582e-04 - acc: 1.0000 - val_loss: 4.7832e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.8024e-04 - acc: 1.0000 - val_loss: 3.6879e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.9133e-04 - acc: 1.0000 - val_loss: 2.7562e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.2284e-04 - acc: 1.0000 - val_loss: 2.0996e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.7292e-04 - acc: 1.0000 - val_loss: 1.6876e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 13, 13, 6)     222         input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 1014)          0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_14 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 1022)          0           flatten_7[0][0]                  \n",
      "                                                                   input_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 32)            32736       merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 32)            1056        dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 1)             33          dense_20[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6815 - acc: 0.5792 - val_loss: 0.6799 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5353 - acc: 0.7453 - val_loss: 0.2874 - val_acc: 0.9345\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1686 - acc: 0.9729 - val_loss: 0.0998 - val_acc: 0.9899\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0634 - acc: 0.9951 - val_loss: 0.0437 - val_acc: 0.9982\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0270 - acc: 0.9998 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 9.3076e-04 - acc: 1.0000 - val_loss: 8.7089e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.7578e-04 - acc: 1.0000 - val_loss: 6.4361e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.0007e-04 - acc: 1.0000 - val_loss: 4.6969e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.7570e-04 - acc: 1.0000 - val_loss: 3.6311e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.8508e-04 - acc: 1.0000 - val_loss: 2.6866e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.1606e-04 - acc: 1.0000 - val_loss: 2.0692e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.6672e-04 - acc: 1.0000 - val_loss: 1.6300e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.3006e-04 - acc: 1.0000 - val_loss: 1.2625e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.0197e-04 - acc: 1.0000 - val_loss: 1.0100e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 13, 13, 6)     222         input_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 1014)          0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_16 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 1022)          0           flatten_8[0][0]                  \n",
      "                                                                   input_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 32)            32736       merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 32)            1056        dense_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 1)             33          dense_23[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6813 - acc: 0.5824 - val_loss: 0.6803 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6609 - acc: 0.6082 - val_loss: 0.5618 - val_acc: 0.7335\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.3180 - acc: 0.8973 - val_loss: 0.1494 - val_acc: 0.9873\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0877 - acc: 0.9938 - val_loss: 0.0501 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0302 - acc: 0.9998 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 8.0101e-04 - acc: 1.0000 - val_loss: 7.1371e-04 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.5419e-04 - acc: 1.0000 - val_loss: 5.0633e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.9620e-04 - acc: 1.0000 - val_loss: 3.6564e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.9237e-04 - acc: 1.0000 - val_loss: 2.7490e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.1638e-04 - acc: 1.0000 - val_loss: 2.0785e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.6258e-04 - acc: 1.0000 - val_loss: 1.5553e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.2419e-04 - acc: 1.0000 - val_loss: 1.1915e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 9.4918e-05 - acc: 1.0000 - val_loss: 9.2048e-05 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 7.3759e-05 - acc: 1.0000 - val_loss: 7.1196e-05 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.7216e-05 - acc: 1.0000 - val_loss: 5.5705e-05 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_17 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 13, 13, 6)     222         input_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 1014)          0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_18 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 1022)          0           flatten_9[0][0]                  \n",
      "                                                                   input_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 32)            32736       merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 32)            1056        dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 1)             33          dense_26[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6817 - acc: 0.5824 - val_loss: 0.6817 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6530 - acc: 0.6220 - val_loss: 0.5453 - val_acc: 0.7572\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.3714 - acc: 0.8517 - val_loss: 0.2016 - val_acc: 0.9522\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1234 - acc: 0.9865 - val_loss: 0.0829 - val_acc: 0.9971\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0538 - acc: 0.9986 - val_loss: 0.0446 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0265 - acc: 0.9998 - val_loss: 0.0203 - val_acc: 0.9994\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.5967e-04 - acc: 1.0000 - val_loss: 7.3453e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.9287e-04 - acc: 1.0000 - val_loss: 5.6226e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.4880e-04 - acc: 1.0000 - val_loss: 4.3303e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.5662e-04 - acc: 1.0000 - val_loss: 3.2922e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.6536e-04 - acc: 1.0000 - val_loss: 2.6502e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.0779e-04 - acc: 1.0000 - val_loss: 2.0874e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 13, 13, 6)     222         input_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 1014)          0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 1022)          0           flatten_10[0][0]                 \n",
      "                                                                   input_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 32)            32736       merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 32)            1056        dense_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 1)             33          dense_29[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6819 - acc: 0.5819 - val_loss: 0.6835 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5567 - acc: 0.7186 - val_loss: 0.3369 - val_acc: 0.9183\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1718 - acc: 0.9839 - val_loss: 0.0809 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0481 - acc: 0.9999 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 8.8463e-04 - acc: 1.0000 - val_loss: 8.1068e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 4s - loss: 6.6626e-04 - acc: 1.0000 - val_loss: 6.1832e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.1043e-04 - acc: 1.0000 - val_loss: 4.7795e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.9608e-04 - acc: 1.0000 - val_loss: 3.7717e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.0752e-04 - acc: 1.0000 - val_loss: 2.9035e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.4215e-04 - acc: 1.0000 - val_loss: 2.2863e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.9173e-04 - acc: 1.0000 - val_loss: 1.8309e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.5206e-04 - acc: 1.0000 - val_loss: 1.4550e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.2062e-04 - acc: 1.0000 - val_loss: 1.1648e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_21 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 13, 13, 6)     222         input_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 1014)          0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 1022)          0           flatten_11[0][0]                 \n",
      "                                                                   input_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 32)            32736       merge_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 32)            1056        dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 1)             33          dense_32[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6750 - acc: 0.5905 - val_loss: 0.6194 - val_acc: 0.6869\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5094 - acc: 0.7586 - val_loss: 0.3958 - val_acc: 0.8192\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.2076 - acc: 0.9510 - val_loss: 0.1124 - val_acc: 0.9889\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0717 - acc: 0.9965 - val_loss: 0.0476 - val_acc: 0.9981\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0337 - acc: 0.9994 - val_loss: 0.0252 - val_acc: 0.9987\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0181 - acc: 0.9998 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.6922e-04 - acc: 1.0000 - val_loss: 7.8126e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 4s - loss: 5.8215e-04 - acc: 1.0000 - val_loss: 5.8512e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.3882e-04 - acc: 1.0000 - val_loss: 4.2470e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 3.3208e-04 - acc: 1.0000 - val_loss: 3.4128e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.5846e-04 - acc: 1.0000 - val_loss: 2.5047e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.9703e-04 - acc: 1.0000 - val_loss: 1.9730e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.5395e-04 - acc: 1.0000 - val_loss: 1.5237e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_23 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 13, 13, 6)     222         input_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 1014)          0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_24 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 1022)          0           flatten_12[0][0]                 \n",
      "                                                                   input_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 32)            32736       merge_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 32)            1056        dense_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 1)             33          dense_35[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6804 - acc: 0.5833 - val_loss: 0.6791 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6767 - acc: 0.5838 - val_loss: 0.6749 - val_acc: 0.5806\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6703 - acc: 0.5809 - val_loss: 0.6683 - val_acc: 0.5835\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6668 - acc: 0.5769 - val_loss: 0.6667 - val_acc: 0.5816\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6659 - acc: 0.5814 - val_loss: 0.6662 - val_acc: 0.5522\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6649 - acc: 0.5795 - val_loss: 0.6681 - val_acc: 0.5635\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6650 - acc: 0.5810 - val_loss: 0.6660 - val_acc: 0.5811\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6644 - acc: 0.5829 - val_loss: 0.6644 - val_acc: 0.5779\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6635 - acc: 0.5806 - val_loss: 0.6655 - val_acc: 0.5766\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6635 - acc: 0.5819 - val_loss: 0.6645 - val_acc: 0.5888\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6635 - acc: 0.5853 - val_loss: 0.6647 - val_acc: 0.5622\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6638 - acc: 0.5800 - val_loss: 0.6639 - val_acc: 0.5771\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6631 - acc: 0.5879 - val_loss: 0.6639 - val_acc: 0.5728\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6628 - acc: 0.5832 - val_loss: 0.6642 - val_acc: 0.5814\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6628 - acc: 0.5837 - val_loss: 0.6641 - val_acc: 0.5777\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6628 - acc: 0.5832 - val_loss: 0.6641 - val_acc: 0.5748\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6630 - acc: 0.5837 - val_loss: 0.6632 - val_acc: 0.5708\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6622 - acc: 0.5825 - val_loss: 0.6646 - val_acc: 0.5777\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6317 - acc: 0.6390 - val_loss: 0.5687 - val_acc: 0.6705\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.4665 - acc: 0.7738 - val_loss: 0.3690 - val_acc: 0.8482\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_25 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 13, 13, 6)     222         input_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 1014)          0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_26 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_13 (Merge)                 (None, 1022)          0           flatten_13[0][0]                 \n",
      "                                                                   input_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_37 (Dense)                 (None, 32)            32736       merge_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_38 (Dense)                 (None, 32)            1056        dense_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_39 (Dense)                 (None, 1)             33          dense_38[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6822 - acc: 0.5813 - val_loss: 0.6822 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6774 - acc: 0.5851 - val_loss: 0.6483 - val_acc: 0.6752\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.4328 - acc: 0.8243 - val_loss: 0.2233 - val_acc: 0.9688\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.1227 - acc: 0.9921 - val_loss: 0.0671 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.0405 - acc: 0.9998 - val_loss: 0.0268 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 4s - loss: 8.4849e-04 - acc: 1.0000 - val_loss: 8.0739e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.4260e-04 - acc: 1.0000 - val_loss: 6.0928e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.9387e-04 - acc: 1.0000 - val_loss: 4.6913e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 6s - loss: 3.8680e-04 - acc: 1.0000 - val_loss: 3.7247e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.9979e-04 - acc: 1.0000 - val_loss: 2.8734e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.3649e-04 - acc: 1.0000 - val_loss: 2.2922e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.8646e-04 - acc: 1.0000 - val_loss: 1.8262e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.4908e-04 - acc: 1.0000 - val_loss: 1.4356e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_27 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 13, 13, 6)     222         input_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 1014)          0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_28 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_14 (Merge)                 (None, 1022)          0           flatten_14[0][0]                 \n",
      "                                                                   input_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_40 (Dense)                 (None, 32)            32736       merge_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_41 (Dense)                 (None, 32)            1056        dense_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_42 (Dense)                 (None, 1)             33          dense_41[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6811 - acc: 0.5831 - val_loss: 0.6804 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6797 - acc: 0.5840 - val_loss: 0.6803 - val_acc: 0.5806\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6798 - acc: 0.5840 - val_loss: 0.6808 - val_acc: 0.5806\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6797 - acc: 0.5840 - val_loss: 0.6801 - val_acc: 0.5806\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6796 - acc: 0.5840 - val_loss: 0.6807 - val_acc: 0.5806\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6793 - acc: 0.5840 - val_loss: 0.6800 - val_acc: 0.5806\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5509 - acc: 0.7232 - val_loss: 0.2549 - val_acc: 0.9643\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0994 - acc: 0.9947 - val_loss: 0.0350 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 8.2218e-04 - acc: 1.0000 - val_loss: 7.5935e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 4s - loss: 5.8394e-04 - acc: 1.0000 - val_loss: 5.4281e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.2640e-04 - acc: 1.0000 - val_loss: 3.9789e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 3.1779e-04 - acc: 1.0000 - val_loss: 2.9836e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.3773e-04 - acc: 1.0000 - val_loss: 2.3077e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.8143e-04 - acc: 1.0000 - val_loss: 1.7480e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.4006e-04 - acc: 1.0000 - val_loss: 1.3553e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_29 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 13, 13, 6)     222         input_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 1014)          0           conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_30 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_15 (Merge)                 (None, 1022)          0           flatten_15[0][0]                 \n",
      "                                                                   input_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_43 (Dense)                 (None, 32)            32736       merge_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_44 (Dense)                 (None, 32)            1056        dense_43[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_45 (Dense)                 (None, 1)             33          dense_44[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6808 - acc: 0.5828 - val_loss: 0.6799 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6776 - acc: 0.5840 - val_loss: 0.6752 - val_acc: 0.5806\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6092 - acc: 0.6643 - val_loss: 0.5062 - val_acc: 0.7429\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.4054 - acc: 0.8199 - val_loss: 0.2422 - val_acc: 0.9361\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.1410 - acc: 0.9683 - val_loss: 0.0904 - val_acc: 0.9840\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0590 - acc: 0.9922 - val_loss: 0.0417 - val_acc: 0.9966\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0286 - acc: 0.9991 - val_loss: 0.0220 - val_acc: 0.9994\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0153 - acc: 0.9998 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.7199e-04 - acc: 1.0000 - val_loss: 7.3010e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.5966e-04 - acc: 1.0000 - val_loss: 5.5144e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.2086e-04 - acc: 1.0000 - val_loss: 4.2507e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.1424e-04 - acc: 1.0000 - val_loss: 3.1703e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.3596e-04 - acc: 1.0000 - val_loss: 2.4892e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.7816e-04 - acc: 1.0000 - val_loss: 1.7949e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_31 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 13, 13, 6)     222         input_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 1014)          0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_32 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_16 (Merge)                 (None, 1022)          0           flatten_16[0][0]                 \n",
      "                                                                   input_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_46 (Dense)                 (None, 32)            32736       merge_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_47 (Dense)                 (None, 32)            1056        dense_46[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_48 (Dense)                 (None, 1)             33          dense_47[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6818 - acc: 0.5815 - val_loss: 0.6811 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6436 - acc: 0.6302 - val_loss: 0.4897 - val_acc: 0.8011\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.2610 - acc: 0.9415 - val_loss: 0.1112 - val_acc: 0.9920\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0579 - acc: 0.9989 - val_loss: 0.0317 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 9.7413e-04 - acc: 1.0000 - val_loss: 8.8852e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.4306e-04 - acc: 1.0000 - val_loss: 6.8433e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.6968e-04 - acc: 1.0000 - val_loss: 5.2897e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.4130e-04 - acc: 1.0000 - val_loss: 4.1209e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.4593e-04 - acc: 1.0000 - val_loss: 3.2703e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.7168e-04 - acc: 1.0000 - val_loss: 2.5421e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.1474e-04 - acc: 1.0000 - val_loss: 2.0304e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.7112e-04 - acc: 1.0000 - val_loss: 1.6365e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.3561e-04 - acc: 1.0000 - val_loss: 1.2989e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_33 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 13, 13, 6)     222         input_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 1014)          0           conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_17 (Merge)                 (None, 1022)          0           flatten_17[0][0]                 \n",
      "                                                                   input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_49 (Dense)                 (None, 32)            32736       merge_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_50 (Dense)                 (None, 32)            1056        dense_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_51 (Dense)                 (None, 1)             33          dense_50[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6805 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6808 - acc: 0.5840 - val_loss: 0.6808 - val_acc: 0.5806\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6797 - acc: 0.5840 - val_loss: 0.6814 - val_acc: 0.5806\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6798 - acc: 0.5840 - val_loss: 0.6806 - val_acc: 0.5806\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6796 - acc: 0.5840 - val_loss: 0.6801 - val_acc: 0.5806\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6794 - acc: 0.5840 - val_loss: 0.6807 - val_acc: 0.5806\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6801 - acc: 0.5840 - val_loss: 0.6813 - val_acc: 0.5806\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6798 - acc: 0.5840 - val_loss: 0.6819 - val_acc: 0.5806\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6793 - acc: 0.5840 - val_loss: 0.6801 - val_acc: 0.5806\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6795 - acc: 0.5840 - val_loss: 0.6806 - val_acc: 0.5806\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6797 - acc: 0.5840 - val_loss: 0.6801 - val_acc: 0.5806\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6794 - acc: 0.5840 - val_loss: 0.6808 - val_acc: 0.5806\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6795 - acc: 0.5840 - val_loss: 0.6801 - val_acc: 0.5806\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6794 - acc: 0.5840 - val_loss: 0.6801 - val_acc: 0.5806\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6795 - acc: 0.5840 - val_loss: 0.6804 - val_acc: 0.5806\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6420 - acc: 0.6207 - val_loss: 0.4669 - val_acc: 0.7606\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.2292 - acc: 0.9337 - val_loss: 0.0941 - val_acc: 0.9920\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0494 - acc: 0.9990 - val_loss: 0.0298 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_35 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 13, 13, 6)     222         input_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 1014)          0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_36 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_18 (Merge)                 (None, 1022)          0           flatten_18[0][0]                 \n",
      "                                                                   input_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_52 (Dense)                 (None, 32)            32736       merge_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 32)            1056        dense_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 1)             33          dense_53[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6813 - acc: 0.5816 - val_loss: 0.6801 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.5396 - acc: 0.7342 - val_loss: 0.2742 - val_acc: 0.9604\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1467 - acc: 0.9892 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.0504 - acc: 0.9999 - val_loss: 0.0342 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.0219 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 8.4913e-04 - acc: 1.0000 - val_loss: 8.2807e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.2882e-04 - acc: 1.0000 - val_loss: 5.8728e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.7283e-04 - acc: 1.0000 - val_loss: 4.4233e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 4s - loss: 3.6333e-04 - acc: 1.0000 - val_loss: 3.4045e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.8127e-04 - acc: 1.0000 - val_loss: 2.6799e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.1866e-04 - acc: 1.0000 - val_loss: 2.0323e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.7229e-04 - acc: 1.0000 - val_loss: 1.6344e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.3635e-04 - acc: 1.0000 - val_loss: 1.2962e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.0802e-04 - acc: 1.0000 - val_loss: 1.0359e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_37 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 13, 13, 6)     222         input_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)             (None, 1014)          0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_38 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_19 (Merge)                 (None, 1022)          0           flatten_19[0][0]                 \n",
      "                                                                   input_38[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 32)            32736       merge_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 32)            1056        dense_55[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 1)             33          dense_56[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6814 - acc: 0.5803 - val_loss: 0.6766 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.4696 - acc: 0.7888 - val_loss: 0.2341 - val_acc: 0.9620\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1414 - acc: 0.9860 - val_loss: 0.0837 - val_acc: 0.9981\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0556 - acc: 0.9995 - val_loss: 0.0345 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0246 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 9.7924e-04 - acc: 1.0000 - val_loss: 8.9490e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 4s - loss: 7.2939e-04 - acc: 1.0000 - val_loss: 6.9355e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 4s - loss: 5.5040e-04 - acc: 1.0000 - val_loss: 5.0947e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 4s - loss: 4.2241e-04 - acc: 1.0000 - val_loss: 3.8829e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 3.2388e-04 - acc: 1.0000 - val_loss: 3.0197e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.5184e-04 - acc: 1.0000 - val_loss: 2.4088e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.9838e-04 - acc: 1.0000 - val_loss: 1.9406e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.5684e-04 - acc: 1.0000 - val_loss: 1.4693e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.2399e-04 - acc: 1.0000 - val_loss: 1.1815e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_39 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 13, 13, 6)     222         input_39[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)             (None, 1014)          0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_40 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_20 (Merge)                 (None, 1022)          0           flatten_20[0][0]                 \n",
      "                                                                   input_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_58 (Dense)                 (None, 32)            32736       merge_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 32)            1056        dense_58[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 1)             33          dense_59[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6812 - acc: 0.5834 - val_loss: 0.6808 - val_acc: 0.5806\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6799 - acc: 0.5840 - val_loss: 0.6820 - val_acc: 0.5806\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6796 - acc: 0.5840 - val_loss: 0.6792 - val_acc: 0.5806\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.4854 - acc: 0.7712 - val_loss: 0.2121 - val_acc: 0.9639\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.1044 - acc: 0.9922 - val_loss: 0.0526 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0304 - acc: 0.9998 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 5s - loss: 8.4748e-04 - acc: 1.0000 - val_loss: 8.0483e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 4s - loss: 6.2873e-04 - acc: 1.0000 - val_loss: 5.8718e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.7402e-04 - acc: 1.0000 - val_loss: 4.4776e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.6082e-04 - acc: 1.0000 - val_loss: 3.3688e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.7792e-04 - acc: 1.0000 - val_loss: 2.6406e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.1529e-04 - acc: 1.0000 - val_loss: 2.0411e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.6839e-04 - acc: 1.0000 - val_loss: 1.5974e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.3227e-04 - acc: 1.0000 - val_loss: 1.3045e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_41 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 13, 13, 6)     222         input_41[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 1014)          0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_42 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_21 (Merge)                 (None, 1022)          0           flatten_21[0][0]                 \n",
      "                                                                   input_42[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_61 (Dense)                 (None, 32)            32736       merge_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_62 (Dense)                 (None, 32)            1056        dense_61[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_63 (Dense)                 (None, 1)             33          dense_62[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 5s - loss: 0.6771 - acc: 0.5818 - val_loss: 0.6389 - val_acc: 0.6595\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.4825 - acc: 0.7621 - val_loss: 0.3488 - val_acc: 0.8804\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1958 - acc: 0.9541 - val_loss: 0.1060 - val_acc: 0.9904\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0603 - acc: 0.9981 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 8.2630e-04 - acc: 1.0000 - val_loss: 7.6280e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.1525e-04 - acc: 1.0000 - val_loss: 5.7710e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.5992e-04 - acc: 1.0000 - val_loss: 4.5241e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.5290e-04 - acc: 1.0000 - val_loss: 3.3461e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.7021e-04 - acc: 1.0000 - val_loss: 2.5771e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 4s - loss: 2.0939e-04 - acc: 1.0000 - val_loss: 1.9793e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.6297e-04 - acc: 1.0000 - val_loss: 1.7316e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 4s - loss: 1.2801e-04 - acc: 1.0000 - val_loss: 1.1987e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 4s - loss: 9.9955e-05 - acc: 1.0000 - val_loss: 9.5869e-05 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_exper= 20\n",
    "epochs=20\n",
    "info = np.zeros((num_exper,4,epochs))\n",
    "for i in range(num_exper):\n",
    "    c,x,z = createLayers(rest_size,conv_size,naction)\n",
    "\n",
    "    allo_classifier = Model(inputs=[c,x],outputs=z)\n",
    "\n",
    "    allo_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    allo_classifier.summary()\n",
    "\n",
    "    allo_history = allo_classifier.fit([cnn_input,rest_input],\n",
    "                                       y,epochs=epochs,batch_size=64,validation_split=0.2)\n",
    "    \n",
    "    info[i,0,:] = allo_history.history['val_loss']\n",
    "    info[i,1,:] = allo_history.history['val_acc']\n",
    "    info[i,2,:] = allo_history.history['loss']\n",
    "    info[i,3,:] = allo_history.history['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ego centric decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26400, 11, 21, 3) (26400, 4) (26400, 1)\n",
      "(11, 21, 3) 5 (4,)\n"
     ]
    }
   ],
   "source": [
    "cnn_input,rest_input,y,conv_size,rest_size = Get_dataset(Ego=True)\n",
    "print(cnn_input.shape,rest_input.shape,y.shape)\n",
    "print(conv_size,naction,rest_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpc/home/labash/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_45 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 11, 21, 6)     168         input_45[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)             (None, 1386)          0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_46 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_23 (Merge)                 (None, 1390)          0           flatten_23[0][0]                 \n",
      "                                                                   input_46[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_67 (Dense)                 (None, 32)            44512       merge_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_68 (Dense)                 (None, 32)            1056        dense_67[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_69 (Dense)                 (None, 1)             33          dense_68[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6821 - acc: 0.5802 - val_loss: 0.6800 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6815 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6797 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6556 - acc: 0.6137 - val_loss: 0.5181 - val_acc: 0.7612\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.4208 - acc: 0.7691 - val_loss: 0.3829 - val_acc: 0.7585\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3702 - acc: 0.7737 - val_loss: 0.3681 - val_acc: 0.7818\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3578 - acc: 0.7814 - val_loss: 0.3534 - val_acc: 0.7830\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3498 - acc: 0.7891 - val_loss: 0.3454 - val_acc: 0.7966\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3332 - acc: 0.8110 - val_loss: 0.3205 - val_acc: 0.8241\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.2798 - acc: 0.8765 - val_loss: 0.2316 - val_acc: 0.9064\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.1577 - acc: 0.9556 - val_loss: 0.1088 - val_acc: 0.9786\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0704 - acc: 0.9880 - val_loss: 0.0579 - val_acc: 0.9879\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0382 - acc: 0.9949 - val_loss: 0.0347 - val_acc: 0.9949\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0234 - acc: 0.9980 - val_loss: 0.0242 - val_acc: 0.9958\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0150 - acc: 0.9991 - val_loss: 0.0167 - val_acc: 0.9973\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0094 - acc: 0.9997 - val_loss: 0.0129 - val_acc: 0.9981\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0070 - acc: 0.9997 - val_loss: 0.0101 - val_acc: 0.9987\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0047 - acc: 0.9999 - val_loss: 0.0060 - val_acc: 0.9992\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9994\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9996\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_47 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 11, 21, 6)     168         input_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)             (None, 1386)          0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_48 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_24 (Merge)                 (None, 1390)          0           flatten_24[0][0]                 \n",
      "                                                                   input_48[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_70 (Dense)                 (None, 32)            44512       merge_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_71 (Dense)                 (None, 32)            1056        dense_70[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_72 (Dense)                 (None, 1)             33          dense_71[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6807 - acc: 0.5826 - val_loss: 0.6800 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6795 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6767 - acc: 0.5831 - val_loss: 0.6732 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6708 - acc: 0.5813 - val_loss: 0.6740 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6667 - acc: 0.5822 - val_loss: 0.6682 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6641 - acc: 0.5802 - val_loss: 0.6699 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6638 - acc: 0.5827 - val_loss: 0.6696 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6630 - acc: 0.5819 - val_loss: 0.6707 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6629 - acc: 0.5796 - val_loss: 0.6704 - val_acc: 0.5841\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6624 - acc: 0.5816 - val_loss: 0.6701 - val_acc: 0.5841\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6625 - acc: 0.5817 - val_loss: 0.6726 - val_acc: 0.5841\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6619 - acc: 0.5816 - val_loss: 0.6717 - val_acc: 0.5841\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6620 - acc: 0.5810 - val_loss: 0.6706 - val_acc: 0.5841\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6620 - acc: 0.5820 - val_loss: 0.6732 - val_acc: 0.5841\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6618 - acc: 0.5821 - val_loss: 0.6713 - val_acc: 0.5841\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6617 - acc: 0.5826 - val_loss: 0.6711 - val_acc: 0.5841\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6619 - acc: 0.5827 - val_loss: 0.6718 - val_acc: 0.5841\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6620 - acc: 0.5812 - val_loss: 0.6742 - val_acc: 0.5841\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6619 - acc: 0.5816 - val_loss: 0.6740 - val_acc: 0.5841\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6618 - acc: 0.5803 - val_loss: 0.6733 - val_acc: 0.5841\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_49 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 11, 21, 6)     168         input_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 1386)          0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_50 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_25 (Merge)                 (None, 1390)          0           flatten_25[0][0]                 \n",
      "                                                                   input_50[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_73 (Dense)                 (None, 32)            44512       merge_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_74 (Dense)                 (None, 32)            1056        dense_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_75 (Dense)                 (None, 1)             33          dense_74[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6823 - acc: 0.5798 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6804 - acc: 0.5830 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6802 - acc: 0.5831 - val_loss: 0.6787 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.5835 - acc: 0.6810 - val_loss: 0.4568 - val_acc: 0.7428\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.4067 - acc: 0.7721 - val_loss: 0.3792 - val_acc: 0.7682\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3700 - acc: 0.7812 - val_loss: 0.3589 - val_acc: 0.7915\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3539 - acc: 0.7959 - val_loss: 0.3412 - val_acc: 0.8045\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3298 - acc: 0.8214 - val_loss: 0.3063 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.2635 - acc: 0.8879 - val_loss: 0.2038 - val_acc: 0.9324\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.1430 - acc: 0.9620 - val_loss: 0.0936 - val_acc: 0.9814\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0671 - acc: 0.9871 - val_loss: 0.0670 - val_acc: 0.9765\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0367 - acc: 0.9952 - val_loss: 0.0318 - val_acc: 0.9962\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0226 - acc: 0.9982 - val_loss: 0.0261 - val_acc: 0.9939\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0143 - acc: 0.9990 - val_loss: 0.0136 - val_acc: 0.9987\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0130 - acc: 0.9985 - val_loss: 0.0117 - val_acc: 0.9981\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0068 - acc: 0.9998 - val_loss: 0.0076 - val_acc: 0.9991\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9987\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9992\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9991\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9991\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_51 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 11, 21, 6)     168         input_51[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)             (None, 1386)          0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_52 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_26 (Merge)                 (None, 1390)          0           flatten_26[0][0]                 \n",
      "                                                                   input_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_76 (Dense)                 (None, 32)            44512       merge_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_77 (Dense)                 (None, 32)            1056        dense_76[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_78 (Dense)                 (None, 1)             33          dense_77[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6817 - acc: 0.5817 - val_loss: 0.6803 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6803 - acc: 0.5831 - val_loss: 0.6798 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6796 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6556 - acc: 0.6187 - val_loss: 0.5598 - val_acc: 0.7519\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.4983 - acc: 0.7437 - val_loss: 0.4286 - val_acc: 0.7742\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.4037 - acc: 0.7729 - val_loss: 0.3819 - val_acc: 0.7866\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3766 - acc: 0.7798 - val_loss: 0.3666 - val_acc: 0.7727\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3620 - acc: 0.7850 - val_loss: 0.3568 - val_acc: 0.7871\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3553 - acc: 0.7880 - val_loss: 0.3535 - val_acc: 0.7809\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3500 - acc: 0.7889 - val_loss: 0.3464 - val_acc: 0.7953\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3474 - acc: 0.7891 - val_loss: 0.3495 - val_acc: 0.7775\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3425 - acc: 0.7927 - val_loss: 0.3374 - val_acc: 0.7956\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3140 - acc: 0.8291 - val_loss: 0.2672 - val_acc: 0.8712\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.1895 - acc: 0.9345 - val_loss: 0.1354 - val_acc: 0.9689\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0943 - acc: 0.9797 - val_loss: 0.0825 - val_acc: 0.9782\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0545 - acc: 0.9927 - val_loss: 0.0478 - val_acc: 0.9932\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0356 - acc: 0.9973 - val_loss: 0.0336 - val_acc: 0.9964\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0246 - acc: 0.9983 - val_loss: 0.0256 - val_acc: 0.9973\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0161 - acc: 0.9998 - val_loss: 0.0149 - val_acc: 0.9992\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_53 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 11, 21, 6)     168         input_53[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)             (None, 1386)          0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_54 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_27 (Merge)                 (None, 1390)          0           flatten_27[0][0]                 \n",
      "                                                                   input_54[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_79 (Dense)                 (None, 32)            44512       merge_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_80 (Dense)                 (None, 32)            1056        dense_79[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_81 (Dense)                 (None, 1)             33          dense_80[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6808 - acc: 0.5828 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6797 - acc: 0.5831 - val_loss: 0.6795 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6788 - acc: 0.5831 - val_loss: 0.6780 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6733 - acc: 0.5830 - val_loss: 0.6726 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6689 - acc: 0.5824 - val_loss: 0.6730 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6667 - acc: 0.5811 - val_loss: 0.6742 - val_acc: 0.5839\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6654 - acc: 0.5829 - val_loss: 0.6747 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6646 - acc: 0.5832 - val_loss: 0.6752 - val_acc: 0.5650\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6636 - acc: 0.5809 - val_loss: 0.6755 - val_acc: 0.5841\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6631 - acc: 0.5811 - val_loss: 0.6736 - val_acc: 0.5841\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6629 - acc: 0.5818 - val_loss: 0.6726 - val_acc: 0.5835\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6626 - acc: 0.5803 - val_loss: 0.6732 - val_acc: 0.5833\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6622 - acc: 0.5815 - val_loss: 0.6752 - val_acc: 0.5830\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6626 - acc: 0.5798 - val_loss: 0.6740 - val_acc: 0.5833\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6617 - acc: 0.5809 - val_loss: 0.6763 - val_acc: 0.5485\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6622 - acc: 0.5801 - val_loss: 0.6762 - val_acc: 0.5826\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6615 - acc: 0.5821 - val_loss: 0.6741 - val_acc: 0.5839\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6616 - acc: 0.5815 - val_loss: 0.6754 - val_acc: 0.5833\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6620 - acc: 0.5812 - val_loss: 0.6742 - val_acc: 0.5835\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6614 - acc: 0.5804 - val_loss: 0.6749 - val_acc: 0.5839\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_55 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 11, 21, 6)     168         input_55[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)             (None, 1386)          0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_56 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_28 (Merge)                 (None, 1390)          0           flatten_28[0][0]                 \n",
      "                                                                   input_56[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_82 (Dense)                 (None, 32)            44512       merge_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_83 (Dense)                 (None, 32)            1056        dense_82[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_84 (Dense)                 (None, 1)             33          dense_83[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6855 - acc: 0.5764 - val_loss: 0.6819 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6815 - acc: 0.5823 - val_loss: 0.6802 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6808 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6804 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6802 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6801 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6804 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6795 - val_acc: 0.5841\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6815 - val_acc: 0.5841\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6801 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6797 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6796 - acc: 0.5831 - val_loss: 0.6799 - val_acc: 0.5841\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6797 - acc: 0.5831 - val_loss: 0.6790 - val_acc: 0.5841\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6796 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6797 - acc: 0.5831 - val_loss: 0.6797 - val_acc: 0.5841\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_57 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 11, 21, 6)     168         input_57[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)             (None, 1386)          0           conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_58 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_29 (Merge)                 (None, 1390)          0           flatten_29[0][0]                 \n",
      "                                                                   input_58[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_85 (Dense)                 (None, 32)            44512       merge_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_86 (Dense)                 (None, 32)            1056        dense_85[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_87 (Dense)                 (None, 1)             33          dense_86[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6829 - acc: 0.5787 - val_loss: 0.6855 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6809 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6802 - acc: 0.5831 - val_loss: 0.6797 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6803 - acc: 0.5831 - val_loss: 0.6801 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6805 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6804 - acc: 0.5831 - val_loss: 0.6795 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6800 - acc: 0.5831 - val_loss: 0.6787 - val_acc: 0.5841\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6802 - acc: 0.5831 - val_loss: 0.6812 - val_acc: 0.5841\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6789 - val_acc: 0.5841\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.5208 - acc: 0.7147 - val_loss: 0.4072 - val_acc: 0.7799\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3788 - acc: 0.7848 - val_loss: 0.3558 - val_acc: 0.7968\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3315 - acc: 0.8166 - val_loss: 0.3145 - val_acc: 0.8259\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.2463 - acc: 0.8961 - val_loss: 0.1918 - val_acc: 0.9339\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.1275 - acc: 0.9670 - val_loss: 0.0938 - val_acc: 0.9788\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0683 - acc: 0.9857 - val_loss: 0.0589 - val_acc: 0.9839\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0412 - acc: 0.9940 - val_loss: 0.0411 - val_acc: 0.9884\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0285 - acc: 0.9962 - val_loss: 0.0273 - val_acc: 0.9956\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_59 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 11, 21, 6)     168         input_59[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)             (None, 1386)          0           conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_60 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_30 (Merge)                 (None, 1390)          0           flatten_30[0][0]                 \n",
      "                                                                   input_60[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_88 (Dense)                 (None, 32)            44512       merge_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_89 (Dense)                 (None, 32)            1056        dense_88[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_90 (Dense)                 (None, 1)             33          dense_89[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6830 - acc: 0.5779 - val_loss: 0.6840 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6808 - acc: 0.5831 - val_loss: 0.6801 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6805 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6806 - acc: 0.5831 - val_loss: 0.6801 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6804 - acc: 0.5831 - val_loss: 0.6790 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6805 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6797 - acc: 0.5831 - val_loss: 0.6792 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6800 - acc: 0.5831 - val_loss: 0.6790 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6800 - acc: 0.5831 - val_loss: 0.6790 - val_acc: 0.5841\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6797 - acc: 0.5831 - val_loss: 0.6787 - val_acc: 0.5841\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.5288 - acc: 0.7084 - val_loss: 0.4042 - val_acc: 0.7506\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3770 - acc: 0.7837 - val_loss: 0.3495 - val_acc: 0.8098\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3246 - acc: 0.8330 - val_loss: 0.3070 - val_acc: 0.8242\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.1745 - acc: 0.9466 - val_loss: 0.1045 - val_acc: 0.9831\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0641 - acc: 0.9917 - val_loss: 0.0447 - val_acc: 0.9958\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0305 - acc: 0.9974 - val_loss: 0.0262 - val_acc: 0.9972\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0160 - acc: 0.9995 - val_loss: 0.0177 - val_acc: 0.9975\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0106 - acc: 0.9994 - val_loss: 0.0112 - val_acc: 0.9983\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0068 - acc: 0.9998 - val_loss: 0.0081 - val_acc: 0.9991\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9991\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_61 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 11, 21, 6)     168         input_61[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)             (None, 1386)          0           conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_62 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_31 (Merge)                 (None, 1390)          0           flatten_31[0][0]                 \n",
      "                                                                   input_62[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_91 (Dense)                 (None, 32)            44512       merge_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_92 (Dense)                 (None, 32)            1056        dense_91[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_93 (Dense)                 (None, 1)             33          dense_92[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 6s - loss: 0.6832 - acc: 0.5795 - val_loss: 0.6806 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6793 - acc: 0.5831 - val_loss: 0.6735 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.5445 - acc: 0.7071 - val_loss: 0.4313 - val_acc: 0.7777\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3917 - acc: 0.7803 - val_loss: 0.3606 - val_acc: 0.7949\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3489 - acc: 0.8085 - val_loss: 0.3323 - val_acc: 0.8246\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.2637 - acc: 0.8984 - val_loss: 0.1900 - val_acc: 0.9506\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.1311 - acc: 0.9724 - val_loss: 0.0897 - val_acc: 0.9867\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0628 - acc: 0.9915 - val_loss: 0.0454 - val_acc: 0.9977\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0338 - acc: 0.9974 - val_loss: 0.0295 - val_acc: 0.9975\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0221 - acc: 0.9981 - val_loss: 0.0215 - val_acc: 0.9975\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0176 - acc: 0.9984 - val_loss: 0.0174 - val_acc: 0.9987\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0105 - acc: 0.9994 - val_loss: 0.0097 - val_acc: 0.9994\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9994\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9985\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0147 - acc: 0.9957 - val_loss: 0.0072 - val_acc: 0.9989\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0040 - acc: 0.9998 - val_loss: 0.0043 - val_acc: 0.9994\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9994\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9994\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9994\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9994\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_63 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 11, 21, 6)     168         input_63[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)             (None, 1386)          0           conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_64 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_32 (Merge)                 (None, 1390)          0           flatten_32[0][0]                 \n",
      "                                                                   input_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_94 (Dense)                 (None, 32)            44512       merge_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_95 (Dense)                 (None, 32)            1056        dense_94[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_96 (Dense)                 (None, 1)             33          dense_95[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6821 - acc: 0.5775 - val_loss: 0.6805 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6797 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6795 - acc: 0.5831 - val_loss: 0.6779 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6190 - acc: 0.6655 - val_loss: 0.5266 - val_acc: 0.7515\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.4483 - acc: 0.7693 - val_loss: 0.3874 - val_acc: 0.7881\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3069 - acc: 0.8736 - val_loss: 0.2257 - val_acc: 0.9210\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.1494 - acc: 0.9667 - val_loss: 0.0967 - val_acc: 0.9867\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0709 - acc: 0.9896 - val_loss: 0.0569 - val_acc: 0.9900\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0418 - acc: 0.9950 - val_loss: 0.0370 - val_acc: 0.9936\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0298 - acc: 0.9948 - val_loss: 0.0348 - val_acc: 0.9922\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0185 - acc: 0.9983 - val_loss: 0.0232 - val_acc: 0.9951\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0132 - acc: 0.9990 - val_loss: 0.0207 - val_acc: 0.9949\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0109 - acc: 0.9989 - val_loss: 0.0289 - val_acc: 0.9871\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0089 - acc: 0.9990 - val_loss: 0.0105 - val_acc: 0.9989\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0052 - acc: 0.9999 - val_loss: 0.0074 - val_acc: 0.9987\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0045 - acc: 0.9997 - val_loss: 0.0076 - val_acc: 0.9981\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0093 - val_acc: 0.9975\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0035 - acc: 0.9999 - val_loss: 0.0043 - val_acc: 0.9991\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9989\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9989\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_65 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 11, 21, 6)     168         input_65[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)             (None, 1386)          0           conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_66 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_33 (Merge)                 (None, 1390)          0           flatten_33[0][0]                 \n",
      "                                                                   input_66[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_97 (Dense)                 (None, 32)            44512       merge_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_98 (Dense)                 (None, 32)            1056        dense_97[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_99 (Dense)                 (None, 1)             33          dense_98[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6806 - acc: 0.5829 - val_loss: 0.6799 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6791 - acc: 0.5831 - val_loss: 0.6787 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6768 - acc: 0.5831 - val_loss: 0.6749 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6721 - acc: 0.5821 - val_loss: 0.6752 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6697 - acc: 0.5821 - val_loss: 0.6766 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6679 - acc: 0.5823 - val_loss: 0.6735 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6666 - acc: 0.5811 - val_loss: 0.6715 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6659 - acc: 0.5806 - val_loss: 0.6714 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6654 - acc: 0.5830 - val_loss: 0.6711 - val_acc: 0.5841\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6652 - acc: 0.5827 - val_loss: 0.6719 - val_acc: 0.5841\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6657 - acc: 0.5821 - val_loss: 0.6721 - val_acc: 0.5839\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6650 - acc: 0.5815 - val_loss: 0.6728 - val_acc: 0.5841\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6651 - acc: 0.5821 - val_loss: 0.6712 - val_acc: 0.5841\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6647 - acc: 0.5825 - val_loss: 0.6706 - val_acc: 0.5841\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6646 - acc: 0.5835 - val_loss: 0.6711 - val_acc: 0.5841\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6641 - acc: 0.5823 - val_loss: 0.6726 - val_acc: 0.5693\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6647 - acc: 0.5816 - val_loss: 0.6726 - val_acc: 0.5841\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6643 - acc: 0.5832 - val_loss: 0.6705 - val_acc: 0.5839\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6642 - acc: 0.5825 - val_loss: 0.6726 - val_acc: 0.5792\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6642 - acc: 0.5812 - val_loss: 0.6716 - val_acc: 0.5839\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_67 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 11, 21, 6)     168         input_67[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)             (None, 1386)          0           conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_68 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_34 (Merge)                 (None, 1390)          0           flatten_34[0][0]                 \n",
      "                                                                   input_68[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_100 (Dense)                (None, 32)            44512       merge_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_101 (Dense)                (None, 32)            1056        dense_100[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_102 (Dense)                (None, 1)             33          dense_101[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6821 - acc: 0.5799 - val_loss: 0.6796 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6795 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6785 - acc: 0.5831 - val_loss: 0.6773 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6729 - acc: 0.5831 - val_loss: 0.6741 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6684 - acc: 0.5812 - val_loss: 0.6760 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6657 - acc: 0.5806 - val_loss: 0.6725 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6642 - acc: 0.5798 - val_loss: 0.6734 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6631 - acc: 0.5791 - val_loss: 0.6734 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6630 - acc: 0.5807 - val_loss: 0.6730 - val_acc: 0.5841\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6625 - acc: 0.5823 - val_loss: 0.6759 - val_acc: 0.5837\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6620 - acc: 0.5808 - val_loss: 0.6739 - val_acc: 0.5841\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6620 - acc: 0.5804 - val_loss: 0.6734 - val_acc: 0.5841\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6623 - acc: 0.5812 - val_loss: 0.6738 - val_acc: 0.5839\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6620 - acc: 0.5808 - val_loss: 0.6732 - val_acc: 0.5839\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6618 - acc: 0.5829 - val_loss: 0.6786 - val_acc: 0.5841\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6622 - acc: 0.5821 - val_loss: 0.6736 - val_acc: 0.5839\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6613 - acc: 0.5829 - val_loss: 0.6739 - val_acc: 0.5841\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6616 - acc: 0.5804 - val_loss: 0.6744 - val_acc: 0.5759\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6614 - acc: 0.5804 - val_loss: 0.6731 - val_acc: 0.5839\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6614 - acc: 0.5796 - val_loss: 0.6756 - val_acc: 0.5841\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_69 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 11, 21, 6)     168         input_69[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)             (None, 1386)          0           conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_70 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_35 (Merge)                 (None, 1390)          0           flatten_35[0][0]                 \n",
      "                                                                   input_70[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_103 (Dense)                (None, 32)            44512       merge_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_104 (Dense)                (None, 32)            1056        dense_103[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_105 (Dense)                (None, 1)             33          dense_104[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 6s - loss: 0.6833 - acc: 0.5798 - val_loss: 0.6797 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6812 - acc: 0.5823 - val_loss: 0.6797 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6809 - acc: 0.5831 - val_loss: 0.6834 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6776 - acc: 0.5835 - val_loss: 0.6525 - val_acc: 0.6199\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.5055 - acc: 0.7345 - val_loss: 0.3997 - val_acc: 0.7835\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3827 - acc: 0.7806 - val_loss: 0.3652 - val_acc: 0.8000\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3546 - acc: 0.7985 - val_loss: 0.3464 - val_acc: 0.7962\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.2989 - acc: 0.8618 - val_loss: 0.2328 - val_acc: 0.9367\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.1483 - acc: 0.9690 - val_loss: 0.0962 - val_acc: 0.9792\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0598 - acc: 0.9941 - val_loss: 0.0521 - val_acc: 0.9936\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0298 - acc: 0.9987 - val_loss: 0.0268 - val_acc: 0.9977\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0175 - acc: 0.9995 - val_loss: 0.0179 - val_acc: 0.9992\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0108 - acc: 0.9999 - val_loss: 0.0123 - val_acc: 0.9994\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0072 - acc: 0.9999 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9996\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0192 - val_acc: 0.9930\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0048 - acc: 0.9989 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9996\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_71 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 11, 21, 6)     168         input_71[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)             (None, 1386)          0           conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_72 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_36 (Merge)                 (None, 1390)          0           flatten_36[0][0]                 \n",
      "                                                                   input_72[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_106 (Dense)                (None, 32)            44512       merge_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_107 (Dense)                (None, 32)            1056        dense_106[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_108 (Dense)                (None, 1)             33          dense_107[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6828 - acc: 0.5789 - val_loss: 0.6809 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6808 - acc: 0.5831 - val_loss: 0.6809 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6798 - acc: 0.5831 - val_loss: 0.6799 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6771 - acc: 0.5837 - val_loss: 0.6594 - val_acc: 0.5987\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.5709 - acc: 0.7064 - val_loss: 0.4957 - val_acc: 0.7339\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.4333 - acc: 0.7652 - val_loss: 0.3965 - val_acc: 0.7816\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3779 - acc: 0.7816 - val_loss: 0.3624 - val_acc: 0.7877\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3579 - acc: 0.7845 - val_loss: 0.3534 - val_acc: 0.7843\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3479 - acc: 0.7890 - val_loss: 0.3475 - val_acc: 0.7858\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3404 - acc: 0.7930 - val_loss: 0.3422 - val_acc: 0.7934\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3291 - acc: 0.8095 - val_loss: 0.3335 - val_acc: 0.8159\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.2971 - acc: 0.8551 - val_loss: 0.2718 - val_acc: 0.8926\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.2076 - acc: 0.9305 - val_loss: 0.1577 - val_acc: 0.9561\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.1252 - acc: 0.9615 - val_loss: 0.1034 - val_acc: 0.9680\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0784 - acc: 0.9809 - val_loss: 0.0717 - val_acc: 0.9809\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0537 - acc: 0.9894 - val_loss: 0.0489 - val_acc: 0.9924\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0388 - acc: 0.9936 - val_loss: 0.0402 - val_acc: 0.9902\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0329 - acc: 0.9937 - val_loss: 0.0314 - val_acc: 0.9938\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0234 - acc: 0.9966 - val_loss: 0.0410 - val_acc: 0.9869\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0223 - acc: 0.9958 - val_loss: 0.0195 - val_acc: 0.9983\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_73 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 11, 21, 6)     168         input_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)             (None, 1386)          0           conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_74 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_37 (Merge)                 (None, 1390)          0           flatten_37[0][0]                 \n",
      "                                                                   input_74[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_109 (Dense)                (None, 32)            44512       merge_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_110 (Dense)                (None, 32)            1056        dense_109[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_111 (Dense)                (None, 1)             33          dense_110[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 6s - loss: 0.6814 - acc: 0.5832 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6800 - acc: 0.5831 - val_loss: 0.6800 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6795 - acc: 0.5831 - val_loss: 0.6795 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6790 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6355 - acc: 0.6439 - val_loss: 0.5544 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.5046 - acc: 0.7394 - val_loss: 0.4341 - val_acc: 0.7691\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.4013 - acc: 0.7733 - val_loss: 0.3772 - val_acc: 0.7663\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3634 - acc: 0.7853 - val_loss: 0.3580 - val_acc: 0.7777\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3488 - acc: 0.7924 - val_loss: 0.3456 - val_acc: 0.7818\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3378 - acc: 0.7967 - val_loss: 0.3371 - val_acc: 0.7998\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3108 - acc: 0.8338 - val_loss: 0.2833 - val_acc: 0.8746\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.1943 - acc: 0.9420 - val_loss: 0.1307 - val_acc: 0.9699\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0822 - acc: 0.9843 - val_loss: 0.0635 - val_acc: 0.9896\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0452 - acc: 0.9940 - val_loss: 0.0412 - val_acc: 0.9922\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0300 - acc: 0.9974 - val_loss: 0.0307 - val_acc: 0.9951\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0216 - acc: 0.9985 - val_loss: 0.0229 - val_acc: 0.9970\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0153 - acc: 0.9991 - val_loss: 0.0184 - val_acc: 0.9981\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0134 - acc: 0.9986 - val_loss: 0.0141 - val_acc: 0.9989\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0084 - acc: 0.9999 - val_loss: 0.0121 - val_acc: 0.9985\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0068 - acc: 0.9999 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_75 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 11, 21, 6)     168         input_75[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)             (None, 1386)          0           conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_76 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_38 (Merge)                 (None, 1390)          0           flatten_38[0][0]                 \n",
      "                                                                   input_76[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_112 (Dense)                (None, 32)            44512       merge_38[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_113 (Dense)                (None, 32)            1056        dense_112[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_114 (Dense)                (None, 1)             33          dense_113[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6818 - acc: 0.5823 - val_loss: 0.6799 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6800 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6794 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6795 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6791 - acc: 0.5831 - val_loss: 0.6786 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6766 - acc: 0.5831 - val_loss: 0.6754 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6707 - acc: 0.5815 - val_loss: 0.6740 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6678 - acc: 0.5801 - val_loss: 0.6735 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6657 - acc: 0.5802 - val_loss: 0.6743 - val_acc: 0.5551\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6656 - acc: 0.5785 - val_loss: 0.6721 - val_acc: 0.5773\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6643 - acc: 0.5797 - val_loss: 0.6750 - val_acc: 0.5830\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6639 - acc: 0.5804 - val_loss: 0.6701 - val_acc: 0.5858\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6627 - acc: 0.5836 - val_loss: 0.6741 - val_acc: 0.5841\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6631 - acc: 0.5836 - val_loss: 0.6692 - val_acc: 0.5841\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6628 - acc: 0.5842 - val_loss: 0.6698 - val_acc: 0.5841\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6620 - acc: 0.5821 - val_loss: 0.6694 - val_acc: 0.5837\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6624 - acc: 0.5825 - val_loss: 0.6703 - val_acc: 0.5837\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6622 - acc: 0.5810 - val_loss: 0.6695 - val_acc: 0.5837\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6620 - acc: 0.5823 - val_loss: 0.6692 - val_acc: 0.5839\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6619 - acc: 0.5820 - val_loss: 0.6702 - val_acc: 0.5837\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_77 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 11, 21, 6)     168         input_77[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)             (None, 1386)          0           conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_78 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_39 (Merge)                 (None, 1390)          0           flatten_39[0][0]                 \n",
      "                                                                   input_78[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_115 (Dense)                (None, 32)            44512       merge_39[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_116 (Dense)                (None, 32)            1056        dense_115[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_117 (Dense)                (None, 1)             33          dense_116[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6829 - acc: 0.5795 - val_loss: 0.6796 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6794 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6804 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6793 - acc: 0.5831 - val_loss: 0.6757 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6027 - acc: 0.6793 - val_loss: 0.5251 - val_acc: 0.7428\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.4671 - acc: 0.7519 - val_loss: 0.4093 - val_acc: 0.7820\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3957 - acc: 0.7749 - val_loss: 0.3738 - val_acc: 0.7955\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3673 - acc: 0.7842 - val_loss: 0.3600 - val_acc: 0.7883\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3557 - acc: 0.7896 - val_loss: 0.3514 - val_acc: 0.7892\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.3335 - acc: 0.8102 - val_loss: 0.3206 - val_acc: 0.8136\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.2709 - acc: 0.8727 - val_loss: 0.2126 - val_acc: 0.9337\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.1525 - acc: 0.9583 - val_loss: 0.1130 - val_acc: 0.9742\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0796 - acc: 0.9848 - val_loss: 0.0807 - val_acc: 0.9720\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0466 - acc: 0.9940 - val_loss: 0.0382 - val_acc: 0.9956\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0300 - acc: 0.9976 - val_loss: 0.0277 - val_acc: 0.9964\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0218 - acc: 0.9979 - val_loss: 0.0225 - val_acc: 0.9972\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0157 - acc: 0.9988 - val_loss: 0.0246 - val_acc: 0.9943\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0130 - acc: 0.9987 - val_loss: 0.0182 - val_acc: 0.9958\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0096 - acc: 0.9990 - val_loss: 0.0109 - val_acc: 0.9991\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0065 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9987\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_79 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 11, 21, 6)     168         input_79[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)             (None, 1386)          0           conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_80 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_40 (Merge)                 (None, 1390)          0           flatten_40[0][0]                 \n",
      "                                                                   input_80[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_118 (Dense)                (None, 32)            44512       merge_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_119 (Dense)                (None, 32)            1056        dense_118[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_120 (Dense)                (None, 1)             33          dense_119[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6825 - acc: 0.5808 - val_loss: 0.6801 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6802 - acc: 0.5831 - val_loss: 0.6788 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6144 - acc: 0.6624 - val_loss: 0.4902 - val_acc: 0.7534\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.4182 - acc: 0.7807 - val_loss: 0.3723 - val_acc: 0.8121\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3483 - acc: 0.8327 - val_loss: 0.2982 - val_acc: 0.8771\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.2234 - acc: 0.9181 - val_loss: 0.1543 - val_acc: 0.9581\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.1143 - acc: 0.9731 - val_loss: 0.0795 - val_acc: 0.9920\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0638 - acc: 0.9936 - val_loss: 0.0505 - val_acc: 0.9972\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0393 - acc: 0.9986 - val_loss: 0.0323 - val_acc: 0.9991\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0268 - acc: 0.9990 - val_loss: 0.0255 - val_acc: 0.9981\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0161 - acc: 0.9999 - val_loss: 0.0138 - val_acc: 0.9998\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9998\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0072 - acc: 0.9999 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9998\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 9.9514e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 7.5504e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_81 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 11, 21, 6)     168         input_81[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)             (None, 1386)          0           conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_82 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_41 (Merge)                 (None, 1390)          0           flatten_41[0][0]                 \n",
      "                                                                   input_82[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_121 (Dense)                (None, 32)            44512       merge_41[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_122 (Dense)                (None, 32)            1056        dense_121[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_123 (Dense)                (None, 1)             33          dense_122[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6841 - acc: 0.5771 - val_loss: 0.6807 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6811 - acc: 0.5831 - val_loss: 0.6802 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6807 - acc: 0.5831 - val_loss: 0.6793 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6791 - val_acc: 0.5841\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6790 - acc: 0.5831 - val_loss: 0.6790 - val_acc: 0.5841\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6763 - acc: 0.5831 - val_loss: 0.6753 - val_acc: 0.5841\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6730 - acc: 0.5831 - val_loss: 0.6766 - val_acc: 0.5841\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6712 - acc: 0.5822 - val_loss: 0.6734 - val_acc: 0.5841\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6693 - acc: 0.5838 - val_loss: 0.6742 - val_acc: 0.5843\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6685 - acc: 0.5829 - val_loss: 0.6728 - val_acc: 0.5841\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6673 - acc: 0.5817 - val_loss: 0.6756 - val_acc: 0.5841\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6660 - acc: 0.5818 - val_loss: 0.6731 - val_acc: 0.5839\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6657 - acc: 0.5813 - val_loss: 0.6732 - val_acc: 0.5833\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6645 - acc: 0.5789 - val_loss: 0.6765 - val_acc: 0.5856\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6640 - acc: 0.5815 - val_loss: 0.6749 - val_acc: 0.5828\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6636 - acc: 0.5827 - val_loss: 0.6794 - val_acc: 0.5848\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6636 - acc: 0.5810 - val_loss: 0.6738 - val_acc: 0.5860\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6625 - acc: 0.5843 - val_loss: 0.6761 - val_acc: 0.5538\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6622 - acc: 0.5857 - val_loss: 0.6748 - val_acc: 0.5727\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6609 - acc: 0.5895 - val_loss: 0.6756 - val_acc: 0.5900\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_83 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 11, 21, 6)     168         input_83[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)             (None, 1386)          0           conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_84 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_42 (Merge)                 (None, 1390)          0           flatten_42[0][0]                 \n",
      "                                                                   input_84[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_124 (Dense)                (None, 32)            44512       merge_42[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_125 (Dense)                (None, 32)            1056        dense_124[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_126 (Dense)                (None, 1)             33          dense_125[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 5s - loss: 0.6820 - acc: 0.5808 - val_loss: 0.6799 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6796 - acc: 0.5831 - val_loss: 0.6799 - val_acc: 0.5841\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6678 - acc: 0.5992 - val_loss: 0.5929 - val_acc: 0.7364\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.4781 - acc: 0.7588 - val_loss: 0.3897 - val_acc: 0.7985\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3720 - acc: 0.7938 - val_loss: 0.3546 - val_acc: 0.8172\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3223 - acc: 0.8420 - val_loss: 0.2797 - val_acc: 0.8735\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.2169 - acc: 0.9189 - val_loss: 0.1624 - val_acc: 0.9536\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.1140 - acc: 0.9726 - val_loss: 0.0826 - val_acc: 0.9833\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0599 - acc: 0.9922 - val_loss: 0.0515 - val_acc: 0.9922\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0354 - acc: 0.9969 - val_loss: 0.0298 - val_acc: 0.9981\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0224 - acc: 0.9989 - val_loss: 0.0208 - val_acc: 0.9994\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0154 - acc: 0.9994 - val_loss: 0.0147 - val_acc: 0.9998\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0108 - acc: 0.9998 - val_loss: 0.0118 - val_acc: 0.9992\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0083 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9998\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0064 - acc: 0.9997 - val_loss: 0.0069 - val_acc: 0.9998\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9998\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9998\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "ego_info = np.zeros((num_exper,4,epochs))\n",
    "for i in range(num_exper):\n",
    "    c,x,z = createLayers(rest_size,conv_size,naction)\n",
    "\n",
    "    ego_classifier = Model(inputs=[c,x],outputs=z)\n",
    "\n",
    "    ego_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    ego_classifier.summary()\n",
    "\n",
    "    ego_history = ego_classifier.fit([cnn_input,rest_input],\n",
    "                                       y,epochs=epochs,batch_size=64,validation_split=0.2)\n",
    "    \n",
    "    ego_info[i,0,:] = ego_history.history['val_loss']\n",
    "    ego_info[i,1,:] = ego_history.history['val_acc']\n",
    "    ego_info[i,2,:] = ego_history.history['loss']\n",
    "    ego_info[i,3,:] = ego_history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26400, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('val_train_acc_loss_E.npz',allo=info,ego=ego_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from APES import *\n",
    "from time import time\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "ticks_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=15, weight='normal', stretch='normal')\n",
    "legend_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=12, weight='normal', stretch='normal')\n",
    "hfont =  {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "csfont = {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "def calculate(val,index):\n",
    "    mean = np.mean(val[:,index,:],axis=0)\n",
    "    std = np.std(val[:,index,:],axis=0)\n",
    "    return mean,std/np.sqrt(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = np.load('val_train_acc_loss_E.npz')\n",
    "ego_info = info['ego']\n",
    "info = info['allo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b414507e5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avlm,avls = calculate(info,0)\n",
    "evlm,evls = calculate(ego_info,0)\n",
    "plt.plot(avlm,color='b',label='allo val loss')\n",
    "plt.fill_between(np.arange(20),avlm+avls,avlm-avls,alpha=0.2)\n",
    "\n",
    "plt.plot(evlm,color='r',label='ego val loss')\n",
    "plt.fill_between(np.arange(20),evlm+evls,evlm-evls,alpha=0.2)\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b414512fbe0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avam,avas = calculate(info,1)\n",
    "evam,evas = calculate(ego_info,1)\n",
    "plt.plot(avam,color='b',label='allo validation accuracy')\n",
    "plt.fill_between(np.arange(20),avam+avas,avam-avas,alpha=0.2)\n",
    "plt.plot(evam,color='r',label='ego validation accuracy')\n",
    "plt.fill_between(np.arange(20),evam+evas,evam-evas,alpha=0.2)\n",
    "atam,avas = calculate(info,3)\n",
    "etam,evas = calculate(ego_info,3)\n",
    "#plt.plot(atam,color='black',label='allo training accuracy')\n",
    "\n",
    "#plt.plot(etam,color='r',label='ego training accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
