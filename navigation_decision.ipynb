{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from APES import *\n",
    "from time import time\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "ticks_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=15, weight='normal', stretch='normal')\n",
    "legend_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=12, weight='normal', stretch='normal')\n",
    "hfont =  {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "csfont = {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "def calculate(val,index):\n",
    "    mean = np.mean(val[:,index,:],axis=0)\n",
    "    std = np.std(val[:,index,:],axis=0)\n",
    "    return mean,std/np.sqrt(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26400, 11, 21, 3) (26400, 4) (26400, 1)\n"
     ]
    }
   ],
   "source": [
    "Ego = True\n",
    "if Ego:\n",
    "    unique_count=26400\n",
    "else:\n",
    "    unique_count=31200\n",
    "all_simu = np.load('in_out_{}_seq_EGO_{}.npz'.format(unique_count,Ego))\n",
    "\n",
    "data = all_simu['input_target']\n",
    "action_sequence = all_simu['action_sequence']\n",
    "\n",
    "if Ego:\n",
    "    cnn_input = data[:,:693]\n",
    "    rest_input = data[:,693:697]\n",
    "    y = data[:,697]\n",
    "    cnn_input = cnn_input.reshape((data.shape[0],11,21,3))\n",
    "    rest_input = rest_input.reshape((data.shape[0],4))\n",
    "else:\n",
    "    cnn_input = data[:,:676]\n",
    "    rest_input = data[:,676:684]\n",
    "    y = data[:,684]\n",
    "    cnn_input = cnn_input.reshape((data.shape[0],13,13,4))\n",
    "    rest_input = rest_input.reshape((data.shape[0],8))\n",
    "    \n",
    "y = y.reshape((data.shape[0],1))\n",
    "\n",
    "print(cnn_input.shape,rest_input.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: Forward, 1:Backword,2:Right,3:left,4:nothing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([['L', 'N'], ['M', 'N']]), list([['L', 'S'], ['M', 'S']]),\n",
       "       list([['L', 'W'], ['M', 'W']]), list([['L', 'E'], ['M', 'E']]),\n",
       "       list([])], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.PossibleActions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = np.where(y==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(cnn_input[locations][1][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  4,  4,  0,  2,  0,  3,  2,  3,  2,  3,  0,  0,  4,  2, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_sequence[locations][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_sequence[action_sequence==-1]=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66557,   5241,  17708,  18054,  70490,      0,      0, 921950])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(action_sequence[locations].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'bincount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-39d9308ec8b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maction_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'bincount'"
     ]
    }
   ],
   "source": [
    "action_sequence[locations].bincount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocentric decision test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,convolutional,Flatten,merge,Dense\n",
    "from keras.models import load_model,Model\n",
    "from APES import *\n",
    "from time import time\n",
    "\n",
    "def createLayers(insize,in_conv,naction):\n",
    "    c = Input(shape=in_conv)\n",
    "    con_process = c\n",
    "    con_process = convolutional.Conv2D(filters=6,kernel_size=(3,3),activation=\"relu\",padding=\"same\",strides=1)(con_process)\n",
    "    con_process = Flatten()(con_process)\n",
    "    x = Input(shape=insize)#env.observation_space.shape)\n",
    "    h = merge([con_process,x],mode=\"concat\")\n",
    "    h = Dense(32, activation='tanh')(h)\n",
    "    h = Dense(32, activation='tanh')(h)\n",
    "    z = Dense(1, activation='sigmoid')(h)\n",
    "    return c,x, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Allocentric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13, 4) 5 (8,)\n"
     ]
    }
   ],
   "source": [
    "Ego = False\n",
    "if Ego:\n",
    "    conv_size=(11,21,3,)\n",
    "    rest_size=(4,)\n",
    "else:\n",
    "    conv_size=(13,13,4,)\n",
    "    rest_size=(8,)\n",
    "naction =  Settings.PossibleActions.shape[0]\n",
    "\n",
    "print(conv_size,naction,rest_size)\n",
    "all_simu = np.load('ego:{}_simulation_31200_unique_E.npz'.format(Ego))\n",
    "cnn_input= all_simu['cnn_input']\n",
    "rest_input = all_simu['rest_input']\n",
    "y = all_simu['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 13, 13, 6)     222         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1014)          0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 1022)          0           flatten_1[0][0]                  \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            32736       merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 32)            1056        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             33          dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpc/home/labash/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6818 - acc: 0.5813 - val_loss: 0.6806 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6787 - acc: 0.5837 - val_loss: 0.6722 - val_acc: 0.6151\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5128 - acc: 0.7548 - val_loss: 0.3222 - val_acc: 0.9048\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1700 - acc: 0.9686 - val_loss: 0.0861 - val_acc: 0.9966\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0580 - acc: 0.9983 - val_loss: 0.0370 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0265 - acc: 0.9999 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0010 - acc: 1.0000 - val_loss: 9.1056e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.3830e-04 - acc: 1.0000 - val_loss: 6.6278e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.4270e-04 - acc: 1.0000 - val_loss: 4.9355e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.0733e-04 - acc: 1.0000 - val_loss: 3.6744e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.0608e-04 - acc: 1.0000 - val_loss: 2.7997e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.3572e-04 - acc: 1.0000 - val_loss: 2.1460e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.8215e-04 - acc: 1.0000 - val_loss: 1.7521e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.4164e-04 - acc: 1.0000 - val_loss: 1.3011e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 13, 13, 6)     222         input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1014)          0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 1022)          0           flatten_2[0][0]                  \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 32)            32736       merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 32)            1056        dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             33          dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6817 - acc: 0.5821 - val_loss: 0.6796 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6781 - acc: 0.5837 - val_loss: 0.6724 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5700 - acc: 0.7007 - val_loss: 0.4672 - val_acc: 0.7649\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.3192 - acc: 0.8709 - val_loss: 0.1647 - val_acc: 0.9747\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1094 - acc: 0.9809 - val_loss: 0.0652 - val_acc: 0.9958\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0451 - acc: 0.9979 - val_loss: 0.0295 - val_acc: 0.9989\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0213 - acc: 0.9998 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0011 - acc: 1.0000 - val_loss: 9.1710e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.5211e-04 - acc: 1.0000 - val_loss: 6.9506e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 5.5579e-04 - acc: 1.0000 - val_loss: 5.2910e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.0167e-04 - acc: 1.0000 - val_loss: 3.9556e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.1018e-04 - acc: 1.0000 - val_loss: 2.8004e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.3472e-04 - acc: 1.0000 - val_loss: 2.1470e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.7930e-04 - acc: 1.0000 - val_loss: 1.6794e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.3482e-04 - acc: 1.0000 - val_loss: 1.2529e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 13, 13, 6)     222         input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 1014)          0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 1022)          0           flatten_3[0][0]                  \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 32)            32736       merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 32)            1056        dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             33          dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6816 - acc: 0.5809 - val_loss: 0.6806 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5501 - acc: 0.7281 - val_loss: 0.3570 - val_acc: 0.8896\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.2022 - acc: 0.9674 - val_loss: 0.1139 - val_acc: 0.9950\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0762 - acc: 0.9986 - val_loss: 0.0494 - val_acc: 0.9994\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0318 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.8453e-04 - acc: 1.0000 - val_loss: 7.5328e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.7910e-04 - acc: 1.0000 - val_loss: 5.4087e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.4019e-04 - acc: 1.0000 - val_loss: 4.1302e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.3536e-04 - acc: 1.0000 - val_loss: 3.1503e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.5801e-04 - acc: 1.0000 - val_loss: 2.4113e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.9996e-04 - acc: 1.0000 - val_loss: 1.9573e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.5667e-04 - acc: 1.0000 - val_loss: 1.5305e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.2147e-04 - acc: 1.0000 - val_loss: 1.1485e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 13, 13, 6)     222         input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 1014)          0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 1022)          0           flatten_4[0][0]                  \n",
      "                                                                   input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 32)            32736       merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 32)            1056        dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             33          dense_11[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6821 - acc: 0.5780 - val_loss: 0.6840 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6803 - acc: 0.5837 - val_loss: 0.6816 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5875 - acc: 0.6710 - val_loss: 0.4226 - val_acc: 0.8162\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.2334 - acc: 0.9462 - val_loss: 0.1008 - val_acc: 0.9984\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0579 - acc: 0.9998 - val_loss: 0.0325 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0011 - acc: 1.0000 - val_loss: 9.8512e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.9255e-04 - acc: 1.0000 - val_loss: 7.3476e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.8844e-04 - acc: 1.0000 - val_loss: 5.3501e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.4453e-04 - acc: 1.0000 - val_loss: 4.0855e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.3656e-04 - acc: 1.0000 - val_loss: 3.1736e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.6017e-04 - acc: 1.0000 - val_loss: 2.4468e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.0208e-04 - acc: 1.0000 - val_loss: 1.8990e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.5771e-04 - acc: 1.0000 - val_loss: 1.4834e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.2409e-04 - acc: 1.0000 - val_loss: 1.1711e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 13, 13, 6)     222         input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 1014)          0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 1022)          0           flatten_5[0][0]                  \n",
      "                                                                   input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 32)            32736       merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 32)            1056        dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 1)             33          dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6811 - acc: 0.5792 - val_loss: 0.6751 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.5092 - acc: 0.7568 - val_loss: 0.2903 - val_acc: 0.9393\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1465 - acc: 0.9831 - val_loss: 0.0772 - val_acc: 0.9976\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0462 - acc: 0.9993 - val_loss: 0.0285 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0196 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 8.8100e-04 - acc: 1.0000 - val_loss: 7.8189e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 6.5766e-04 - acc: 1.0000 - val_loss: 5.9350e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.9811e-04 - acc: 1.0000 - val_loss: 4.4915e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.8196e-04 - acc: 1.0000 - val_loss: 3.3862e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.9602e-04 - acc: 1.0000 - val_loss: 2.6589e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.2969e-04 - acc: 1.0000 - val_loss: 2.0699e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.7903e-04 - acc: 1.0000 - val_loss: 1.7506e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.4248e-04 - acc: 1.0000 - val_loss: 1.4099e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.1314e-04 - acc: 1.0000 - val_loss: 1.0404e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 13, 13, 6)     222         input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 1014)          0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 1022)          0           flatten_6[0][0]                  \n",
      "                                                                   input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 32)            32736       merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 32)            1056        dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 1)             33          dense_17[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6814 - acc: 0.5817 - val_loss: 0.6795 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6194 - acc: 0.6521 - val_loss: 0.4176 - val_acc: 0.8646\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.2093 - acc: 0.9647 - val_loss: 0.1029 - val_acc: 0.9923\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0595 - acc: 0.9992 - val_loss: 0.0350 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 9.7032e-04 - acc: 1.0000 - val_loss: 8.7842e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.3065e-04 - acc: 1.0000 - val_loss: 6.6308e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 5.5433e-04 - acc: 1.0000 - val_loss: 5.0412e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.2757e-04 - acc: 1.0000 - val_loss: 4.0461e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.3154e-04 - acc: 1.0000 - val_loss: 3.0994e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.5697e-04 - acc: 1.0000 - val_loss: 2.3515e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.0157e-04 - acc: 1.0000 - val_loss: 1.8873e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.5892e-04 - acc: 1.0000 - val_loss: 1.4983e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.2378e-04 - acc: 1.0000 - val_loss: 1.1790e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 13, 13, 6)     222         input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 1014)          0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_14 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 1022)          0           flatten_7[0][0]                  \n",
      "                                                                   input_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 32)            32736       merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 32)            1056        dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 1)             33          dense_20[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6820 - acc: 0.5819 - val_loss: 0.6842 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6278 - acc: 0.6379 - val_loss: 0.4569 - val_acc: 0.8226\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.2373 - acc: 0.9509 - val_loss: 0.1066 - val_acc: 0.9947\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0615 - acc: 0.9995 - val_loss: 0.0348 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0224 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0010 - acc: 1.0000 - val_loss: 9.3522e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.9226e-04 - acc: 1.0000 - val_loss: 7.4219e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 6.0717e-04 - acc: 1.0000 - val_loss: 5.7370e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.6913e-04 - acc: 1.0000 - val_loss: 4.2585e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.6540e-04 - acc: 1.0000 - val_loss: 3.4685e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.8503e-04 - acc: 1.0000 - val_loss: 2.6938e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.2548e-04 - acc: 1.0000 - val_loss: 2.1090e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.7758e-04 - acc: 1.0000 - val_loss: 1.6615e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.4099e-04 - acc: 1.0000 - val_loss: 1.3433e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 13, 13, 6)     222         input_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 1014)          0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_16 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 1022)          0           flatten_8[0][0]                  \n",
      "                                                                   input_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 32)            32736       merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 32)            1056        dense_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 1)             33          dense_23[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6832 - acc: 0.5796 - val_loss: 0.6796 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6549 - acc: 0.6142 - val_loss: 0.5040 - val_acc: 0.8021\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.2856 - acc: 0.9352 - val_loss: 0.1437 - val_acc: 0.9886\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0820 - acc: 0.9967 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0277 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 8.8280e-04 - acc: 1.0000 - val_loss: 8.2119e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.7493e-04 - acc: 1.0000 - val_loss: 6.0580e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.2082e-04 - acc: 1.0000 - val_loss: 4.6664e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.0438e-04 - acc: 1.0000 - val_loss: 3.7382e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.1689e-04 - acc: 1.0000 - val_loss: 2.8771e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.4926e-04 - acc: 1.0000 - val_loss: 2.3071e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.9680e-04 - acc: 1.0000 - val_loss: 1.8073e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.5602e-04 - acc: 1.0000 - val_loss: 1.4303e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_17 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 13, 13, 6)     222         input_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 1014)          0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_18 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 1022)          0           flatten_9[0][0]                  \n",
      "                                                                   input_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 32)            32736       merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 32)            1056        dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 1)             33          dense_26[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6820 - acc: 0.5819 - val_loss: 0.6796 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6803 - acc: 0.5837 - val_loss: 0.6801 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6799 - acc: 0.5837 - val_loss: 0.6794 - val_acc: 0.5821\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6784 - acc: 0.5838 - val_loss: 0.6590 - val_acc: 0.6112\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.3222 - acc: 0.9029 - val_loss: 0.1062 - val_acc: 0.9979\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0549 - acc: 0.9989 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 8.4022e-04 - acc: 1.0000 - val_loss: 7.3712e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 6.1278e-04 - acc: 1.0000 - val_loss: 5.5595e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.5615e-04 - acc: 1.0000 - val_loss: 4.1558e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 3s - loss: 3.4395e-04 - acc: 1.0000 - val_loss: 3.1051e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.6358e-04 - acc: 1.0000 - val_loss: 2.3568e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.0222e-04 - acc: 1.0000 - val_loss: 1.8243e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.5695e-04 - acc: 1.0000 - val_loss: 1.4268e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.2219e-04 - acc: 1.0000 - val_loss: 1.1275e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 13, 13, 6)     222         input_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 1014)          0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 1022)          0           flatten_10[0][0]                 \n",
      "                                                                   input_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 32)            32736       merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 32)            1056        dense_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 1)             33          dense_29[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6829 - acc: 0.5809 - val_loss: 0.6824 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6472 - acc: 0.6230 - val_loss: 0.4940 - val_acc: 0.7800\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.2957 - acc: 0.9095 - val_loss: 0.1374 - val_acc: 0.9838\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0721 - acc: 0.9988 - val_loss: 0.0379 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0243 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0010 - acc: 1.0000 - val_loss: 9.2310e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 7.4861e-04 - acc: 1.0000 - val_loss: 6.9821e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 3s - loss: 5.6791e-04 - acc: 1.0000 - val_loss: 5.3563e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 3s - loss: 4.3670e-04 - acc: 1.0000 - val_loss: 4.1275e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.4194e-04 - acc: 1.0000 - val_loss: 3.3031e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.6674e-04 - acc: 1.0000 - val_loss: 2.4914e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.0959e-04 - acc: 1.0000 - val_loss: 1.9731e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.6554e-04 - acc: 1.0000 - val_loss: 1.5761e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.3207e-04 - acc: 1.0000 - val_loss: 1.2851e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_21 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 13, 13, 6)     222         input_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 1014)          0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 1022)          0           flatten_11[0][0]                 \n",
      "                                                                   input_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 32)            32736       merge_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 32)            1056        dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 1)             33          dense_32[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6814 - acc: 0.5823 - val_loss: 0.6814 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6804 - acc: 0.5837 - val_loss: 0.6813 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6798 - acc: 0.5837 - val_loss: 0.6825 - val_acc: 0.5821\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6796 - acc: 0.5837 - val_loss: 0.6798 - val_acc: 0.5821\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6800 - acc: 0.5837 - val_loss: 0.6796 - val_acc: 0.5821\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6800 - acc: 0.5837 - val_loss: 0.6797 - val_acc: 0.5821\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6795 - acc: 0.5837 - val_loss: 0.6796 - val_acc: 0.5821\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6795 - acc: 0.5837 - val_loss: 0.6802 - val_acc: 0.5821\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6796 - acc: 0.5837 - val_loss: 0.6805 - val_acc: 0.5821\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6796 - acc: 0.5837 - val_loss: 0.6799 - val_acc: 0.5821\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6796 - acc: 0.5837 - val_loss: 0.6806 - val_acc: 0.5821\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6796 - acc: 0.5837 - val_loss: 0.6800 - val_acc: 0.5821\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6794 - acc: 0.5837 - val_loss: 0.6797 - val_acc: 0.5821\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6774 - acc: 0.5859 - val_loss: 0.6357 - val_acc: 0.6386\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.2670 - acc: 0.9140 - val_loss: 0.0660 - val_acc: 0.9976\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0312 - acc: 0.9995 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_23 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 13, 13, 6)     222         input_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 1014)          0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_24 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 1022)          0           flatten_12[0][0]                 \n",
      "                                                                   input_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 32)            32736       merge_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 32)            1056        dense_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 1)             33          dense_35[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6799 - acc: 0.5831 - val_loss: 0.6790 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6773 - acc: 0.5836 - val_loss: 0.6753 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6724 - acc: 0.5821 - val_loss: 0.6760 - val_acc: 0.5454\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6694 - acc: 0.5780 - val_loss: 0.6662 - val_acc: 0.5819\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.5921 - acc: 0.6821 - val_loss: 0.5000 - val_acc: 0.7473\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.4387 - acc: 0.7800 - val_loss: 0.3045 - val_acc: 0.8861\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.1904 - acc: 0.9498 - val_loss: 0.1239 - val_acc: 0.9742\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0910 - acc: 0.9819 - val_loss: 0.0683 - val_acc: 0.9888\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0491 - acc: 0.9950 - val_loss: 0.0371 - val_acc: 0.9979\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0282 - acc: 0.9986 - val_loss: 0.0231 - val_acc: 0.9981\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0175 - acc: 0.9995 - val_loss: 0.0145 - val_acc: 0.9990\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0114 - acc: 0.9998 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 8.7009e-04 - acc: 1.0000 - val_loss: 8.3280e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_25 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 13, 13, 6)     222         input_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 1014)          0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_26 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_13 (Merge)                 (None, 1022)          0           flatten_13[0][0]                 \n",
      "                                                                   input_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_37 (Dense)                 (None, 32)            32736       merge_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_38 (Dense)                 (None, 32)            1056        dense_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_39 (Dense)                 (None, 1)             33          dense_38[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6703 - acc: 0.6002 - val_loss: 0.5988 - val_acc: 0.7122\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.4891 - acc: 0.7595 - val_loss: 0.3806 - val_acc: 0.8574\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.2145 - acc: 0.9532 - val_loss: 0.1084 - val_acc: 0.9954\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0643 - acc: 0.9979 - val_loss: 0.0377 - val_acc: 0.9998\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0258 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0011 - acc: 1.0000 - val_loss: 9.5781e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.9033e-04 - acc: 1.0000 - val_loss: 7.1324e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 5.9488e-04 - acc: 1.0000 - val_loss: 5.3712e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.5204e-04 - acc: 1.0000 - val_loss: 4.0903e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.4363e-04 - acc: 1.0000 - val_loss: 3.2669e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.6712e-04 - acc: 1.0000 - val_loss: 2.4838e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.0798e-04 - acc: 1.0000 - val_loss: 1.9123e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.6299e-04 - acc: 1.0000 - val_loss: 1.5064e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.2822e-04 - acc: 1.0000 - val_loss: 1.1983e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_27 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 13, 13, 6)     222         input_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 1014)          0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_28 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_14 (Merge)                 (None, 1022)          0           flatten_14[0][0]                 \n",
      "                                                                   input_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_40 (Dense)                 (None, 32)            32736       merge_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_41 (Dense)                 (None, 32)            1056        dense_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_42 (Dense)                 (None, 1)             33          dense_41[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6816 - acc: 0.5821 - val_loss: 0.6796 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6802 - acc: 0.5837 - val_loss: 0.6799 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6798 - acc: 0.5837 - val_loss: 0.6798 - val_acc: 0.5821\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6276 - acc: 0.6430 - val_loss: 0.4174 - val_acc: 0.8516\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.2140 - acc: 0.9621 - val_loss: 0.0925 - val_acc: 0.9992\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0522 - acc: 0.9998 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0011 - acc: 1.0000 - val_loss: 9.2618e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.3810e-04 - acc: 1.0000 - val_loss: 6.5686e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 5.3628e-04 - acc: 1.0000 - val_loss: 4.7900e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.9699e-04 - acc: 1.0000 - val_loss: 3.6433e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.9911e-04 - acc: 1.0000 - val_loss: 2.7393e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 2.2821e-04 - acc: 1.0000 - val_loss: 2.1003e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.7636e-04 - acc: 1.0000 - val_loss: 1.6444e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.3715e-04 - acc: 1.0000 - val_loss: 1.2733e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.0724e-04 - acc: 1.0000 - val_loss: 1.0091e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_29 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 13, 13, 6)     222         input_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 1014)          0           conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_30 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_15 (Merge)                 (None, 1022)          0           flatten_15[0][0]                 \n",
      "                                                                   input_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_43 (Dense)                 (None, 32)            32736       merge_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_44 (Dense)                 (None, 32)            1056        dense_43[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_45 (Dense)                 (None, 1)             33          dense_44[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6809 - acc: 0.5806 - val_loss: 0.6665 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.4380 - acc: 0.8284 - val_loss: 0.2334 - val_acc: 0.9587\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.1420 - acc: 0.9861 - val_loss: 0.0831 - val_acc: 0.9976\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0557 - acc: 0.9988 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0246 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 3s - loss: 9.9952e-04 - acc: 1.0000 - val_loss: 8.8784e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.2996e-04 - acc: 1.0000 - val_loss: 6.5970e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 5.4408e-04 - acc: 1.0000 - val_loss: 4.9219e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.0916e-04 - acc: 1.0000 - val_loss: 3.8173e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.1146e-04 - acc: 1.0000 - val_loss: 2.8455e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.3881e-04 - acc: 1.0000 - val_loss: 2.2631e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.8470e-04 - acc: 1.0000 - val_loss: 1.7209e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.4437e-04 - acc: 1.0000 - val_loss: 1.3834e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 3s - loss: 1.1353e-04 - acc: 1.0000 - val_loss: 1.0723e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_31 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 13, 13, 6)     222         input_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 1014)          0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_32 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_16 (Merge)                 (None, 1022)          0           flatten_16[0][0]                 \n",
      "                                                                   input_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_46 (Dense)                 (None, 32)            32736       merge_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_47 (Dense)                 (None, 32)            1056        dense_46[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_48 (Dense)                 (None, 1)             33          dense_47[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6812 - acc: 0.5826 - val_loss: 0.6793 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6768 - acc: 0.5837 - val_loss: 0.6739 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6714 - acc: 0.5824 - val_loss: 0.6727 - val_acc: 0.5816\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6684 - acc: 0.5817 - val_loss: 0.6674 - val_acc: 0.5793\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6666 - acc: 0.5814 - val_loss: 0.6670 - val_acc: 0.5737\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6659 - acc: 0.5820 - val_loss: 0.6706 - val_acc: 0.5654\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6658 - acc: 0.5822 - val_loss: 0.6660 - val_acc: 0.5846\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6650 - acc: 0.5825 - val_loss: 0.6664 - val_acc: 0.5821\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6642 - acc: 0.5789 - val_loss: 0.6641 - val_acc: 0.5808\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6632 - acc: 0.5820 - val_loss: 0.6666 - val_acc: 0.5611\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6628 - acc: 0.5825 - val_loss: 0.6657 - val_acc: 0.5787\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6626 - acc: 0.5804 - val_loss: 0.6653 - val_acc: 0.5777\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6622 - acc: 0.5780 - val_loss: 0.6629 - val_acc: 0.5782\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6614 - acc: 0.5815 - val_loss: 0.6619 - val_acc: 0.5732\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6603 - acc: 0.5826 - val_loss: 0.6597 - val_acc: 0.5817\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6250 - acc: 0.6348 - val_loss: 0.5412 - val_acc: 0.7189\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.4022 - acc: 0.8168 - val_loss: 0.2837 - val_acc: 0.8984\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.1708 - acc: 0.9533 - val_loss: 0.1090 - val_acc: 0.9780\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0802 - acc: 0.9839 - val_loss: 0.0620 - val_acc: 0.9912\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0502 - acc: 0.9925 - val_loss: 0.0391 - val_acc: 0.9960\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_33 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 13, 13, 6)     222         input_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 1014)          0           conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_17 (Merge)                 (None, 1022)          0           flatten_17[0][0]                 \n",
      "                                                                   input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_49 (Dense)                 (None, 32)            32736       merge_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_50 (Dense)                 (None, 32)            1056        dense_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_51 (Dense)                 (None, 1)             33          dense_50[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6807 - acc: 0.5824 - val_loss: 0.6797 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6076 - acc: 0.6747 - val_loss: 0.4749 - val_acc: 0.7721\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.2896 - acc: 0.9213 - val_loss: 0.1654 - val_acc: 0.9604\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0885 - acc: 0.9940 - val_loss: 0.0497 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0312 - acc: 0.9997 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 9.3817e-04 - acc: 1.0000 - val_loss: 8.3335e-04 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 6.5926e-04 - acc: 1.0000 - val_loss: 5.9075e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.7449e-04 - acc: 1.0000 - val_loss: 4.3509e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.4693e-04 - acc: 1.0000 - val_loss: 3.1375e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.5987e-04 - acc: 1.0000 - val_loss: 2.4350e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.9378e-04 - acc: 1.0000 - val_loss: 1.7758e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.4616e-04 - acc: 1.0000 - val_loss: 1.3625e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.1231e-04 - acc: 1.0000 - val_loss: 1.0651e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 8.6508e-05 - acc: 1.0000 - val_loss: 8.0706e-05 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 6.7413e-05 - acc: 1.0000 - val_loss: 6.2239e-05 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_35 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 13, 13, 6)     222         input_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 1014)          0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_36 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_18 (Merge)                 (None, 1022)          0           flatten_18[0][0]                 \n",
      "                                                                   input_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_52 (Dense)                 (None, 32)            32736       merge_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 32)            1056        dense_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 1)             33          dense_53[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6804 - acc: 0.5835 - val_loss: 0.6799 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6789 - acc: 0.5837 - val_loss: 0.6817 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6748 - acc: 0.5837 - val_loss: 0.6721 - val_acc: 0.5821\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6698 - acc: 0.5819 - val_loss: 0.6683 - val_acc: 0.5821\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6677 - acc: 0.5822 - val_loss: 0.6674 - val_acc: 0.5833\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6664 - acc: 0.5808 - val_loss: 0.6668 - val_acc: 0.5821\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6659 - acc: 0.5793 - val_loss: 0.6670 - val_acc: 0.5803\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6649 - acc: 0.5834 - val_loss: 0.6664 - val_acc: 0.5816\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6646 - acc: 0.5820 - val_loss: 0.6671 - val_acc: 0.5628\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6643 - acc: 0.5808 - val_loss: 0.6663 - val_acc: 0.5838\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6631 - acc: 0.5830 - val_loss: 0.6650 - val_acc: 0.5591\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.6144 - acc: 0.6549 - val_loss: 0.4905 - val_acc: 0.7688\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.3729 - acc: 0.8534 - val_loss: 0.2750 - val_acc: 0.9088\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.1937 - acc: 0.9376 - val_loss: 0.1261 - val_acc: 0.9638\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0859 - acc: 0.9787 - val_loss: 0.0570 - val_acc: 0.9915\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0438 - acc: 0.9942 - val_loss: 0.0337 - val_acc: 0.9958\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0258 - acc: 0.9984 - val_loss: 0.0206 - val_acc: 0.9982\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0167 - acc: 0.9993 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0113 - acc: 0.9998 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_37 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 13, 13, 6)     222         input_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)             (None, 1014)          0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_38 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_19 (Merge)                 (None, 1022)          0           flatten_19[0][0]                 \n",
      "                                                                   input_38[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 32)            32736       merge_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 32)            1056        dense_55[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 1)             33          dense_56[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6825 - acc: 0.5802 - val_loss: 0.6801 - val_acc: 0.5821\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.6802 - acc: 0.5837 - val_loss: 0.6805 - val_acc: 0.5821\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.5760 - acc: 0.6901 - val_loss: 0.3763 - val_acc: 0.8647\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.1930 - acc: 0.9655 - val_loss: 0.0935 - val_acc: 0.9957\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0523 - acc: 0.9998 - val_loss: 0.0299 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 8.9387e-04 - acc: 1.0000 - val_loss: 8.2322e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 6.9319e-04 - acc: 1.0000 - val_loss: 6.3188e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 5.3775e-04 - acc: 1.0000 - val_loss: 4.9307e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.2184e-04 - acc: 1.0000 - val_loss: 3.8431e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.3259e-04 - acc: 1.0000 - val_loss: 3.1106e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.6194e-04 - acc: 1.0000 - val_loss: 2.4331e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.0838e-04 - acc: 1.0000 - val_loss: 1.9305e-04 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_39 (InputLayer)            (None, 13, 13, 4)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 13, 13, 6)     222         input_39[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)             (None, 1014)          0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_40 (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_20 (Merge)                 (None, 1022)          0           flatten_20[0][0]                 \n",
      "                                                                   input_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_58 (Dense)                 (None, 32)            32736       merge_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 32)            1056        dense_58[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 1)             33          dense_59[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 24960 samples, validate on 6240 samples\n",
      "Epoch 1/20\n",
      "24960/24960 [==============================] - 4s - loss: 0.6787 - acc: 0.5816 - val_loss: 0.6534 - val_acc: 0.6375\n",
      "Epoch 2/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.4413 - acc: 0.8223 - val_loss: 0.2182 - val_acc: 0.9702\n",
      "Epoch 3/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.1187 - acc: 0.9879 - val_loss: 0.0619 - val_acc: 0.9973\n",
      "Epoch 4/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0392 - acc: 0.9992 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "24960/24960 [==============================] - 3s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "24960/24960 [==============================] - 2s - loss: 0.0010 - acc: 1.0000 - val_loss: 9.3030e-04 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "24960/24960 [==============================] - 2s - loss: 7.5159e-04 - acc: 1.0000 - val_loss: 6.9485e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "24960/24960 [==============================] - 2s - loss: 5.4627e-04 - acc: 1.0000 - val_loss: 5.0385e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "24960/24960 [==============================] - 2s - loss: 4.1892e-04 - acc: 1.0000 - val_loss: 3.7926e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "24960/24960 [==============================] - 2s - loss: 3.1084e-04 - acc: 1.0000 - val_loss: 2.9055e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "24960/24960 [==============================] - 2s - loss: 2.3822e-04 - acc: 1.0000 - val_loss: 2.4102e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.8493e-04 - acc: 1.0000 - val_loss: 1.7407e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.4311e-04 - acc: 1.0000 - val_loss: 1.3876e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "24960/24960 [==============================] - 2s - loss: 1.1254e-04 - acc: 1.0000 - val_loss: 1.0917e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "24960/24960 [==============================] - 2s - loss: 8.7410e-05 - acc: 1.0000 - val_loss: 8.4234e-05 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_exper= 20\n",
    "epochs=20\n",
    "info = np.zeros((num_exper,4,epochs))\n",
    "for i in range(num_exper):\n",
    "    c,x,z = createLayers(rest_size,conv_size,naction)\n",
    "\n",
    "    allo_classifier = Model(inputs=[c,x],outputs=z)\n",
    "\n",
    "    allo_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    allo_classifier.summary()\n",
    "\n",
    "    allo_history = allo_classifier.fit([all_simu['cnn_input'],all_simu['rest_input']],\n",
    "                                       all_simu['y'],epochs=epochs,batch_size=64,validation_split=0.2)\n",
    "    \n",
    "    info[i,0,:] = allo_history.history['val_loss']\n",
    "    info[i,1,:] = allo_history.history['val_acc']\n",
    "    info[i,2,:] = allo_history.history['loss']\n",
    "    info[i,3,:] = allo_history.history['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ego centric decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 21, 3) 5 (4,)\n"
     ]
    }
   ],
   "source": [
    "Ego = True\n",
    "if Ego:\n",
    "    conv_size=(11,21,3,)\n",
    "    rest_size=(4,)\n",
    "else:\n",
    "    conv_size=(13,13,4,)\n",
    "    rest_size=(8,)\n",
    "naction =  Settings.PossibleActions.shape[0]\n",
    "\n",
    "print(conv_size,naction,rest_size)\n",
    "all_simu = np.load('ego:{}_simulation_26400_unique_E.npz'.format(Ego))\n",
    "#all_simu = np.load('ego:{}_simulation_200000.npz'.format(Ego))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpc/home/labash/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/gpfs/hpc/home/labash/miniconda3/envs/PT_old/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_41 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 11, 21, 6)     168         input_41[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 1386)          0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_42 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_21 (Merge)                 (None, 1390)          0           flatten_21[0][0]                 \n",
      "                                                                   input_42[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_61 (Dense)                 (None, 32)            44512       merge_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_62 (Dense)                 (None, 32)            1056        dense_61[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_63 (Dense)                 (None, 1)             33          dense_62[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6811 - acc: 0.5838 - val_loss: 0.6835 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6774 - acc: 0.5863 - val_loss: 0.6811 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6722 - acc: 0.5857 - val_loss: 0.6761 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6674 - acc: 0.5851 - val_loss: 0.6760 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6661 - acc: 0.5848 - val_loss: 0.6752 - val_acc: 0.5720\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6651 - acc: 0.5852 - val_loss: 0.6748 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6643 - acc: 0.5856 - val_loss: 0.6757 - val_acc: 0.5708\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6642 - acc: 0.5846 - val_loss: 0.6759 - val_acc: 0.5534\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6636 - acc: 0.5845 - val_loss: 0.6763 - val_acc: 0.5678\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6633 - acc: 0.5860 - val_loss: 0.6763 - val_acc: 0.5716\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6632 - acc: 0.5842 - val_loss: 0.6742 - val_acc: 0.5716\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6629 - acc: 0.5833 - val_loss: 0.6766 - val_acc: 0.5693\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6627 - acc: 0.5838 - val_loss: 0.6778 - val_acc: 0.5718\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6625 - acc: 0.5867 - val_loss: 0.6756 - val_acc: 0.5687\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6617 - acc: 0.5854 - val_loss: 0.6751 - val_acc: 0.5657\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6616 - acc: 0.5866 - val_loss: 0.6763 - val_acc: 0.5716\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6611 - acc: 0.5878 - val_loss: 0.6763 - val_acc: 0.5657\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6614 - acc: 0.5826 - val_loss: 0.6748 - val_acc: 0.5716\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6616 - acc: 0.5888 - val_loss: 0.6794 - val_acc: 0.5652\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_43 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 11, 21, 6)     168         input_43[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)             (None, 1386)          0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_44 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_22 (Merge)                 (None, 1390)          0           flatten_22[0][0]                 \n",
      "                                                                   input_44[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 32)            44512       merge_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 32)            1056        dense_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_66 (Dense)                 (None, 1)             33          dense_65[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6804 - acc: 0.5838 - val_loss: 0.6840 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6793 - acc: 0.5863 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6841 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6311 - acc: 0.6512 - val_loss: 0.5579 - val_acc: 0.7350\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4785 - acc: 0.7543 - val_loss: 0.4195 - val_acc: 0.7616\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3811 - acc: 0.7843 - val_loss: 0.3766 - val_acc: 0.7871\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3419 - acc: 0.8130 - val_loss: 0.3161 - val_acc: 0.8464\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2234 - acc: 0.9229 - val_loss: 0.1586 - val_acc: 0.9523\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0955 - acc: 0.9828 - val_loss: 0.0737 - val_acc: 0.9839\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0542 - acc: 0.9915 - val_loss: 0.0404 - val_acc: 0.9975\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0297 - acc: 0.9980 - val_loss: 0.0258 - val_acc: 0.9991\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0180 - acc: 0.9997 - val_loss: 0.0173 - val_acc: 0.9992\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0120 - acc: 0.9999 - val_loss: 0.0121 - val_acc: 0.9991\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0090 - acc: 0.9998 - val_loss: 0.0104 - val_acc: 0.9994\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9996\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9996\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9996\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9996\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9996\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0179 - acc: 0.9942 - val_loss: 0.0075 - val_acc: 0.9979\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_45 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 11, 21, 6)     168         input_45[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)             (None, 1386)          0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_46 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_23 (Merge)                 (None, 1390)          0           flatten_23[0][0]                 \n",
      "                                                                   input_46[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_67 (Dense)                 (None, 32)            44512       merge_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_68 (Dense)                 (None, 32)            1056        dense_67[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_69 (Dense)                 (None, 1)             33          dense_68[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6819 - acc: 0.5808 - val_loss: 0.6839 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6791 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6777 - acc: 0.5863 - val_loss: 0.6827 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6752 - acc: 0.5866 - val_loss: 0.6808 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6706 - acc: 0.5845 - val_loss: 0.6767 - val_acc: 0.5712\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6648 - acc: 0.5899 - val_loss: 0.6615 - val_acc: 0.6214\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5524 - acc: 0.7159 - val_loss: 0.4459 - val_acc: 0.7564\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3897 - acc: 0.7779 - val_loss: 0.3891 - val_acc: 0.7614\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3550 - acc: 0.7881 - val_loss: 0.3582 - val_acc: 0.7652\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3396 - acc: 0.7952 - val_loss: 0.3579 - val_acc: 0.7845\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3229 - acc: 0.8120 - val_loss: 0.3325 - val_acc: 0.7936\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2819 - acc: 0.8590 - val_loss: 0.2594 - val_acc: 0.8752\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1933 - acc: 0.9271 - val_loss: 0.1550 - val_acc: 0.9525\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1090 - acc: 0.9753 - val_loss: 0.0864 - val_acc: 0.9811\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0597 - acc: 0.9905 - val_loss: 0.0674 - val_acc: 0.9771\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0370 - acc: 0.9946 - val_loss: 0.0398 - val_acc: 0.9900\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0269 - acc: 0.9955 - val_loss: 0.0327 - val_acc: 0.9917\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0194 - acc: 0.9970 - val_loss: 0.0165 - val_acc: 0.9985\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0123 - acc: 0.9994 - val_loss: 0.0142 - val_acc: 0.9985\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0104 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9996\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_47 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 11, 21, 6)     168         input_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)             (None, 1386)          0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_48 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_24 (Merge)                 (None, 1390)          0           flatten_24[0][0]                 \n",
      "                                                                   input_48[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_70 (Dense)                 (None, 32)            44512       merge_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_71 (Dense)                 (None, 32)            1056        dense_70[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_72 (Dense)                 (None, 1)             33          dense_71[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6802 - acc: 0.5855 - val_loss: 0.6843 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6769 - acc: 0.5863 - val_loss: 0.6799 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6730 - acc: 0.5863 - val_loss: 0.6793 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6696 - acc: 0.5862 - val_loss: 0.6767 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6673 - acc: 0.5860 - val_loss: 0.6759 - val_acc: 0.5716\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6658 - acc: 0.5868 - val_loss: 0.6790 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6648 - acc: 0.5864 - val_loss: 0.6757 - val_acc: 0.5716\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6648 - acc: 0.5857 - val_loss: 0.6744 - val_acc: 0.5716\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6643 - acc: 0.5831 - val_loss: 0.6749 - val_acc: 0.5716\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6638 - acc: 0.5863 - val_loss: 0.6754 - val_acc: 0.5716\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6636 - acc: 0.5855 - val_loss: 0.6784 - val_acc: 0.5716\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6631 - acc: 0.5844 - val_loss: 0.6745 - val_acc: 0.5716\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6623 - acc: 0.5842 - val_loss: 0.6744 - val_acc: 0.5587\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6627 - acc: 0.5836 - val_loss: 0.6743 - val_acc: 0.5716\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6618 - acc: 0.5835 - val_loss: 0.6742 - val_acc: 0.5716\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6617 - acc: 0.5863 - val_loss: 0.6754 - val_acc: 0.5716\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6616 - acc: 0.5816 - val_loss: 0.6761 - val_acc: 0.5826\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.6617 - acc: 0.5867 - val_loss: 0.6765 - val_acc: 0.5716\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6608 - acc: 0.5842 - val_loss: 0.6765 - val_acc: 0.5663\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_49 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 11, 21, 6)     168         input_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 1386)          0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_50 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_25 (Merge)                 (None, 1390)          0           flatten_25[0][0]                 \n",
      "                                                                   input_50[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_73 (Dense)                 (None, 32)            44512       merge_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_74 (Dense)                 (None, 32)            1056        dense_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_75 (Dense)                 (None, 1)             33          dense_74[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6812 - acc: 0.5828 - val_loss: 0.6836 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6794 - acc: 0.5863 - val_loss: 0.6838 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6790 - acc: 0.5863 - val_loss: 0.6856 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6788 - acc: 0.5863 - val_loss: 0.6881 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6792 - acc: 0.5863 - val_loss: 0.6837 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6526 - acc: 0.6133 - val_loss: 0.5889 - val_acc: 0.6788\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4514 - acc: 0.7788 - val_loss: 0.3865 - val_acc: 0.8027\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3270 - acc: 0.8473 - val_loss: 0.2693 - val_acc: 0.8854\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1837 - acc: 0.9479 - val_loss: 0.1148 - val_acc: 0.9866\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0791 - acc: 0.9890 - val_loss: 0.0509 - val_acc: 0.9966\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0390 - acc: 0.9967 - val_loss: 0.0306 - val_acc: 0.9972\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0223 - acc: 0.9985 - val_loss: 0.0191 - val_acc: 0.9983\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0141 - acc: 0.9996 - val_loss: 0.0128 - val_acc: 0.9996\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0097 - acc: 0.9997 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0072 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9998\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0059 - acc: 0.9997 - val_loss: 0.0049 - val_acc: 0.9998\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9998\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_51 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 11, 21, 6)     168         input_51[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)             (None, 1386)          0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_52 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_26 (Merge)                 (None, 1390)          0           flatten_26[0][0]                 \n",
      "                                                                   input_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_76 (Dense)                 (None, 32)            44512       merge_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_77 (Dense)                 (None, 32)            1056        dense_76[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_78 (Dense)                 (None, 1)             33          dense_77[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6807 - acc: 0.5843 - val_loss: 0.6850 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6795 - acc: 0.5863 - val_loss: 0.6837 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6791 - acc: 0.5863 - val_loss: 0.6858 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6464 - acc: 0.6223 - val_loss: 0.5396 - val_acc: 0.7229\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4391 - acc: 0.7644 - val_loss: 0.3937 - val_acc: 0.7693\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3808 - acc: 0.7795 - val_loss: 0.3698 - val_acc: 0.7775\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3624 - acc: 0.7818 - val_loss: 0.3688 - val_acc: 0.7623\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3495 - acc: 0.7936 - val_loss: 0.3535 - val_acc: 0.7602\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3290 - acc: 0.8134 - val_loss: 0.3101 - val_acc: 0.8415\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2926 - acc: 0.8502 - val_loss: 0.2759 - val_acc: 0.8663\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2517 - acc: 0.8778 - val_loss: 0.2224 - val_acc: 0.9004\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1978 - acc: 0.9090 - val_loss: 0.1723 - val_acc: 0.9273\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1460 - acc: 0.9359 - val_loss: 0.1200 - val_acc: 0.9447\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1063 - acc: 0.9560 - val_loss: 0.0914 - val_acc: 0.9627\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0818 - acc: 0.9693 - val_loss: 0.0689 - val_acc: 0.9780\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0606 - acc: 0.9805 - val_loss: 0.0524 - val_acc: 0.9867\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0500 - acc: 0.9843 - val_loss: 0.0359 - val_acc: 0.9920\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0367 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9871\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0378 - acc: 0.9867 - val_loss: 0.0235 - val_acc: 0.9960\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0262 - acc: 0.9931 - val_loss: 0.0215 - val_acc: 0.9949\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_53 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 11, 21, 6)     168         input_53[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)             (None, 1386)          0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_54 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_27 (Merge)                 (None, 1390)          0           flatten_27[0][0]                 \n",
      "                                                                   input_54[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_79 (Dense)                 (None, 32)            44512       merge_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_80 (Dense)                 (None, 32)            1056        dense_79[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_81 (Dense)                 (None, 1)             33          dense_80[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6816 - acc: 0.5833 - val_loss: 0.6836 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6840 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6788 - acc: 0.5863 - val_loss: 0.6834 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6786 - acc: 0.5863 - val_loss: 0.6852 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6839 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6840 - val_acc: 0.5716\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6843 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6776 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6744 - acc: 0.5864 - val_loss: 0.6816 - val_acc: 0.5716\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6712 - acc: 0.5830 - val_loss: 0.6789 - val_acc: 0.5653\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6689 - acc: 0.5815 - val_loss: 0.6784 - val_acc: 0.5703\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6676 - acc: 0.5818 - val_loss: 0.6786 - val_acc: 0.5661\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6668 - acc: 0.5832 - val_loss: 0.6798 - val_acc: 0.5447\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6663 - acc: 0.5833 - val_loss: 0.6788 - val_acc: 0.5665\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6660 - acc: 0.5827 - val_loss: 0.6788 - val_acc: 0.5663\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6657 - acc: 0.5821 - val_loss: 0.6787 - val_acc: 0.5674\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6653 - acc: 0.5845 - val_loss: 0.6769 - val_acc: 0.5695\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6648 - acc: 0.5838 - val_loss: 0.6763 - val_acc: 0.5684\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6650 - acc: 0.5861 - val_loss: 0.6795 - val_acc: 0.5695\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6649 - acc: 0.5852 - val_loss: 0.6783 - val_acc: 0.5650\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_55 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 11, 21, 6)     168         input_55[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)             (None, 1386)          0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_56 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_28 (Merge)                 (None, 1390)          0           flatten_28[0][0]                 \n",
      "                                                                   input_56[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_82 (Dense)                 (None, 32)            44512       merge_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_83 (Dense)                 (None, 32)            1056        dense_82[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_84 (Dense)                 (None, 1)             33          dense_83[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6811 - acc: 0.5842 - val_loss: 0.6837 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6752 - acc: 0.5864 - val_loss: 0.6771 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6262 - acc: 0.6505 - val_loss: 0.5450 - val_acc: 0.7212\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4565 - acc: 0.7623 - val_loss: 0.4070 - val_acc: 0.7720\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3831 - acc: 0.7802 - val_loss: 0.3798 - val_acc: 0.7695\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3529 - acc: 0.7944 - val_loss: 0.3550 - val_acc: 0.7856\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3067 - acc: 0.8462 - val_loss: 0.2595 - val_acc: 0.8864\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1505 - acc: 0.9689 - val_loss: 0.0880 - val_acc: 0.9907\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0592 - acc: 0.9953 - val_loss: 0.0427 - val_acc: 0.9981\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0310 - acc: 0.9986 - val_loss: 0.0260 - val_acc: 0.9983\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0186 - acc: 0.9995 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9996\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0082 - acc: 0.9999 - val_loss: 0.0086 - val_acc: 0.9998\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0063 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9996\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0047 - acc: 0.9999 - val_loss: 0.0060 - val_acc: 0.9992\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_57 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 11, 21, 6)     168         input_57[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)             (None, 1386)          0           conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_58 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_29 (Merge)                 (None, 1390)          0           flatten_29[0][0]                 \n",
      "                                                                   input_58[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_85 (Dense)                 (None, 32)            44512       merge_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_86 (Dense)                 (None, 32)            1056        dense_85[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_87 (Dense)                 (None, 1)             33          dense_86[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6827 - acc: 0.5826 - val_loss: 0.6861 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6791 - acc: 0.5863 - val_loss: 0.6839 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6831 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6783 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5240 - acc: 0.7201 - val_loss: 0.4203 - val_acc: 0.7750\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3872 - acc: 0.7744 - val_loss: 0.3802 - val_acc: 0.7595\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3667 - acc: 0.7804 - val_loss: 0.3696 - val_acc: 0.7617\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3568 - acc: 0.7855 - val_loss: 0.3606 - val_acc: 0.7708\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3528 - acc: 0.7883 - val_loss: 0.3663 - val_acc: 0.7778\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3463 - acc: 0.7970 - val_loss: 0.3617 - val_acc: 0.7553\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3363 - acc: 0.8163 - val_loss: 0.3392 - val_acc: 0.8174\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3153 - acc: 0.8429 - val_loss: 0.3035 - val_acc: 0.8595\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2409 - acc: 0.9027 - val_loss: 0.1922 - val_acc: 0.9375\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1387 - acc: 0.9587 - val_loss: 0.1049 - val_acc: 0.9710\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0787 - acc: 0.9839 - val_loss: 0.0571 - val_acc: 0.9934\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0474 - acc: 0.9940 - val_loss: 0.0354 - val_acc: 0.9981\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0295 - acc: 0.9976 - val_loss: 0.0238 - val_acc: 0.9992\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0198 - acc: 0.9986 - val_loss: 0.0174 - val_acc: 0.9991\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0123 - acc: 0.9999 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_59 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 11, 21, 6)     168         input_59[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)             (None, 1386)          0           conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_60 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_30 (Merge)                 (None, 1390)          0           flatten_30[0][0]                 \n",
      "                                                                   input_60[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_88 (Dense)                 (None, 32)            44512       merge_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_89 (Dense)                 (None, 32)            1056        dense_88[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_90 (Dense)                 (None, 1)             33          dense_89[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6836 - acc: 0.5821 - val_loss: 0.6868 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6797 - acc: 0.5861 - val_loss: 0.6847 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6792 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6793 - acc: 0.5863 - val_loss: 0.6847 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6792 - acc: 0.5863 - val_loss: 0.6836 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6790 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6798 - acc: 0.5863 - val_loss: 0.6831 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6790 - acc: 0.5863 - val_loss: 0.6848 - val_acc: 0.5716\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6839 - val_acc: 0.5716\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6829 - val_acc: 0.5716\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6782 - acc: 0.5866 - val_loss: 0.6698 - val_acc: 0.5771\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4837 - acc: 0.7426 - val_loss: 0.4012 - val_acc: 0.7737\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3773 - acc: 0.7817 - val_loss: 0.3767 - val_acc: 0.7580\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3551 - acc: 0.7907 - val_loss: 0.3551 - val_acc: 0.7991\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3276 - acc: 0.8281 - val_loss: 0.3190 - val_acc: 0.8400\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2308 - acc: 0.9198 - val_loss: 0.1582 - val_acc: 0.9578\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0944 - acc: 0.9839 - val_loss: 0.0634 - val_acc: 0.9917\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0426 - acc: 0.9961 - val_loss: 0.0309 - val_acc: 0.9989\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0225 - acc: 0.9989 - val_loss: 0.0224 - val_acc: 0.9977\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0140 - acc: 0.9993 - val_loss: 0.0120 - val_acc: 0.9989\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_61 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 11, 21, 6)     168         input_61[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)             (None, 1386)          0           conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_62 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_31 (Merge)                 (None, 1390)          0           flatten_31[0][0]                 \n",
      "                                                                   input_62[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_91 (Dense)                 (None, 32)            44512       merge_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_92 (Dense)                 (None, 32)            1056        dense_91[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_93 (Dense)                 (None, 1)             33          dense_92[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6810 - acc: 0.5858 - val_loss: 0.6835 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6792 - acc: 0.5863 - val_loss: 0.6845 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6835 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6611 - acc: 0.6150 - val_loss: 0.5900 - val_acc: 0.7150\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4979 - acc: 0.7517 - val_loss: 0.4207 - val_acc: 0.7642\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3762 - acc: 0.7990 - val_loss: 0.3371 - val_acc: 0.8258\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2498 - acc: 0.9129 - val_loss: 0.1538 - val_acc: 0.9758\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1003 - acc: 0.9869 - val_loss: 0.0697 - val_acc: 0.9871\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0465 - acc: 0.9960 - val_loss: 0.0331 - val_acc: 0.9973\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0256 - acc: 0.9992 - val_loss: 0.0203 - val_acc: 0.9996\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0167 - acc: 0.9993 - val_loss: 0.0145 - val_acc: 0.9998\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0119 - acc: 0.9996 - val_loss: 0.0118 - val_acc: 0.9996\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0111 - acc: 0.9988 - val_loss: 0.0103 - val_acc: 0.9987\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0067 - acc: 0.9996 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0061 - acc: 0.9989 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_63 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 11, 21, 6)     168         input_63[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)             (None, 1386)          0           conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_64 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_32 (Merge)                 (None, 1390)          0           flatten_32[0][0]                 \n",
      "                                                                   input_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_94 (Dense)                 (None, 32)            44512       merge_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_95 (Dense)                 (None, 32)            1056        dense_94[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_96 (Dense)                 (None, 1)             33          dense_95[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6811 - acc: 0.5855 - val_loss: 0.6845 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6786 - acc: 0.5863 - val_loss: 0.6833 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6776 - acc: 0.5863 - val_loss: 0.6819 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6738 - acc: 0.5863 - val_loss: 0.6776 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6697 - acc: 0.5859 - val_loss: 0.6749 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6676 - acc: 0.5845 - val_loss: 0.6748 - val_acc: 0.5712\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6661 - acc: 0.5860 - val_loss: 0.6744 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6624 - acc: 0.5839 - val_loss: 0.6561 - val_acc: 0.5964\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5670 - acc: 0.6991 - val_loss: 0.4799 - val_acc: 0.7479\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4220 - acc: 0.7693 - val_loss: 0.3907 - val_acc: 0.7729\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3671 - acc: 0.7888 - val_loss: 0.3609 - val_acc: 0.7748\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3436 - acc: 0.7879 - val_loss: 0.3469 - val_acc: 0.7722\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3309 - acc: 0.7984 - val_loss: 0.3363 - val_acc: 0.7710\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3180 - acc: 0.8082 - val_loss: 0.3169 - val_acc: 0.8242\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2647 - acc: 0.8761 - val_loss: 0.2261 - val_acc: 0.9080\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1554 - acc: 0.9533 - val_loss: 0.1070 - val_acc: 0.9748\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0780 - acc: 0.9833 - val_loss: 0.0602 - val_acc: 0.9894\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0448 - acc: 0.9915 - val_loss: 0.0441 - val_acc: 0.9894\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0317 - acc: 0.9935 - val_loss: 0.0286 - val_acc: 0.9922\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0228 - acc: 0.9960 - val_loss: 0.0210 - val_acc: 0.9962\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_65 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 11, 21, 6)     168         input_65[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)             (None, 1386)          0           conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_66 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_33 (Merge)                 (None, 1390)          0           flatten_33[0][0]                 \n",
      "                                                                   input_66[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_97 (Dense)                 (None, 32)            44512       merge_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_98 (Dense)                 (None, 32)            1056        dense_97[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_99 (Dense)                 (None, 1)             33          dense_98[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6814 - acc: 0.5832 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6795 - acc: 0.5863 - val_loss: 0.6876 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6838 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6836 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6786 - acc: 0.5863 - val_loss: 0.6831 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6846 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6774 - acc: 0.5863 - val_loss: 0.6762 - val_acc: 0.5716\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5674 - acc: 0.7044 - val_loss: 0.4780 - val_acc: 0.7466\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4203 - acc: 0.7755 - val_loss: 0.3968 - val_acc: 0.7693\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3774 - acc: 0.7866 - val_loss: 0.3733 - val_acc: 0.7712\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3614 - acc: 0.7899 - val_loss: 0.3727 - val_acc: 0.7689\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3525 - acc: 0.7939 - val_loss: 0.3649 - val_acc: 0.7795\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3357 - acc: 0.8120 - val_loss: 0.3217 - val_acc: 0.8273\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2600 - acc: 0.8888 - val_loss: 0.2118 - val_acc: 0.9297\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1622 - acc: 0.9504 - val_loss: 0.1307 - val_acc: 0.9623\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1015 - acc: 0.9770 - val_loss: 0.0810 - val_acc: 0.9883\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0642 - acc: 0.9911 - val_loss: 0.0552 - val_acc: 0.9930\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0410 - acc: 0.9969 - val_loss: 0.0380 - val_acc: 0.9972\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0270 - acc: 0.9986 - val_loss: 0.0234 - val_acc: 0.9994\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_67 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 11, 21, 6)     168         input_67[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)             (None, 1386)          0           conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_68 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_34 (Merge)                 (None, 1390)          0           flatten_34[0][0]                 \n",
      "                                                                   input_68[0][0]                   \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_100 (Dense)                (None, 32)            44512       merge_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_101 (Dense)                (None, 32)            1056        dense_100[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_102 (Dense)                (None, 1)             33          dense_101[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6797 - acc: 0.5851 - val_loss: 0.6836 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6787 - acc: 0.5863 - val_loss: 0.6833 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6786 - acc: 0.5863 - val_loss: 0.6834 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6834 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6849 - val_acc: 0.5716\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6851 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6842 - val_acc: 0.5716\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6835 - val_acc: 0.5716\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6833 - val_acc: 0.5716\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6839 - val_acc: 0.5716\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6839 - val_acc: 0.5716\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6837 - val_acc: 0.5716\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6835 - val_acc: 0.5716\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6833 - val_acc: 0.5716\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_69 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 11, 21, 6)     168         input_69[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)             (None, 1386)          0           conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_70 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_35 (Merge)                 (None, 1390)          0           flatten_35[0][0]                 \n",
      "                                                                   input_70[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_103 (Dense)                (None, 32)            44512       merge_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_104 (Dense)                (None, 32)            1056        dense_103[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_105 (Dense)                (None, 1)             33          dense_104[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6813 - acc: 0.5831 - val_loss: 0.6837 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6791 - acc: 0.5863 - val_loss: 0.6833 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6787 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6786 - acc: 0.5863 - val_loss: 0.6831 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6835 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6831 - val_acc: 0.5716\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6829 - val_acc: 0.5716\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6838 - val_acc: 0.5716\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6784 - acc: 0.5863 - val_loss: 0.6830 - val_acc: 0.5716\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6781 - acc: 0.5863 - val_loss: 0.6827 - val_acc: 0.5716\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6769 - acc: 0.5859 - val_loss: 0.6836 - val_acc: 0.5716\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6749 - acc: 0.5834 - val_loss: 0.6818 - val_acc: 0.5706\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6745 - acc: 0.5830 - val_loss: 0.6829 - val_acc: 0.5716\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6727 - acc: 0.5841 - val_loss: 0.6803 - val_acc: 0.5449\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6690 - acc: 0.5827 - val_loss: 0.6692 - val_acc: 0.5716\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6417 - acc: 0.6295 - val_loss: 0.6196 - val_acc: 0.6530\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5868 - acc: 0.6809 - val_loss: 0.5613 - val_acc: 0.6958\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5302 - acc: 0.7045 - val_loss: 0.5151 - val_acc: 0.7201\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_71 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 11, 21, 6)     168         input_71[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)             (None, 1386)          0           conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_72 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_36 (Merge)                 (None, 1390)          0           flatten_36[0][0]                 \n",
      "                                                                   input_72[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_106 (Dense)                (None, 32)            44512       merge_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_107 (Dense)                (None, 32)            1056        dense_106[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_108 (Dense)                (None, 1)             33          dense_107[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6808 - acc: 0.5848 - val_loss: 0.6841 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6789 - acc: 0.5863 - val_loss: 0.6837 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6648 - acc: 0.6091 - val_loss: 0.6009 - val_acc: 0.7068\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5243 - acc: 0.7342 - val_loss: 0.4991 - val_acc: 0.7265\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4109 - acc: 0.7695 - val_loss: 0.3878 - val_acc: 0.7739\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3777 - acc: 0.7776 - val_loss: 0.3837 - val_acc: 0.7589\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3631 - acc: 0.7805 - val_loss: 0.3705 - val_acc: 0.7731\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3577 - acc: 0.7830 - val_loss: 0.3633 - val_acc: 0.7811\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3521 - acc: 0.7876 - val_loss: 0.3640 - val_acc: 0.7564\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3485 - acc: 0.7902 - val_loss: 0.3591 - val_acc: 0.7653\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3478 - acc: 0.7874 - val_loss: 0.3594 - val_acc: 0.7782\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.3429 - acc: 0.7975 - val_loss: 0.3677 - val_acc: 0.7744\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3365 - acc: 0.8055 - val_loss: 0.3496 - val_acc: 0.8027\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3247 - acc: 0.8183 - val_loss: 0.3352 - val_acc: 0.8068\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2954 - acc: 0.8500 - val_loss: 0.2718 - val_acc: 0.8847\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2238 - acc: 0.9098 - val_loss: 0.1823 - val_acc: 0.9485\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1412 - acc: 0.9563 - val_loss: 0.1066 - val_acc: 0.9746\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 3s - loss: 0.0894 - acc: 0.9780 - val_loss: 0.0683 - val_acc: 0.9907\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0592 - acc: 0.9886 - val_loss: 0.0534 - val_acc: 0.9888\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0431 - acc: 0.9922 - val_loss: 0.0338 - val_acc: 0.9962\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_73 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 11, 21, 6)     168         input_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)             (None, 1386)          0           conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_74 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_37 (Merge)                 (None, 1390)          0           flatten_37[0][0]                 \n",
      "                                                                   input_74[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_109 (Dense)                (None, 32)            44512       merge_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_110 (Dense)                (None, 32)            1056        dense_109[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_111 (Dense)                (None, 1)             33          dense_110[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6813 - acc: 0.5824 - val_loss: 0.6838 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6790 - acc: 0.5863 - val_loss: 0.6832 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6786 - acc: 0.5863 - val_loss: 0.6844 - val_acc: 0.5716\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6787 - acc: 0.5863 - val_loss: 0.6835 - val_acc: 0.5716\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6785 - acc: 0.5863 - val_loss: 0.6843 - val_acc: 0.5716\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6786 - acc: 0.5863 - val_loss: 0.6841 - val_acc: 0.5716\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6834 - val_acc: 0.5716\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6831 - val_acc: 0.5716\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6783 - acc: 0.5863 - val_loss: 0.6829 - val_acc: 0.5716\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6781 - acc: 0.5863 - val_loss: 0.6828 - val_acc: 0.5716\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6764 - acc: 0.5863 - val_loss: 0.6802 - val_acc: 0.5716\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6728 - acc: 0.5860 - val_loss: 0.6772 - val_acc: 0.5437\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6694 - acc: 0.5822 - val_loss: 0.6757 - val_acc: 0.5716\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6677 - acc: 0.5827 - val_loss: 0.6754 - val_acc: 0.5676\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6665 - acc: 0.5841 - val_loss: 0.6744 - val_acc: 0.5551\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6659 - acc: 0.5846 - val_loss: 0.6732 - val_acc: 0.5680\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6657 - acc: 0.5813 - val_loss: 0.6734 - val_acc: 0.5729\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6650 - acc: 0.5859 - val_loss: 0.6731 - val_acc: 0.5733\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6647 - acc: 0.5853 - val_loss: 0.6753 - val_acc: 0.5725\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6643 - acc: 0.5831 - val_loss: 0.6715 - val_acc: 0.5691\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_75 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 11, 21, 6)     168         input_75[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)             (None, 1386)          0           conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_76 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_38 (Merge)                 (None, 1390)          0           flatten_38[0][0]                 \n",
      "                                                                   input_76[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_112 (Dense)                (None, 32)            44512       merge_38[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_113 (Dense)                (None, 32)            1056        dense_112[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_114 (Dense)                (None, 1)             33          dense_113[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6815 - acc: 0.5841 - val_loss: 0.6840 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6795 - acc: 0.5863 - val_loss: 0.6874 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6740 - acc: 0.5938 - val_loss: 0.6455 - val_acc: 0.7123\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5102 - acc: 0.7454 - val_loss: 0.4173 - val_acc: 0.7625\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3862 - acc: 0.7792 - val_loss: 0.3772 - val_acc: 0.7830\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3600 - acc: 0.7921 - val_loss: 0.3673 - val_acc: 0.7881\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3468 - acc: 0.8068 - val_loss: 0.3544 - val_acc: 0.8140\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3251 - acc: 0.8443 - val_loss: 0.3204 - val_acc: 0.8424\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2404 - acc: 0.9152 - val_loss: 0.1622 - val_acc: 0.9576\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1093 - acc: 0.9782 - val_loss: 0.0756 - val_acc: 0.9903\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0544 - acc: 0.9941 - val_loss: 0.0425 - val_acc: 0.9975\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0323 - acc: 0.9978 - val_loss: 0.0247 - val_acc: 0.9994\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0193 - acc: 0.9998 - val_loss: 0.0173 - val_acc: 0.9996\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0127 - acc: 0.9999 - val_loss: 0.0122 - val_acc: 0.9998\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_77 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 11, 21, 6)     168         input_77[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)             (None, 1386)          0           conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_78 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_39 (Merge)                 (None, 1390)          0           flatten_39[0][0]                 \n",
      "                                                                   input_78[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_115 (Dense)                (None, 32)            44512       merge_39[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_116 (Dense)                (None, 32)            1056        dense_115[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_117 (Dense)                (None, 1)             33          dense_116[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6810 - acc: 0.5811 - val_loss: 0.6855 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6757 - acc: 0.5898 - val_loss: 0.6474 - val_acc: 0.6487\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.5101 - acc: 0.7459 - val_loss: 0.4152 - val_acc: 0.7706\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3865 - acc: 0.7767 - val_loss: 0.3758 - val_acc: 0.7775\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3589 - acc: 0.7928 - val_loss: 0.3621 - val_acc: 0.7888\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3429 - acc: 0.8110 - val_loss: 0.3493 - val_acc: 0.8148\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3119 - acc: 0.8484 - val_loss: 0.2827 - val_acc: 0.8920\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1920 - acc: 0.9384 - val_loss: 0.1159 - val_acc: 0.9744\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0801 - acc: 0.9878 - val_loss: 0.0571 - val_acc: 0.9938\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0428 - acc: 0.9970 - val_loss: 0.0319 - val_acc: 0.9992\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0248 - acc: 0.9992 - val_loss: 0.0222 - val_acc: 0.9991\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0153 - acc: 0.9999 - val_loss: 0.0166 - val_acc: 0.9994\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_79 (InputLayer)            (None, 11, 21, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 11, 21, 6)     168         input_79[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)             (None, 1386)          0           conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_80 (InputLayer)            (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_40 (Merge)                 (None, 1390)          0           flatten_40[0][0]                 \n",
      "                                                                   input_80[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_118 (Dense)                (None, 32)            44512       merge_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_119 (Dense)                (None, 32)            1056        dense_118[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_120 (Dense)                (None, 1)             33          dense_119[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 45,769\n",
      "Trainable params: 45,769\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21120 samples, validate on 5280 samples\n",
      "Epoch 1/20\n",
      "21120/21120 [==============================] - 4s - loss: 0.6825 - acc: 0.5839 - val_loss: 0.6871 - val_acc: 0.5716\n",
      "Epoch 2/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6792 - acc: 0.5863 - val_loss: 0.6831 - val_acc: 0.5716\n",
      "Epoch 3/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.6316 - acc: 0.6447 - val_loss: 0.5002 - val_acc: 0.7559\n",
      "Epoch 4/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.4256 - acc: 0.7737 - val_loss: 0.3878 - val_acc: 0.7782\n",
      "Epoch 5/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3729 - acc: 0.7793 - val_loss: 0.3740 - val_acc: 0.7799\n",
      "Epoch 6/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3581 - acc: 0.7861 - val_loss: 0.3623 - val_acc: 0.7894\n",
      "Epoch 7/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.3343 - acc: 0.8136 - val_loss: 0.3213 - val_acc: 0.8288\n",
      "Epoch 8/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.2512 - acc: 0.9018 - val_loss: 0.1755 - val_acc: 0.9492\n",
      "Epoch 9/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.1167 - acc: 0.9743 - val_loss: 0.0752 - val_acc: 0.9877\n",
      "Epoch 10/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0566 - acc: 0.9926 - val_loss: 0.0450 - val_acc: 0.9924\n",
      "Epoch 11/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0307 - acc: 0.9974 - val_loss: 0.0249 - val_acc: 0.9973\n",
      "Epoch 12/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0185 - acc: 0.9990 - val_loss: 0.0143 - val_acc: 0.9996\n",
      "Epoch 13/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0114 - acc: 0.9997 - val_loss: 0.0099 - val_acc: 0.9996\n",
      "Epoch 14/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9998\n",
      "Epoch 15/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "21120/21120 [==============================] - 2s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "ego_info = np.zeros((num_exper,4,epochs))\n",
    "for i in range(num_exper):\n",
    "    c,x,z = createLayers(rest_size,conv_size,naction)\n",
    "\n",
    "    ego_classifier = Model(inputs=[c,x],outputs=z)\n",
    "\n",
    "    ego_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    ego_classifier.summary()\n",
    "\n",
    "    ego_history = ego_classifier.fit([all_simu['cnn_input'],all_simu['rest_input']],\n",
    "                                       all_simu['y'],epochs=epochs,batch_size=64,validation_split=0.2)\n",
    "    \n",
    "    ego_info[i,0,:] = ego_history.history['val_loss']\n",
    "    ego_info[i,1,:] = ego_history.history['val_acc']\n",
    "    ego_info[i,2,:] = ego_history.history['loss']\n",
    "    ego_info[i,3,:] = ego_history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31200, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('val_train_acc_loss_E.npz',allo=info,ego=ego_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from APES import *\n",
    "from time import time\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "ticks_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=15, weight='normal', stretch='normal')\n",
    "legend_font = font_manager.FontProperties(family='helvetica-light-587ebe5a59211', style='normal',\n",
    "    size=12, weight='normal', stretch='normal')\n",
    "hfont =  {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "csfont = {'fontname':'helvetica-light-587ebe5a59211'}\n",
    "def calculate(val,index):\n",
    "    mean = np.mean(val[:,index,:],axis=0)\n",
    "    std = np.std(val[:,index,:],axis=0)\n",
    "    return mean,std/np.sqrt(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = np.load('val_train_acc_loss_E.npz')\n",
    "ego_info = info['ego']\n",
    "info = info['allo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b64ae8aac50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avlm,avls = calculate(info,0)\n",
    "evlm,evls = calculate(ego_info,0)\n",
    "plt.plot(avlm,color='b',label='allo val loss')\n",
    "plt.fill_between(np.arange(20),avlm+avls,avlm-avls,alpha=0.2)\n",
    "\n",
    "plt.plot(evlm,color='r',label='ego val loss')\n",
    "plt.fill_between(np.arange(20),evlm+evls,evlm-evls,alpha=0.2)\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b64aea2e208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avam,avas = calculate(info,1)\n",
    "evam,evas = calculate(ego_info,1)\n",
    "plt.plot(avam,color='b',label='allo validation accuracy')\n",
    "plt.fill_between(np.arange(20),avam+avas,avam-avas,alpha=0.2)\n",
    "plt.plot(evam,color='r',label='ego validation accuracy')\n",
    "plt.fill_between(np.arange(20),evam+evas,evam-evas,alpha=0.2)\n",
    "atam,avas = calculate(info,3)\n",
    "etam,evas = calculate(ego_info,3)\n",
    "#plt.plot(atam,color='black',label='allo training accuracy')\n",
    "\n",
    "#plt.plot(etam,color='r',label='ego training accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
