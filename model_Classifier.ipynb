{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 5) 5 (8,)\n"
     ]
    }
   ],
   "source": [
    "Ego = False\n",
    "conv_size=(11,11,5,)\n",
    "rest_size=(0*5+8,)\n",
    "naction =  5\n",
    "print(conv_size,naction,rest_size)\n",
    "all_simu = np.load('ego:{}_simulation_26388_unique_E.npz'.format(Ego))\n",
    "cnn_input,rest_input,y= all_simu['cnn_input'],all_simu['rest_input'],all_simu['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10993, 15395])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(np.array(y[:,0],dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5834091253600121"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15395/(15395+10993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttt = np.load('ego:False_simulation_200000.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tttt['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143227,  56773])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(np.array(y,dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71613499999999997"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "143227/np.sum([143227,  56773])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-628c882ca1e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "np.bincount(y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Model(input_shape=(613,)):\n",
    "    x = Input(shape=input_shape)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    input_model = Model(inputs=[x],outputs=[out])\n",
    "    input_model.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    return input_model\n",
    "def Do_experiments(x,y,num_expr,epochs):\n",
    "    input_history= np.zeros((num_expr,4,epochs))\n",
    "    for i in range(num_expr):\n",
    "        model = Create_Model((x.shape[1],))\n",
    "        history = model.fit(x,y,epochs=epochs,batch_size=64,validation_split=0.2)\n",
    "        input_history[i,0,:] = history.history['val_loss']\n",
    "        input_history[i,1,:] = history.history['val_acc']\n",
    "        input_history[i,2,:] = history.history['loss']\n",
    "        input_history[i,3,:] = history.history['acc']\n",
    "    return input_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.concatenate([cnn_input.reshape((26388,-1)),rest_input],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_FC1 = np.load('FC1_data.npy')\n",
    "x_FC2 = np.load('FC2_data.npy')\n",
    "x_LSTM = np.load('LSTM_data.npy')\n",
    "x_FINAL = np.load('final.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6827 - acc: 0.5798 - val_loss: 0.6798 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6820 - acc: 0.5794 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6819 - acc: 0.5814 - val_loss: 0.6800 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5828 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5825 - val_loss: 0.6880 - val_acc: 0.5803\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6813 - acc: 0.5827 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6824 - acc: 0.5797 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6809 - acc: 0.5825 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6816 - acc: 0.5823 - val_loss: 0.6839 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6815 - acc: 0.5829 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5811 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6811 - acc: 0.5829 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5828 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5812 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5825 - val_loss: 0.6843 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5822 - val_loss: 0.6829 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6817 - acc: 0.5825 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5810 - val_loss: 0.6837 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6822 - acc: 0.5815 - val_loss: 0.6794 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5826 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6823 - acc: 0.5804 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6824 - acc: 0.5820 - val_loss: 0.6799 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6818 - acc: 0.5823 - val_loss: 0.6831 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 34us/step - loss: 0.6814 - acc: 0.5828 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5831 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6816 - acc: 0.5805 - val_loss: 0.6835 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5805 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6808 - acc: 0.5814 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6807 - acc: 0.5828 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6807 - acc: 0.5822 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5820 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6821 - acc: 0.5802 - val_loss: 0.6862 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6818 - acc: 0.5820 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5826 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5828 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5830 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5830 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 37us/step - loss: 0.6827 - acc: 0.5790 - val_loss: 0.6881 - val_acc: 0.5498\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6817 - acc: 0.5803 - val_loss: 0.6827 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5818 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6817 - acc: 0.5829 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5821 - val_loss: 0.6917 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6816 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6804 - acc: 0.5829 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5776 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5828 - val_loss: 0.6836 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5825 - val_loss: 0.6820 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6815 - acc: 0.5824 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5830 - val_loss: 0.6828 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6826 - acc: 0.5819 - val_loss: 0.6930 - val_acc: 0.5136\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6817 - acc: 0.5824 - val_loss: 0.6885 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6811 - acc: 0.5811 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5827 - val_loss: 0.6877 - val_acc: 0.5790\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6820 - acc: 0.5820 - val_loss: 0.6840 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6806 - acc: 0.5829 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6813 - acc: 0.5823 - val_loss: 0.6820 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 35us/step - loss: 0.6835 - acc: 0.5779 - val_loss: 0.6820 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6818 - acc: 0.5823 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5803 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6816 - acc: 0.5820 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5828 - val_loss: 0.6885 - val_acc: 0.5767\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5831 - val_loss: 0.6876 - val_acc: 0.5843\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5811 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5831 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6811 - acc: 0.5829 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6809 - acc: 0.5830 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6809 - acc: 0.5825 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5824 - val_loss: 0.6847 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6816 - acc: 0.5806 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6811 - acc: 0.5826 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6807 - acc: 0.5829 - val_loss: 0.6835 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6807 - acc: 0.5829 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6819 - acc: 0.5805 - val_loss: 0.6931 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6822 - acc: 0.5799 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 35us/step - loss: 0.6843 - acc: 0.5760 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5817 - val_loss: 0.6885 - val_acc: 0.5603\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5785 - val_loss: 0.6801 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6818 - acc: 0.5814 - val_loss: 0.6836 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6806 - acc: 0.5829 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6818 - acc: 0.5820 - val_loss: 0.6824 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5821 - val_loss: 0.6873 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6815 - acc: 0.5822 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5825 - val_loss: 0.6848 - val_acc: 0.5851\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6819 - acc: 0.5794 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5813 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6816 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6809 - acc: 0.5822 - val_loss: 0.6825 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6817 - acc: 0.5829 - val_loss: 0.6829 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6846 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6813 - acc: 0.5829 - val_loss: 0.6866 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6813 - acc: 0.5830 - val_loss: 0.6816 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6815 - acc: 0.5818 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6806 - acc: 0.5829 - val_loss: 0.6816 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 36us/step - loss: 0.6836 - acc: 0.5797 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6813 - acc: 0.5803 - val_loss: 0.6884 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6817 - acc: 0.5811 - val_loss: 0.6832 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5811 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6809 - acc: 0.5829 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5826 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6820 - acc: 0.5828 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6815 - acc: 0.5829 - val_loss: 0.6864 - val_acc: 0.5849\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5829 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5799 - val_loss: 0.6831 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5812 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5816 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5824 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6851 - val_acc: 0.5851\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5828 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5828 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5821 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6862 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5827 - val_loss: 0.6832 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 0.6827 - acc: 0.5813 - val_loss: 0.6791 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6820 - acc: 0.5832 - val_loss: 0.6868 - val_acc: 0.5784\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6821 - acc: 0.5811 - val_loss: 0.6797 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6822 - acc: 0.5796 - val_loss: 0.6801 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6820 - acc: 0.5830 - val_loss: 0.6840 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6828 - acc: 0.5810 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5820 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5827 - val_loss: 0.6823 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6826 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5822 - val_loss: 0.6849 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6809 - acc: 0.5827 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5823 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6811 - acc: 0.5830 - val_loss: 0.6827 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5820 - val_loss: 0.6816 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6805 - acc: 0.5820 - val_loss: 0.6975 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5820 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6813 - acc: 0.5825 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5826 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6808 - acc: 0.5828 - val_loss: 0.6828 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 39us/step - loss: 0.6820 - acc: 0.5817 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5828 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5811 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6807 - acc: 0.5829 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5826 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5816 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5831 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5819 - val_loss: 0.6843 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6818 - acc: 0.5824 - val_loss: 0.6826 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6805 - acc: 0.5828 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6813 - acc: 0.5821 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5823 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5817 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5826 - val_loss: 0.6846 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6820 - acc: 0.5792 - val_loss: 0.6821 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5794 - val_loss: 0.6839 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6821 - acc: 0.5828 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6811 - acc: 0.5793 - val_loss: 0.6824 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5829 - val_loss: 0.6825 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5828 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 39us/step - loss: 0.6826 - acc: 0.5815 - val_loss: 0.6842 - val_acc: 0.5818\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6828 - acc: 0.5808 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5816 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6828 - acc: 0.5775 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5830 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5828 - val_loss: 0.6881 - val_acc: 0.5801\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6813 - acc: 0.5820 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5831 - val_loss: 0.6824 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5828 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6813 - acc: 0.5811 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5828 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5825 - val_loss: 0.6827 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5826 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5818 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5820 - val_loss: 0.6856 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5817 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6814 - acc: 0.5812 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6821 - acc: 0.5822 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6818 - acc: 0.5800 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 41us/step - loss: 0.6827 - acc: 0.5796 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6821 - acc: 0.5810 - val_loss: 0.6800 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6818 - acc: 0.5824 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6815 - acc: 0.5813 - val_loss: 0.6799 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6809 - acc: 0.5828 - val_loss: 0.6818 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5829 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5820 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6812 - acc: 0.5831 - val_loss: 0.6865 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6804 - acc: 0.5830 - val_loss: 0.6893 - val_acc: 0.5716\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6811 - acc: 0.5816 - val_loss: 0.6910 - val_acc: 0.5483\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6814 - acc: 0.5829 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5810 - val_loss: 0.6840 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6816 - acc: 0.5820 - val_loss: 0.6842 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5827 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5830 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5830 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6810 - acc: 0.5828 - val_loss: 0.6845 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6815 - acc: 0.5821 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5828 - val_loss: 0.6849 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5819 - val_loss: 0.6823 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 42us/step - loss: 0.6827 - acc: 0.5810 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5826 - val_loss: 0.6838 - val_acc: 0.5851\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5811 - val_loss: 0.6821 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5824 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5810 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5826 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6823 - acc: 0.5826 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5830 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5829 - val_loss: 0.6824 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5829 - val_loss: 0.6831 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5792 - val_loss: 0.6830 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5822 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5829 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5810 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6818 - acc: 0.5802 - val_loss: 0.6847 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5828 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5831 - val_loss: 0.6855 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6826 - acc: 0.5813 - val_loss: 0.6920 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 0.6831 - acc: 0.5802 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6824 - acc: 0.5803 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5832 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6811 - acc: 0.5830 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5830 - val_loss: 0.6820 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5829 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6806 - acc: 0.5820 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5830 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6804 - acc: 0.5829 - val_loss: 0.6836 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6811 - acc: 0.5828 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6816 - acc: 0.5824 - val_loss: 0.6902 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6812 - acc: 0.5806 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5832 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6811 - acc: 0.5828 - val_loss: 0.6831 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6812 - acc: 0.5830 - val_loss: 0.6879 - val_acc: 0.5800\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6806 - acc: 0.5823 - val_loss: 0.6862 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6814 - acc: 0.5831 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5830 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5824 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6808 - acc: 0.5827 - val_loss: 0.6816 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6838 - acc: 0.5795 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6824 - acc: 0.5832 - val_loss: 0.6827 - val_acc: 0.5858\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5824 - val_loss: 0.6801 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6820 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5817 - val_loss: 0.6825 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5828 - val_loss: 0.6874 - val_acc: 0.5820\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5824 - val_loss: 0.6860 - val_acc: 0.5851\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5829 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5821 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5820 - val_loss: 0.6854 - val_acc: 0.5851\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5826 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6820 - acc: 0.5828 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5829 - val_loss: 0.6816 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5822 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6806 - acc: 0.5829 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5829 - val_loss: 0.6840 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6810 - acc: 0.5820 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5824 - val_loss: 0.6868 - val_acc: 0.5841\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6821 - acc: 0.5827 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6818 - acc: 0.5828 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6835 - acc: 0.5748 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5802 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5822 - val_loss: 0.6832 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5800 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6818 - acc: 0.5824 - val_loss: 0.6852 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6809 - acc: 0.5829 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5828 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5830 - val_loss: 0.6842 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6806 - acc: 0.5830 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6818 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6813 - acc: 0.5826 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5829 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5821 - val_loss: 0.6836 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5817 - val_loss: 0.6880 - val_acc: 0.5777\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5831 - val_loss: 0.6819 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6804 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5813 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 34us/step - loss: 0.6816 - acc: 0.5830 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5824 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6810 - acc: 0.5831 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6833 - acc: 0.5776 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5803 - val_loss: 0.6818 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5822 - val_loss: 0.6801 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5811 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5830 - val_loss: 0.6844 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5803 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6811 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6827 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5829 - val_loss: 0.6824 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5811 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5828 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5828 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5829 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5799 - val_loss: 0.6904 - val_acc: 0.5599\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6823 - acc: 0.5817 - val_loss: 0.6820 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6813 - acc: 0.5830 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6808 - acc: 0.5825 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5828 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6807 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6811 - acc: 0.5831 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6821 - acc: 0.5816 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5828 - val_loss: 0.6801 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5819 - val_loss: 0.6799 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6814 - acc: 0.5829 - val_loss: 0.6840 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 35us/step - loss: 0.6821 - acc: 0.5829 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6807 - acc: 0.5829 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5817 - val_loss: 0.6829 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6813 - acc: 0.5825 - val_loss: 0.6833 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6815 - acc: 0.5810 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 36us/step - loss: 0.6818 - acc: 0.5809 - val_loss: 0.6867 - val_acc: 0.5845\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6817 - acc: 0.5824 - val_loss: 0.6835 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6815 - acc: 0.5800 - val_loss: 0.6825 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6807 - acc: 0.5830 - val_loss: 0.6830 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5825 - val_loss: 0.6835 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5829 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6809 - acc: 0.5830 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6808 - acc: 0.5825 - val_loss: 0.6827 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5809 - val_loss: 0.6811 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5798 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6834 - acc: 0.5793 - val_loss: 0.6798 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6822 - acc: 0.5810 - val_loss: 0.6830 - val_acc: 0.5851\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6816 - acc: 0.5814 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6805 - acc: 0.5826 - val_loss: 0.6846 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5818 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5818 - val_loss: 0.6864 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5830 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5825 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5830 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5830 - val_loss: 0.6815 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5820 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6819 - acc: 0.5818 - val_loss: 0.6836 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6815 - acc: 0.5830 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6806 - acc: 0.5826 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5808 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5825 - val_loss: 0.6820 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6805 - acc: 0.5828 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 34us/step - loss: 0.6810 - acc: 0.5827 - val_loss: 0.6822 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6827 - acc: 0.5800 - val_loss: 0.6791 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6812 - acc: 0.5829 - val_loss: 0.6802 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5826 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6818 - acc: 0.5811 - val_loss: 0.6880 - val_acc: 0.5803\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6812 - acc: 0.5821 - val_loss: 0.6801 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5828 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6808 - acc: 0.5825 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6821 - acc: 0.5814 - val_loss: 0.6809 - val_acc: 0.5853\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5830 - val_loss: 0.6835 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6819 - acc: 0.5829 - val_loss: 0.6841 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5829 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6812 - acc: 0.5827 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6841 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5832 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 36us/step - loss: 0.6810 - acc: 0.5794 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6821 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5822 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6806 - acc: 0.5830 - val_loss: 0.6871 - val_acc: 0.5839\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5805 - val_loss: 0.6827 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6809 - acc: 0.5814 - val_loss: 0.6853 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6824 - acc: 0.5805 - val_loss: 0.6861 - val_acc: 0.5750\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6817 - acc: 0.5810 - val_loss: 0.6826 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5825 - val_loss: 0.6799 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5829 - val_loss: 0.6825 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6812 - acc: 0.5827 - val_loss: 0.6868 - val_acc: 0.5832\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5827 - val_loss: 0.6859 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6808 - acc: 0.5829 - val_loss: 0.6817 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5816 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6814 - acc: 0.5828 - val_loss: 0.6896 - val_acc: 0.5693\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6807 - acc: 0.5830 - val_loss: 0.6813 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6818 - acc: 0.5810 - val_loss: 0.6906 - val_acc: 0.5578\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6818 - acc: 0.5827 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6808 - acc: 0.5815 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5830 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5827 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6814 - acc: 0.5809 - val_loss: 0.6830 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6818 - acc: 0.5805 - val_loss: 0.6872 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6810 - acc: 0.5824 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6834 - acc: 0.5796 - val_loss: 0.6865 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6818 - acc: 0.5824 - val_loss: 0.6798 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5822 - val_loss: 0.6810 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6814 - acc: 0.5820 - val_loss: 0.6801 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6823 - acc: 0.5807 - val_loss: 0.6803 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6805 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6813 - acc: 0.5829 - val_loss: 0.6804 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6810 - acc: 0.5829 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5830 - val_loss: 0.6839 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6809 - acc: 0.5822 - val_loss: 0.6861 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6814 - acc: 0.5827 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6807 - acc: 0.5826 - val_loss: 0.6807 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6806 - acc: 0.5829 - val_loss: 0.6814 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6811 - acc: 0.5811 - val_loss: 0.6877 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6806 - acc: 0.5826 - val_loss: 0.6806 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6809 - acc: 0.5791 - val_loss: 0.6808 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6816 - acc: 0.5824 - val_loss: 0.6818 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6816 - acc: 0.5823 - val_loss: 0.6812 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6827 - acc: 0.5807 - val_loss: 0.6856 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6810 - acc: 0.5826 - val_loss: 0.6807 - val_acc: 0.5853\n"
     ]
    }
   ],
   "source": [
    "num_expr = 20\n",
    "epochs=20\n",
    "input_history= Do_experiments(x_input,y,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.7201 - acc: 0.5553 - val_loss: 0.6848 - val_acc: 0.5794\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6751 - acc: 0.5901 - val_loss: 0.6609 - val_acc: 0.6034\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6603 - acc: 0.6123 - val_loss: 0.6499 - val_acc: 0.6283\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6532 - acc: 0.6303 - val_loss: 0.6445 - val_acc: 0.6377\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6499 - acc: 0.6338 - val_loss: 0.6420 - val_acc: 0.6419\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6484 - acc: 0.6347 - val_loss: 0.6410 - val_acc: 0.6461\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6472 - acc: 0.6367 - val_loss: 0.6400 - val_acc: 0.6453\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6466 - acc: 0.6382 - val_loss: 0.6391 - val_acc: 0.6508\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6463 - acc: 0.6388 - val_loss: 0.6385 - val_acc: 0.6521\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6386 - val_loss: 0.6390 - val_acc: 0.6461\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6458 - acc: 0.6376 - val_loss: 0.6382 - val_acc: 0.6459\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6369 - val_loss: 0.6381 - val_acc: 0.6466\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6352 - val_loss: 0.6383 - val_acc: 0.6453\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6455 - acc: 0.6391 - val_loss: 0.6378 - val_acc: 0.6457\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 25us/step - loss: 0.6455 - acc: 0.6386 - val_loss: 0.6382 - val_acc: 0.6457\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 25us/step - loss: 0.6454 - acc: 0.6387 - val_loss: 0.6375 - val_acc: 0.6516\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6450 - acc: 0.6398 - val_loss: 0.6380 - val_acc: 0.6448\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6453 - acc: 0.6389 - val_loss: 0.6380 - val_acc: 0.6444\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6451 - acc: 0.6351 - val_loss: 0.6373 - val_acc: 0.6533\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6452 - acc: 0.6393 - val_loss: 0.6379 - val_acc: 0.6451\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 58us/step - loss: 0.6952 - acc: 0.5645 - val_loss: 0.6681 - val_acc: 0.5858\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6661 - acc: 0.6012 - val_loss: 0.6537 - val_acc: 0.6268\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6560 - acc: 0.6214 - val_loss: 0.6469 - val_acc: 0.6376\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6512 - acc: 0.6267 - val_loss: 0.6440 - val_acc: 0.6349\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6491 - acc: 0.6315 - val_loss: 0.6415 - val_acc: 0.6502\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6478 - acc: 0.6356 - val_loss: 0.6407 - val_acc: 0.6491\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6473 - acc: 0.6367 - val_loss: 0.6401 - val_acc: 0.6499\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6469 - acc: 0.6382 - val_loss: 0.6396 - val_acc: 0.6442\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6468 - acc: 0.6366 - val_loss: 0.6393 - val_acc: 0.6468\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6465 - acc: 0.6382 - val_loss: 0.6395 - val_acc: 0.6444\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6466 - acc: 0.6384 - val_loss: 0.6389 - val_acc: 0.6463\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6465 - acc: 0.6378 - val_loss: 0.6389 - val_acc: 0.6491\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6464 - acc: 0.6354 - val_loss: 0.6391 - val_acc: 0.6404\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6464 - acc: 0.6366 - val_loss: 0.6391 - val_acc: 0.6459\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6463 - acc: 0.6362 - val_loss: 0.6387 - val_acc: 0.6495\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6465 - acc: 0.6361 - val_loss: 0.6385 - val_acc: 0.6485\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6463 - acc: 0.6360 - val_loss: 0.6384 - val_acc: 0.6480\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6376 - val_loss: 0.6385 - val_acc: 0.6425\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6463 - acc: 0.6365 - val_loss: 0.6387 - val_acc: 0.6448\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6370 - val_loss: 0.6385 - val_acc: 0.6438\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 61us/step - loss: 0.6993 - acc: 0.5703 - val_loss: 0.6703 - val_acc: 0.6031\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6723 - acc: 0.5987 - val_loss: 0.6556 - val_acc: 0.6213\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6610 - acc: 0.6114 - val_loss: 0.6476 - val_acc: 0.6368\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6547 - acc: 0.6206 - val_loss: 0.6436 - val_acc: 0.6398\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6514 - acc: 0.6253 - val_loss: 0.6425 - val_acc: 0.6449\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6498 - acc: 0.6277 - val_loss: 0.6402 - val_acc: 0.6465\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6483 - acc: 0.6334 - val_loss: 0.6400 - val_acc: 0.6491\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6475 - acc: 0.6325 - val_loss: 0.6390 - val_acc: 0.6485\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6470 - acc: 0.6341 - val_loss: 0.6388 - val_acc: 0.6476\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6467 - acc: 0.6353 - val_loss: 0.6388 - val_acc: 0.6463\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6465 - acc: 0.6353 - val_loss: 0.6384 - val_acc: 0.6501\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6464 - acc: 0.6329 - val_loss: 0.6383 - val_acc: 0.6529\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6464 - acc: 0.6354 - val_loss: 0.6386 - val_acc: 0.6480\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6374 - val_loss: 0.6384 - val_acc: 0.6444\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6357 - val_loss: 0.6382 - val_acc: 0.6474\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6356 - val_loss: 0.6382 - val_acc: 0.6482\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6459 - acc: 0.6364 - val_loss: 0.6383 - val_acc: 0.6453\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6351 - val_loss: 0.6382 - val_acc: 0.6444\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6359 - val_loss: 0.6386 - val_acc: 0.6472\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6360 - val_loss: 0.6379 - val_acc: 0.6506\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.7311 - acc: 0.5234 - val_loss: 0.6883 - val_acc: 0.5396\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6780 - acc: 0.5673 - val_loss: 0.6590 - val_acc: 0.6048\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6596 - acc: 0.6100 - val_loss: 0.6485 - val_acc: 0.6239\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6528 - acc: 0.6244 - val_loss: 0.6434 - val_acc: 0.6425\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6500 - acc: 0.6306 - val_loss: 0.6420 - val_acc: 0.6529\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6482 - acc: 0.6345 - val_loss: 0.6412 - val_acc: 0.6538\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6475 - acc: 0.6363 - val_loss: 0.6398 - val_acc: 0.6489\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6469 - acc: 0.6362 - val_loss: 0.6392 - val_acc: 0.6506\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6465 - acc: 0.6365 - val_loss: 0.6395 - val_acc: 0.6459\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6465 - acc: 0.6399 - val_loss: 0.6389 - val_acc: 0.6453\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6378 - val_loss: 0.6386 - val_acc: 0.6461\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6389 - val_loss: 0.6383 - val_acc: 0.6495\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6345 - val_loss: 0.6390 - val_acc: 0.6396\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6387 - val_loss: 0.6380 - val_acc: 0.6501\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6363 - val_loss: 0.6383 - val_acc: 0.6459\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6458 - acc: 0.6388 - val_loss: 0.6391 - val_acc: 0.6495\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6459 - acc: 0.6357 - val_loss: 0.6381 - val_acc: 0.6508\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6380 - val_loss: 0.6384 - val_acc: 0.6482\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6458 - acc: 0.6382 - val_loss: 0.6379 - val_acc: 0.6455\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6459 - acc: 0.6371 - val_loss: 0.6399 - val_acc: 0.6459\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 64us/step - loss: 0.7420 - acc: 0.6081 - val_loss: 0.6807 - val_acc: 0.5868\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6714 - acc: 0.5914 - val_loss: 0.6557 - val_acc: 0.6163\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6571 - acc: 0.6137 - val_loss: 0.6456 - val_acc: 0.6317\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6511 - acc: 0.6228 - val_loss: 0.6414 - val_acc: 0.6446\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6483 - acc: 0.6321 - val_loss: 0.6395 - val_acc: 0.6487\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6471 - acc: 0.6358 - val_loss: 0.6381 - val_acc: 0.6504\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6376 - val_loss: 0.6383 - val_acc: 0.6419\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6458 - acc: 0.6399 - val_loss: 0.6372 - val_acc: 0.6535\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6384 - val_loss: 0.6373 - val_acc: 0.6468\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6454 - acc: 0.6376 - val_loss: 0.6374 - val_acc: 0.6459\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6455 - acc: 0.6387 - val_loss: 0.6372 - val_acc: 0.6501\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6451 - acc: 0.6390 - val_loss: 0.6374 - val_acc: 0.6448\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6453 - acc: 0.6383 - val_loss: 0.6373 - val_acc: 0.6497\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6453 - acc: 0.6395 - val_loss: 0.6371 - val_acc: 0.6535\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6449 - acc: 0.6410 - val_loss: 0.6377 - val_acc: 0.6453\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6451 - acc: 0.6367 - val_loss: 0.6373 - val_acc: 0.6429\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6452 - acc: 0.6376 - val_loss: 0.6374 - val_acc: 0.6438\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6449 - acc: 0.6359 - val_loss: 0.6374 - val_acc: 0.6502\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6450 - acc: 0.6371 - val_loss: 0.6375 - val_acc: 0.6463\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6449 - acc: 0.6377 - val_loss: 0.6371 - val_acc: 0.6510\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 65us/step - loss: 0.7234 - acc: 0.5609 - val_loss: 0.6829 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6672 - acc: 0.5993 - val_loss: 0.6580 - val_acc: 0.6165\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6546 - acc: 0.6214 - val_loss: 0.6488 - val_acc: 0.6330\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6497 - acc: 0.6277 - val_loss: 0.6441 - val_acc: 0.6360\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6475 - acc: 0.6294 - val_loss: 0.6426 - val_acc: 0.6372\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6467 - acc: 0.6337 - val_loss: 0.6411 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6459 - acc: 0.6360 - val_loss: 0.6402 - val_acc: 0.6398\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6347 - val_loss: 0.6392 - val_acc: 0.6436\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6455 - acc: 0.6364 - val_loss: 0.6391 - val_acc: 0.6423\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6453 - acc: 0.6382 - val_loss: 0.6384 - val_acc: 0.6423\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6453 - acc: 0.6366 - val_loss: 0.6387 - val_acc: 0.6448\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6451 - acc: 0.6367 - val_loss: 0.6381 - val_acc: 0.6520\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6451 - acc: 0.6376 - val_loss: 0.6384 - val_acc: 0.6451\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6452 - acc: 0.6382 - val_loss: 0.6377 - val_acc: 0.6482\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6451 - acc: 0.6372 - val_loss: 0.6383 - val_acc: 0.6444\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6452 - acc: 0.6385 - val_loss: 0.6377 - val_acc: 0.6491\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6451 - acc: 0.6383 - val_loss: 0.6378 - val_acc: 0.6457\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6450 - acc: 0.6372 - val_loss: 0.6375 - val_acc: 0.6497\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6450 - acc: 0.6377 - val_loss: 0.6376 - val_acc: 0.6427\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6451 - acc: 0.6373 - val_loss: 0.6377 - val_acc: 0.6434\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 66us/step - loss: 0.7360 - acc: 0.5294 - val_loss: 0.6905 - val_acc: 0.5629\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6801 - acc: 0.5682 - val_loss: 0.6650 - val_acc: 0.5953\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6632 - acc: 0.5963 - val_loss: 0.6523 - val_acc: 0.6116\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6550 - acc: 0.6138 - val_loss: 0.6464 - val_acc: 0.6345\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6509 - acc: 0.6252 - val_loss: 0.6430 - val_acc: 0.6446\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6484 - acc: 0.6319 - val_loss: 0.6423 - val_acc: 0.6304\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6476 - acc: 0.6337 - val_loss: 0.6397 - val_acc: 0.6489\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6468 - acc: 0.6383 - val_loss: 0.6400 - val_acc: 0.6453\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6463 - acc: 0.6371 - val_loss: 0.6396 - val_acc: 0.6446\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6390 - val_loss: 0.6393 - val_acc: 0.6459\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6403 - val_loss: 0.6385 - val_acc: 0.6432\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6375 - val_loss: 0.6383 - val_acc: 0.6425\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6381 - val_loss: 0.6382 - val_acc: 0.6442\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6457 - acc: 0.6374 - val_loss: 0.6379 - val_acc: 0.6504\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6369 - val_loss: 0.6380 - val_acc: 0.6497\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6457 - acc: 0.6370 - val_loss: 0.6380 - val_acc: 0.6504\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6457 - acc: 0.6386 - val_loss: 0.6379 - val_acc: 0.6504\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6454 - acc: 0.6369 - val_loss: 0.6379 - val_acc: 0.6466\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6454 - acc: 0.6358 - val_loss: 0.6378 - val_acc: 0.6476\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6366 - val_loss: 0.6381 - val_acc: 0.6466\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 70us/step - loss: 0.7384 - acc: 0.5397 - val_loss: 0.7029 - val_acc: 0.5599\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6820 - acc: 0.5728 - val_loss: 0.6725 - val_acc: 0.5834\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6641 - acc: 0.5968 - val_loss: 0.6574 - val_acc: 0.6063\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6553 - acc: 0.6088 - val_loss: 0.6504 - val_acc: 0.6277\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6511 - acc: 0.6221 - val_loss: 0.6451 - val_acc: 0.6311\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6490 - acc: 0.6252 - val_loss: 0.6434 - val_acc: 0.6438\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6477 - acc: 0.6301 - val_loss: 0.6418 - val_acc: 0.6476\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6469 - acc: 0.6337 - val_loss: 0.6408 - val_acc: 0.6463\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6466 - acc: 0.6358 - val_loss: 0.6400 - val_acc: 0.6457\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6464 - acc: 0.6377 - val_loss: 0.6392 - val_acc: 0.6451\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6460 - acc: 0.6369 - val_loss: 0.6391 - val_acc: 0.6468\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6458 - acc: 0.6390 - val_loss: 0.6396 - val_acc: 0.6440\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6371 - val_loss: 0.6391 - val_acc: 0.6432\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6384 - val_loss: 0.6391 - val_acc: 0.6442\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6349 - val_loss: 0.6385 - val_acc: 0.6440\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6457 - acc: 0.6356 - val_loss: 0.6389 - val_acc: 0.6440\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6380 - val_loss: 0.6383 - val_acc: 0.6474\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6358 - val_loss: 0.6383 - val_acc: 0.6465\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6458 - acc: 0.6383 - val_loss: 0.6380 - val_acc: 0.6470\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6370 - val_loss: 0.6380 - val_acc: 0.6474\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 70us/step - loss: 0.7553 - acc: 0.5081 - val_loss: 0.6995 - val_acc: 0.5500\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6872 - acc: 0.5690 - val_loss: 0.6695 - val_acc: 0.6033\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6669 - acc: 0.5996 - val_loss: 0.6555 - val_acc: 0.6239\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6568 - acc: 0.6119 - val_loss: 0.6474 - val_acc: 0.6296\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6518 - acc: 0.6206 - val_loss: 0.6440 - val_acc: 0.6453\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6491 - acc: 0.6264 - val_loss: 0.6408 - val_acc: 0.6463\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6477 - acc: 0.6321 - val_loss: 0.6401 - val_acc: 0.6463\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6467 - acc: 0.6336 - val_loss: 0.6392 - val_acc: 0.6459\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6354 - val_loss: 0.6384 - val_acc: 0.6489\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6459 - acc: 0.6365 - val_loss: 0.6386 - val_acc: 0.6429\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6354 - val_loss: 0.6379 - val_acc: 0.6495\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6456 - acc: 0.6359 - val_loss: 0.6382 - val_acc: 0.6474\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6367 - val_loss: 0.6385 - val_acc: 0.6457\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6360 - val_loss: 0.6383 - val_acc: 0.6470\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6454 - acc: 0.6387 - val_loss: 0.6378 - val_acc: 0.6470\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6453 - acc: 0.6356 - val_loss: 0.6377 - val_acc: 0.6497\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6452 - acc: 0.6371 - val_loss: 0.6380 - val_acc: 0.6387\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6453 - acc: 0.6386 - val_loss: 0.6375 - val_acc: 0.6512\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6453 - acc: 0.6376 - val_loss: 0.6376 - val_acc: 0.6425\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6452 - acc: 0.6376 - val_loss: 0.6376 - val_acc: 0.6484\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 72us/step - loss: 0.7269 - acc: 0.5315 - val_loss: 0.6865 - val_acc: 0.5659\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6757 - acc: 0.5863 - val_loss: 0.6636 - val_acc: 0.6002\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6618 - acc: 0.6085 - val_loss: 0.6526 - val_acc: 0.6220\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6553 - acc: 0.6189 - val_loss: 0.6472 - val_acc: 0.6313\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6520 - acc: 0.6251 - val_loss: 0.6441 - val_acc: 0.6362\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6497 - acc: 0.6314 - val_loss: 0.6422 - val_acc: 0.6472\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6485 - acc: 0.6334 - val_loss: 0.6409 - val_acc: 0.6478\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6478 - acc: 0.6361 - val_loss: 0.6400 - val_acc: 0.6442\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6470 - acc: 0.6348 - val_loss: 0.6396 - val_acc: 0.6489\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6465 - acc: 0.6350 - val_loss: 0.6396 - val_acc: 0.6499\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6375 - val_loss: 0.6386 - val_acc: 0.6523\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6359 - val_loss: 0.6383 - val_acc: 0.6527\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6459 - acc: 0.6374 - val_loss: 0.6384 - val_acc: 0.6512\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6457 - acc: 0.6376 - val_loss: 0.6381 - val_acc: 0.6487\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6369 - val_loss: 0.6381 - val_acc: 0.6472\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6455 - acc: 0.6349 - val_loss: 0.6377 - val_acc: 0.6520\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6452 - acc: 0.6369 - val_loss: 0.6378 - val_acc: 0.6569\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6454 - acc: 0.6395 - val_loss: 0.6378 - val_acc: 0.6527\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6453 - acc: 0.6385 - val_loss: 0.6378 - val_acc: 0.6487\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6454 - acc: 0.6382 - val_loss: 0.6380 - val_acc: 0.6449\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 68us/step - loss: 0.7220 - acc: 0.5622 - val_loss: 0.6892 - val_acc: 0.5765\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6777 - acc: 0.5883 - val_loss: 0.6659 - val_acc: 0.6061\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6626 - acc: 0.6140 - val_loss: 0.6550 - val_acc: 0.6228\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6552 - acc: 0.6227 - val_loss: 0.6497 - val_acc: 0.6317\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6514 - acc: 0.6258 - val_loss: 0.6456 - val_acc: 0.6332\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6494 - acc: 0.6287 - val_loss: 0.6436 - val_acc: 0.6410\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6480 - acc: 0.6324 - val_loss: 0.6422 - val_acc: 0.6429\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6473 - acc: 0.6361 - val_loss: 0.6417 - val_acc: 0.6421\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6469 - acc: 0.6349 - val_loss: 0.6407 - val_acc: 0.6446\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6466 - acc: 0.6360 - val_loss: 0.6400 - val_acc: 0.6497\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6354 - val_loss: 0.6399 - val_acc: 0.6421\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6461 - acc: 0.6355 - val_loss: 0.6391 - val_acc: 0.6466\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6343 - val_loss: 0.6393 - val_acc: 0.6466\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6351 - val_loss: 0.6391 - val_acc: 0.6430\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6357 - val_loss: 0.6386 - val_acc: 0.6480\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6364 - val_loss: 0.6386 - val_acc: 0.6465\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6348 - val_loss: 0.6384 - val_acc: 0.6400\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6363 - val_loss: 0.6383 - val_acc: 0.6415\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6360 - val_loss: 0.6392 - val_acc: 0.6446\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6455 - acc: 0.6390 - val_loss: 0.6391 - val_acc: 0.6396\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 1s 67us/step - loss: 0.7812 - acc: 0.5288 - val_loss: 0.7060 - val_acc: 0.5428\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 24us/step - loss: 0.6887 - acc: 0.5678 - val_loss: 0.6703 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6661 - acc: 0.6032 - val_loss: 0.6559 - val_acc: 0.6211\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6561 - acc: 0.6224 - val_loss: 0.6482 - val_acc: 0.6360\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6514 - acc: 0.6282 - val_loss: 0.6440 - val_acc: 0.6389\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6489 - acc: 0.6307 - val_loss: 0.6415 - val_acc: 0.6448\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6476 - acc: 0.6324 - val_loss: 0.6402 - val_acc: 0.6487\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6469 - acc: 0.6343 - val_loss: 0.6398 - val_acc: 0.6504\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6464 - acc: 0.6336 - val_loss: 0.6390 - val_acc: 0.6472\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6462 - acc: 0.6361 - val_loss: 0.6397 - val_acc: 0.6474\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6461 - acc: 0.6353 - val_loss: 0.6386 - val_acc: 0.6497\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6365 - val_loss: 0.6387 - val_acc: 0.6470\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6460 - acc: 0.6356 - val_loss: 0.6390 - val_acc: 0.6434\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6459 - acc: 0.6378 - val_loss: 0.6387 - val_acc: 0.6453\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6457 - acc: 0.6384 - val_loss: 0.6380 - val_acc: 0.6523\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6351 - val_loss: 0.6380 - val_acc: 0.6523\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6457 - acc: 0.6376 - val_loss: 0.6382 - val_acc: 0.6427\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6380 - val_loss: 0.6384 - val_acc: 0.6436\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6340 - val_loss: 0.6381 - val_acc: 0.6461\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6362 - val_loss: 0.6384 - val_acc: 0.6451\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 77us/step - loss: 0.7467 - acc: 0.5249 - val_loss: 0.7052 - val_acc: 0.5445\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6903 - acc: 0.5654 - val_loss: 0.6731 - val_acc: 0.5955\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6685 - acc: 0.6021 - val_loss: 0.6579 - val_acc: 0.6171\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6581 - acc: 0.6161 - val_loss: 0.6488 - val_acc: 0.6290\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6527 - acc: 0.6248 - val_loss: 0.6454 - val_acc: 0.6358\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6500 - acc: 0.6298 - val_loss: 0.6422 - val_acc: 0.6468\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6486 - acc: 0.6324 - val_loss: 0.6410 - val_acc: 0.6425\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6476 - acc: 0.6363 - val_loss: 0.6400 - val_acc: 0.6468\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6470 - acc: 0.6350 - val_loss: 0.6390 - val_acc: 0.6516\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6464 - acc: 0.6373 - val_loss: 0.6385 - val_acc: 0.6531\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6387 - val_loss: 0.6387 - val_acc: 0.6470\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6461 - acc: 0.6354 - val_loss: 0.6382 - val_acc: 0.6495\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6377 - val_loss: 0.6385 - val_acc: 0.6485\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6372 - val_loss: 0.6381 - val_acc: 0.6451\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6401 - val_loss: 0.6383 - val_acc: 0.6432\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6379 - val_loss: 0.6378 - val_acc: 0.6468\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6454 - acc: 0.6355 - val_loss: 0.6377 - val_acc: 0.6535\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6370 - val_loss: 0.6378 - val_acc: 0.6472\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6455 - acc: 0.6370 - val_loss: 0.6376 - val_acc: 0.6510\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6454 - acc: 0.6390 - val_loss: 0.6379 - val_acc: 0.6480\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 80us/step - loss: 0.7271 - acc: 0.5546 - val_loss: 0.6643 - val_acc: 0.5947\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6674 - acc: 0.5965 - val_loss: 0.6498 - val_acc: 0.6273\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6567 - acc: 0.6192 - val_loss: 0.6440 - val_acc: 0.6436\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6517 - acc: 0.6314 - val_loss: 0.6416 - val_acc: 0.6404\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6498 - acc: 0.6353 - val_loss: 0.6422 - val_acc: 0.6438\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6484 - acc: 0.6347 - val_loss: 0.6393 - val_acc: 0.6514\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6476 - acc: 0.6360 - val_loss: 0.6386 - val_acc: 0.6548\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6471 - acc: 0.6391 - val_loss: 0.6389 - val_acc: 0.6466\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6469 - acc: 0.6365 - val_loss: 0.6389 - val_acc: 0.6484\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6468 - acc: 0.6381 - val_loss: 0.6382 - val_acc: 0.6514\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6466 - acc: 0.6388 - val_loss: 0.6382 - val_acc: 0.6465\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6358 - val_loss: 0.6382 - val_acc: 0.6499\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6464 - acc: 0.6362 - val_loss: 0.6383 - val_acc: 0.6468\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6462 - acc: 0.6360 - val_loss: 0.6380 - val_acc: 0.6501\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6377 - val_loss: 0.6380 - val_acc: 0.6470\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6461 - acc: 0.6377 - val_loss: 0.6380 - val_acc: 0.6502\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6461 - acc: 0.6380 - val_loss: 0.6384 - val_acc: 0.6466\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6460 - acc: 0.6376 - val_loss: 0.6381 - val_acc: 0.6506\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6460 - acc: 0.6362 - val_loss: 0.6380 - val_acc: 0.6463\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6379 - val_loss: 0.6380 - val_acc: 0.6415\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 83us/step - loss: 0.7017 - acc: 0.5814 - val_loss: 0.6788 - val_acc: 0.6112\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6717 - acc: 0.6055 - val_loss: 0.6611 - val_acc: 0.6245\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6596 - acc: 0.6138 - val_loss: 0.6514 - val_acc: 0.6194\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6532 - acc: 0.6146 - val_loss: 0.6463 - val_acc: 0.6288\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6500 - acc: 0.6234 - val_loss: 0.6435 - val_acc: 0.6338\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6482 - acc: 0.6284 - val_loss: 0.6417 - val_acc: 0.6394\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6472 - acc: 0.6282 - val_loss: 0.6408 - val_acc: 0.6459\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6466 - acc: 0.6344 - val_loss: 0.6400 - val_acc: 0.6438\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6351 - val_loss: 0.6393 - val_acc: 0.6461\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6464 - acc: 0.6345 - val_loss: 0.6390 - val_acc: 0.6419\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6460 - acc: 0.6355 - val_loss: 0.6386 - val_acc: 0.6427\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6460 - acc: 0.6347 - val_loss: 0.6384 - val_acc: 0.6476\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6461 - acc: 0.6355 - val_loss: 0.6393 - val_acc: 0.6429\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6460 - acc: 0.6358 - val_loss: 0.6384 - val_acc: 0.6429\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6356 - val_loss: 0.6383 - val_acc: 0.6480\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6458 - acc: 0.6370 - val_loss: 0.6391 - val_acc: 0.6455\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6460 - acc: 0.6380 - val_loss: 0.6381 - val_acc: 0.6442\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6346 - val_loss: 0.6382 - val_acc: 0.6446\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6384 - val_loss: 0.6381 - val_acc: 0.6440\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6459 - acc: 0.6405 - val_loss: 0.6385 - val_acc: 0.6455\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 76us/step - loss: 0.7738 - acc: 0.5443 - val_loss: 0.6863 - val_acc: 0.5826\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6729 - acc: 0.5987 - val_loss: 0.6598 - val_acc: 0.6120\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6594 - acc: 0.6124 - val_loss: 0.6507 - val_acc: 0.6296\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6543 - acc: 0.6203 - val_loss: 0.6460 - val_acc: 0.6326\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6516 - acc: 0.6260 - val_loss: 0.6437 - val_acc: 0.6448\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6502 - acc: 0.6305 - val_loss: 0.6422 - val_acc: 0.6487\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6491 - acc: 0.6330 - val_loss: 0.6413 - val_acc: 0.6472\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6484 - acc: 0.6344 - val_loss: 0.6414 - val_acc: 0.6501\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6479 - acc: 0.6353 - val_loss: 0.6399 - val_acc: 0.6466\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6476 - acc: 0.6342 - val_loss: 0.6398 - val_acc: 0.6491\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6471 - acc: 0.6344 - val_loss: 0.6399 - val_acc: 0.6463\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6472 - acc: 0.6365 - val_loss: 0.6392 - val_acc: 0.6489\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6468 - acc: 0.6367 - val_loss: 0.6388 - val_acc: 0.6529\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6468 - acc: 0.6370 - val_loss: 0.6389 - val_acc: 0.6512\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6467 - acc: 0.6351 - val_loss: 0.6390 - val_acc: 0.6484\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6466 - acc: 0.6364 - val_loss: 0.6393 - val_acc: 0.6457\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6464 - acc: 0.6355 - val_loss: 0.6393 - val_acc: 0.6461\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6465 - acc: 0.6369 - val_loss: 0.6388 - val_acc: 0.6491\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6362 - val_loss: 0.6382 - val_acc: 0.6510\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6464 - acc: 0.6360 - val_loss: 0.6390 - val_acc: 0.6485\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 86us/step - loss: 0.6981 - acc: 0.5453 - val_loss: 0.6693 - val_acc: 0.5885\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6642 - acc: 0.5988 - val_loss: 0.6525 - val_acc: 0.6177\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6543 - acc: 0.6197 - val_loss: 0.6465 - val_acc: 0.6389\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6505 - acc: 0.6281 - val_loss: 0.6429 - val_acc: 0.6478\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6486 - acc: 0.6315 - val_loss: 0.6411 - val_acc: 0.6438\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6479 - acc: 0.6339 - val_loss: 0.6403 - val_acc: 0.6520\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6473 - acc: 0.6341 - val_loss: 0.6397 - val_acc: 0.6489\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6470 - acc: 0.6375 - val_loss: 0.6395 - val_acc: 0.6470\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6467 - acc: 0.6363 - val_loss: 0.6397 - val_acc: 0.6468\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6467 - acc: 0.6352 - val_loss: 0.6392 - val_acc: 0.6472\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6465 - acc: 0.6363 - val_loss: 0.6391 - val_acc: 0.6449\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6465 - acc: 0.6373 - val_loss: 0.6387 - val_acc: 0.6472\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6366 - val_loss: 0.6390 - val_acc: 0.6457\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6463 - acc: 0.6372 - val_loss: 0.6390 - val_acc: 0.6457\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6464 - acc: 0.6340 - val_loss: 0.6390 - val_acc: 0.6438\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6460 - acc: 0.6361 - val_loss: 0.6390 - val_acc: 0.6440\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6462 - acc: 0.6357 - val_loss: 0.6385 - val_acc: 0.6442\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6363 - val_loss: 0.6385 - val_acc: 0.6427\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6462 - acc: 0.6348 - val_loss: 0.6383 - val_acc: 0.6461\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6460 - acc: 0.6380 - val_loss: 0.6385 - val_acc: 0.6419\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 89us/step - loss: 0.7406 - acc: 0.5504 - val_loss: 0.6819 - val_acc: 0.5911\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6785 - acc: 0.5884 - val_loss: 0.6634 - val_acc: 0.6036\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 35us/step - loss: 0.6642 - acc: 0.6003 - val_loss: 0.6536 - val_acc: 0.6203\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6567 - acc: 0.6148 - val_loss: 0.6484 - val_acc: 0.6260\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6526 - acc: 0.6196 - val_loss: 0.6463 - val_acc: 0.6379\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6506 - acc: 0.6247 - val_loss: 0.6436 - val_acc: 0.6387\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6490 - acc: 0.6304 - val_loss: 0.6425 - val_acc: 0.6446\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6482 - acc: 0.6303 - val_loss: 0.6421 - val_acc: 0.6413\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6477 - acc: 0.6350 - val_loss: 0.6410 - val_acc: 0.6478\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6472 - acc: 0.6339 - val_loss: 0.6405 - val_acc: 0.6493\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6471 - acc: 0.6363 - val_loss: 0.6402 - val_acc: 0.6415\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6469 - acc: 0.6332 - val_loss: 0.6400 - val_acc: 0.6417\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6468 - acc: 0.6349 - val_loss: 0.6393 - val_acc: 0.6421\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6465 - acc: 0.6351 - val_loss: 0.6392 - val_acc: 0.6425\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6465 - acc: 0.6362 - val_loss: 0.6397 - val_acc: 0.6415\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6464 - acc: 0.6342 - val_loss: 0.6399 - val_acc: 0.6413\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6344 - val_loss: 0.6389 - val_acc: 0.6453\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6462 - acc: 0.6352 - val_loss: 0.6390 - val_acc: 0.6451\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6465 - acc: 0.6366 - val_loss: 0.6390 - val_acc: 0.6394\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6461 - acc: 0.6381 - val_loss: 0.6386 - val_acc: 0.6448\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 91us/step - loss: 0.7397 - acc: 0.5360 - val_loss: 0.6844 - val_acc: 0.5786\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6745 - acc: 0.5795 - val_loss: 0.6615 - val_acc: 0.6052\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6595 - acc: 0.6072 - val_loss: 0.6513 - val_acc: 0.6103\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6532 - acc: 0.6184 - val_loss: 0.6455 - val_acc: 0.6268\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6503 - acc: 0.6273 - val_loss: 0.6423 - val_acc: 0.6391\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6485 - acc: 0.6314 - val_loss: 0.6408 - val_acc: 0.6482\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6474 - acc: 0.6342 - val_loss: 0.6397 - val_acc: 0.6449\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6469 - acc: 0.6341 - val_loss: 0.6393 - val_acc: 0.6463\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6466 - acc: 0.6371 - val_loss: 0.6396 - val_acc: 0.6465\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6387 - val_loss: 0.6389 - val_acc: 0.6444\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6463 - acc: 0.6365 - val_loss: 0.6382 - val_acc: 0.6485\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6461 - acc: 0.6372 - val_loss: 0.6384 - val_acc: 0.6444\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6458 - acc: 0.6369 - val_loss: 0.6384 - val_acc: 0.6432\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6354 - val_loss: 0.6385 - val_acc: 0.6491\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6456 - acc: 0.6368 - val_loss: 0.6380 - val_acc: 0.6461\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6457 - acc: 0.6385 - val_loss: 0.6382 - val_acc: 0.6451\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6455 - acc: 0.6360 - val_loss: 0.6378 - val_acc: 0.6527\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6396 - val_loss: 0.6380 - val_acc: 0.6465\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6365 - val_loss: 0.6379 - val_acc: 0.6487\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6455 - acc: 0.6391 - val_loss: 0.6377 - val_acc: 0.6485\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 87us/step - loss: 0.7532 - acc: 0.5275 - val_loss: 0.6930 - val_acc: 0.5659\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 26us/step - loss: 0.6790 - acc: 0.5835 - val_loss: 0.6642 - val_acc: 0.6034\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6627 - acc: 0.6051 - val_loss: 0.6526 - val_acc: 0.6205\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6554 - acc: 0.6182 - val_loss: 0.6467 - val_acc: 0.6366\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6516 - acc: 0.6303 - val_loss: 0.6435 - val_acc: 0.6408\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6494 - acc: 0.6342 - val_loss: 0.6415 - val_acc: 0.6497\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6481 - acc: 0.6349 - val_loss: 0.6401 - val_acc: 0.6470\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6473 - acc: 0.6379 - val_loss: 0.6394 - val_acc: 0.6508\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6467 - acc: 0.6383 - val_loss: 0.6389 - val_acc: 0.6512\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6465 - acc: 0.6397 - val_loss: 0.6385 - val_acc: 0.6501\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6460 - acc: 0.6380 - val_loss: 0.6387 - val_acc: 0.6446\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6349 - val_loss: 0.6384 - val_acc: 0.6487\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6397 - val_loss: 0.6386 - val_acc: 0.6455\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6457 - acc: 0.6362 - val_loss: 0.6379 - val_acc: 0.6455\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6455 - acc: 0.6387 - val_loss: 0.6379 - val_acc: 0.6459\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6455 - acc: 0.6375 - val_loss: 0.6380 - val_acc: 0.6436\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6456 - acc: 0.6367 - val_loss: 0.6380 - val_acc: 0.6484\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6453 - acc: 0.6373 - val_loss: 0.6377 - val_acc: 0.6499\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6453 - acc: 0.6351 - val_loss: 0.6375 - val_acc: 0.6508\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6453 - acc: 0.6372 - val_loss: 0.6378 - val_acc: 0.6482\n"
     ]
    }
   ],
   "source": [
    "FC1_history=Do_experiments(x_FC1,y,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 96us/step - loss: 0.7962 - acc: 0.5540 - val_loss: 0.7067 - val_acc: 0.5731\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6821 - acc: 0.5813 - val_loss: 0.6678 - val_acc: 0.5906\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 29us/step - loss: 0.6627 - acc: 0.6002 - val_loss: 0.6545 - val_acc: 0.6108\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 36us/step - loss: 0.6551 - acc: 0.6145 - val_loss: 0.6489 - val_acc: 0.6336\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6514 - acc: 0.6246 - val_loss: 0.6443 - val_acc: 0.6336\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6492 - acc: 0.6304 - val_loss: 0.6421 - val_acc: 0.6376\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6477 - acc: 0.6320 - val_loss: 0.6439 - val_acc: 0.6461\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6475 - acc: 0.6343 - val_loss: 0.6400 - val_acc: 0.6484\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 27us/step - loss: 0.6467 - acc: 0.6370 - val_loss: 0.6393 - val_acc: 0.6493\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 39us/step - loss: 0.6466 - acc: 0.6371 - val_loss: 0.6391 - val_acc: 0.6468\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6463 - acc: 0.6365 - val_loss: 0.6387 - val_acc: 0.6476\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6461 - acc: 0.6356 - val_loss: 0.6386 - val_acc: 0.6459\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6458 - acc: 0.6355 - val_loss: 0.6385 - val_acc: 0.6461\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6457 - acc: 0.6357 - val_loss: 0.6380 - val_acc: 0.6484\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6458 - acc: 0.6361 - val_loss: 0.6380 - val_acc: 0.6457\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6458 - acc: 0.6376 - val_loss: 0.6379 - val_acc: 0.6495\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6360 - val_loss: 0.6380 - val_acc: 0.6440\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6330 - val_loss: 0.6377 - val_acc: 0.6493\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6454 - acc: 0.6361 - val_loss: 0.6381 - val_acc: 0.6457\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6455 - acc: 0.6361 - val_loss: 0.6382 - val_acc: 0.6440\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 95us/step - loss: 0.7414 - acc: 0.5401 - val_loss: 0.6951 - val_acc: 0.5777\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 0.6877 - acc: 0.5724 - val_loss: 0.6670 - val_acc: 0.5989\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6674 - acc: 0.6026 - val_loss: 0.6535 - val_acc: 0.6250\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6574 - acc: 0.6176 - val_loss: 0.6472 - val_acc: 0.6377\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6524 - acc: 0.6282 - val_loss: 0.6438 - val_acc: 0.6408\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6498 - acc: 0.6306 - val_loss: 0.6410 - val_acc: 0.6436\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6482 - acc: 0.6314 - val_loss: 0.6400 - val_acc: 0.6408\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6477 - acc: 0.6343 - val_loss: 0.6398 - val_acc: 0.6484\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6473 - acc: 0.6340 - val_loss: 0.6395 - val_acc: 0.6432\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6469 - acc: 0.6355 - val_loss: 0.6386 - val_acc: 0.6489\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6467 - acc: 0.6370 - val_loss: 0.6389 - val_acc: 0.6480\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6467 - acc: 0.6344 - val_loss: 0.6386 - val_acc: 0.6451\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6464 - acc: 0.6356 - val_loss: 0.6384 - val_acc: 0.6487\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6464 - acc: 0.6355 - val_loss: 0.6385 - val_acc: 0.6412\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6464 - acc: 0.6352 - val_loss: 0.6388 - val_acc: 0.6427\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6462 - acc: 0.6373 - val_loss: 0.6384 - val_acc: 0.6448\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6461 - acc: 0.6360 - val_loss: 0.6385 - val_acc: 0.6472\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6395 - val_loss: 0.6384 - val_acc: 0.6463\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6462 - acc: 0.6349 - val_loss: 0.6388 - val_acc: 0.6453\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6461 - acc: 0.6372 - val_loss: 0.6383 - val_acc: 0.6459\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 95us/step - loss: 0.7604 - acc: 0.5684 - val_loss: 0.6962 - val_acc: 0.5784\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6839 - acc: 0.5829 - val_loss: 0.6698 - val_acc: 0.5985\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6666 - acc: 0.5997 - val_loss: 0.6580 - val_acc: 0.6137\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6582 - acc: 0.6093 - val_loss: 0.6513 - val_acc: 0.6258\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6537 - acc: 0.6191 - val_loss: 0.6469 - val_acc: 0.6372\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6509 - acc: 0.6248 - val_loss: 0.6446 - val_acc: 0.6406\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6490 - acc: 0.6312 - val_loss: 0.6424 - val_acc: 0.6425\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 0.6479 - acc: 0.6339 - val_loss: 0.6416 - val_acc: 0.6470\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6470 - acc: 0.6337 - val_loss: 0.6405 - val_acc: 0.6434\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6467 - acc: 0.6364 - val_loss: 0.6412 - val_acc: 0.6436\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6355 - val_loss: 0.6395 - val_acc: 0.6480\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6463 - acc: 0.6370 - val_loss: 0.6389 - val_acc: 0.6476\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6460 - acc: 0.6361 - val_loss: 0.6389 - val_acc: 0.6451\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6457 - acc: 0.6358 - val_loss: 0.6392 - val_acc: 0.6444\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6360 - val_loss: 0.6392 - val_acc: 0.6417\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6456 - acc: 0.6363 - val_loss: 0.6391 - val_acc: 0.6442\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6454 - acc: 0.6380 - val_loss: 0.6382 - val_acc: 0.6413\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6375 - val_loss: 0.6380 - val_acc: 0.6410\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6452 - acc: 0.6349 - val_loss: 0.6380 - val_acc: 0.6495\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6452 - acc: 0.6365 - val_loss: 0.6383 - val_acc: 0.6457\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 111us/step - loss: 0.7473 - acc: 0.5234 - val_loss: 0.7042 - val_acc: 0.5515\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6870 - acc: 0.5699 - val_loss: 0.6705 - val_acc: 0.5862\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6672 - acc: 0.5925 - val_loss: 0.6554 - val_acc: 0.6127\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6576 - acc: 0.6107 - val_loss: 0.6480 - val_acc: 0.6413\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6526 - acc: 0.6252 - val_loss: 0.6439 - val_acc: 0.6434\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6499 - acc: 0.6318 - val_loss: 0.6418 - val_acc: 0.6493\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6484 - acc: 0.6343 - val_loss: 0.6407 - val_acc: 0.6432\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6475 - acc: 0.6357 - val_loss: 0.6395 - val_acc: 0.6448\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6471 - acc: 0.6372 - val_loss: 0.6390 - val_acc: 0.6438\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6467 - acc: 0.6361 - val_loss: 0.6396 - val_acc: 0.6470\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6466 - acc: 0.6371 - val_loss: 0.6386 - val_acc: 0.6514\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6466 - acc: 0.6370 - val_loss: 0.6385 - val_acc: 0.6480\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6463 - acc: 0.6351 - val_loss: 0.6386 - val_acc: 0.6474\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6462 - acc: 0.6374 - val_loss: 0.6383 - val_acc: 0.6497\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6463 - acc: 0.6387 - val_loss: 0.6382 - val_acc: 0.6455\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6369 - val_loss: 0.6381 - val_acc: 0.6516\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6382 - val_loss: 0.6381 - val_acc: 0.6476\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6360 - val_loss: 0.6381 - val_acc: 0.6468\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6461 - acc: 0.6359 - val_loss: 0.6381 - val_acc: 0.6495\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6460 - acc: 0.6345 - val_loss: 0.6378 - val_acc: 0.6512\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 108us/step - loss: 0.7067 - acc: 0.5644 - val_loss: 0.6765 - val_acc: 0.5898\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 37us/step - loss: 0.6671 - acc: 0.5993 - val_loss: 0.6536 - val_acc: 0.6152\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6546 - acc: 0.6182 - val_loss: 0.6453 - val_acc: 0.6340\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6500 - acc: 0.6300 - val_loss: 0.6421 - val_acc: 0.6482\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6483 - acc: 0.6348 - val_loss: 0.6404 - val_acc: 0.6465\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6471 - acc: 0.6360 - val_loss: 0.6400 - val_acc: 0.6415\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6470 - acc: 0.6389 - val_loss: 0.6402 - val_acc: 0.6468\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 42us/step - loss: 0.6468 - acc: 0.6366 - val_loss: 0.6390 - val_acc: 0.6518\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6466 - acc: 0.6363 - val_loss: 0.6389 - val_acc: 0.6453\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6465 - acc: 0.6394 - val_loss: 0.6404 - val_acc: 0.6449\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6464 - acc: 0.6360 - val_loss: 0.6386 - val_acc: 0.6495\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6465 - acc: 0.6370 - val_loss: 0.6387 - val_acc: 0.6491\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6462 - acc: 0.6354 - val_loss: 0.6385 - val_acc: 0.6470\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6464 - acc: 0.6359 - val_loss: 0.6389 - val_acc: 0.6451\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6460 - acc: 0.6366 - val_loss: 0.6387 - val_acc: 0.6406\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6461 - acc: 0.6382 - val_loss: 0.6386 - val_acc: 0.6463\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6462 - acc: 0.6372 - val_loss: 0.6387 - val_acc: 0.6502\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6462 - acc: 0.6370 - val_loss: 0.6385 - val_acc: 0.6457\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6462 - acc: 0.6371 - val_loss: 0.6397 - val_acc: 0.6465\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6462 - acc: 0.6375 - val_loss: 0.6386 - val_acc: 0.6461\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 100us/step - loss: 0.7013 - acc: 0.5683 - val_loss: 0.6762 - val_acc: 0.5775\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 43us/step - loss: 0.6667 - acc: 0.6008 - val_loss: 0.6569 - val_acc: 0.6156\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6566 - acc: 0.6165 - val_loss: 0.6487 - val_acc: 0.6309\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6520 - acc: 0.6276 - val_loss: 0.6443 - val_acc: 0.6425\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6496 - acc: 0.6324 - val_loss: 0.6422 - val_acc: 0.6506\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6482 - acc: 0.6337 - val_loss: 0.6406 - val_acc: 0.6518\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6474 - acc: 0.6360 - val_loss: 0.6400 - val_acc: 0.6516\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6467 - acc: 0.6346 - val_loss: 0.6390 - val_acc: 0.6499\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 0.6466 - acc: 0.6359 - val_loss: 0.6388 - val_acc: 0.6461\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6460 - acc: 0.6365 - val_loss: 0.6385 - val_acc: 0.6476\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6459 - acc: 0.6344 - val_loss: 0.6384 - val_acc: 0.6493\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6460 - acc: 0.6367 - val_loss: 0.6381 - val_acc: 0.6459\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6457 - acc: 0.6353 - val_loss: 0.6378 - val_acc: 0.6533\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6455 - acc: 0.6399 - val_loss: 0.6381 - val_acc: 0.6436\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6457 - acc: 0.6355 - val_loss: 0.6380 - val_acc: 0.6457\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6346 - val_loss: 0.6383 - val_acc: 0.6470\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6454 - acc: 0.6380 - val_loss: 0.6378 - val_acc: 0.6504\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6371 - val_loss: 0.6377 - val_acc: 0.6493\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6456 - acc: 0.6375 - val_loss: 0.6376 - val_acc: 0.6518\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6454 - acc: 0.6401 - val_loss: 0.6379 - val_acc: 0.6472\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 102us/step - loss: 0.7316 - acc: 0.5493 - val_loss: 0.6853 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6789 - acc: 0.5912 - val_loss: 0.6614 - val_acc: 0.6222\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6627 - acc: 0.6192 - val_loss: 0.6505 - val_acc: 0.6286\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6552 - acc: 0.6277 - val_loss: 0.6449 - val_acc: 0.6457\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6512 - acc: 0.6325 - val_loss: 0.6427 - val_acc: 0.6527\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6492 - acc: 0.6358 - val_loss: 0.6405 - val_acc: 0.6501\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6479 - acc: 0.6369 - val_loss: 0.6396 - val_acc: 0.6516\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6472 - acc: 0.6376 - val_loss: 0.6392 - val_acc: 0.6510\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6469 - acc: 0.6375 - val_loss: 0.6387 - val_acc: 0.6538\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6466 - acc: 0.6393 - val_loss: 0.6384 - val_acc: 0.6521\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6463 - acc: 0.6372 - val_loss: 0.6398 - val_acc: 0.6383\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6462 - acc: 0.6361 - val_loss: 0.6388 - val_acc: 0.6381\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6460 - acc: 0.6369 - val_loss: 0.6390 - val_acc: 0.6480\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6460 - acc: 0.6369 - val_loss: 0.6383 - val_acc: 0.6470\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6366 - val_loss: 0.6378 - val_acc: 0.6516\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6460 - acc: 0.6349 - val_loss: 0.6377 - val_acc: 0.6510\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6459 - acc: 0.6364 - val_loss: 0.6381 - val_acc: 0.6466\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6459 - acc: 0.6374 - val_loss: 0.6379 - val_acc: 0.6510\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6458 - acc: 0.6369 - val_loss: 0.6383 - val_acc: 0.6446\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6457 - acc: 0.6378 - val_loss: 0.6380 - val_acc: 0.6493\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 101us/step - loss: 0.7519 - acc: 0.5460 - val_loss: 0.6945 - val_acc: 0.5603\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6811 - acc: 0.5754 - val_loss: 0.6619 - val_acc: 0.6029\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6603 - acc: 0.6043 - val_loss: 0.6497 - val_acc: 0.6192\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6525 - acc: 0.6196 - val_loss: 0.6447 - val_acc: 0.6349\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6493 - acc: 0.6282 - val_loss: 0.6424 - val_acc: 0.6412\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6479 - acc: 0.6313 - val_loss: 0.6413 - val_acc: 0.6434\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6469 - acc: 0.6337 - val_loss: 0.6402 - val_acc: 0.6427\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6465 - acc: 0.6369 - val_loss: 0.6397 - val_acc: 0.6446\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6360 - val_loss: 0.6396 - val_acc: 0.6423\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6460 - acc: 0.6343 - val_loss: 0.6391 - val_acc: 0.6449\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6457 - acc: 0.6374 - val_loss: 0.6391 - val_acc: 0.6434\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 37us/step - loss: 0.6459 - acc: 0.6346 - val_loss: 0.6385 - val_acc: 0.6457\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6457 - acc: 0.6351 - val_loss: 0.6383 - val_acc: 0.6474\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6360 - val_loss: 0.6382 - val_acc: 0.6495\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6457 - acc: 0.6391 - val_loss: 0.6380 - val_acc: 0.6504\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6457 - acc: 0.6358 - val_loss: 0.6382 - val_acc: 0.6438\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6364 - val_loss: 0.6389 - val_acc: 0.6449\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6366 - val_loss: 0.6386 - val_acc: 0.6362\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6457 - acc: 0.6372 - val_loss: 0.6380 - val_acc: 0.6429\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6457 - acc: 0.6359 - val_loss: 0.6381 - val_acc: 0.6449\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 101us/step - loss: 0.7243 - acc: 0.5668 - val_loss: 0.6770 - val_acc: 0.5980\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 0.6717 - acc: 0.5982 - val_loss: 0.6552 - val_acc: 0.6110\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6586 - acc: 0.6110 - val_loss: 0.6475 - val_acc: 0.6294\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6532 - acc: 0.6236 - val_loss: 0.6437 - val_acc: 0.6391\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6504 - acc: 0.6287 - val_loss: 0.6416 - val_acc: 0.6429\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6489 - acc: 0.6310 - val_loss: 0.6399 - val_acc: 0.6485\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6479 - acc: 0.6348 - val_loss: 0.6398 - val_acc: 0.6474\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6470 - acc: 0.6344 - val_loss: 0.6401 - val_acc: 0.6434\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6469 - acc: 0.6360 - val_loss: 0.6387 - val_acc: 0.6485\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6464 - acc: 0.6371 - val_loss: 0.6385 - val_acc: 0.6485\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6465 - acc: 0.6347 - val_loss: 0.6384 - val_acc: 0.6487\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6462 - acc: 0.6367 - val_loss: 0.6384 - val_acc: 0.6468\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6459 - acc: 0.6384 - val_loss: 0.6393 - val_acc: 0.6472\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6459 - acc: 0.6355 - val_loss: 0.6388 - val_acc: 0.6470\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6458 - acc: 0.6370 - val_loss: 0.6381 - val_acc: 0.6465\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6457 - acc: 0.6383 - val_loss: 0.6385 - val_acc: 0.6448\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6456 - acc: 0.6388 - val_loss: 0.6381 - val_acc: 0.6442\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6456 - acc: 0.6357 - val_loss: 0.6384 - val_acc: 0.6468\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 0.6457 - acc: 0.6395 - val_loss: 0.6378 - val_acc: 0.6501\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6456 - acc: 0.6393 - val_loss: 0.6385 - val_acc: 0.6463\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 103us/step - loss: 0.7301 - acc: 0.5412 - val_loss: 0.6963 - val_acc: 0.5620\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6831 - acc: 0.5748 - val_loss: 0.6683 - val_acc: 0.6017\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6648 - acc: 0.6040 - val_loss: 0.6549 - val_acc: 0.6197\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6556 - acc: 0.6221 - val_loss: 0.6477 - val_acc: 0.6286\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6513 - acc: 0.6249 - val_loss: 0.6435 - val_acc: 0.6398\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6489 - acc: 0.6287 - val_loss: 0.6415 - val_acc: 0.6463\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6481 - acc: 0.6317 - val_loss: 0.6404 - val_acc: 0.6410\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6472 - acc: 0.6348 - val_loss: 0.6399 - val_acc: 0.6438\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6468 - acc: 0.6333 - val_loss: 0.6396 - val_acc: 0.6442\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6466 - acc: 0.6318 - val_loss: 0.6394 - val_acc: 0.6453\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6372 - val_loss: 0.6393 - val_acc: 0.6383\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6360 - val_loss: 0.6390 - val_acc: 0.6419\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6368 - val_loss: 0.6385 - val_acc: 0.6493\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6460 - acc: 0.6336 - val_loss: 0.6384 - val_acc: 0.6497\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6461 - acc: 0.6355 - val_loss: 0.6386 - val_acc: 0.6459\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6459 - acc: 0.6377 - val_loss: 0.6383 - val_acc: 0.6485\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6459 - acc: 0.6375 - val_loss: 0.6386 - val_acc: 0.6468\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6460 - acc: 0.6372 - val_loss: 0.6388 - val_acc: 0.6449\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6458 - acc: 0.6360 - val_loss: 0.6385 - val_acc: 0.6415\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6458 - acc: 0.6370 - val_loss: 0.6383 - val_acc: 0.6465\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 107us/step - loss: 0.7095 - acc: 0.5530 - val_loss: 0.6803 - val_acc: 0.5862\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6692 - acc: 0.5973 - val_loss: 0.6553 - val_acc: 0.6127\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6552 - acc: 0.6112 - val_loss: 0.6459 - val_acc: 0.6286\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6499 - acc: 0.6222 - val_loss: 0.6415 - val_acc: 0.6347\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6477 - acc: 0.6294 - val_loss: 0.6401 - val_acc: 0.6480\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6466 - acc: 0.6327 - val_loss: 0.6386 - val_acc: 0.6480\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6462 - acc: 0.6343 - val_loss: 0.6382 - val_acc: 0.6474\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6457 - acc: 0.6373 - val_loss: 0.6379 - val_acc: 0.6489\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6458 - acc: 0.6376 - val_loss: 0.6377 - val_acc: 0.6470\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6367 - val_loss: 0.6381 - val_acc: 0.6421\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6455 - acc: 0.6371 - val_loss: 0.6373 - val_acc: 0.6478\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6456 - acc: 0.6374 - val_loss: 0.6386 - val_acc: 0.6466\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6375 - val_loss: 0.6375 - val_acc: 0.6504\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6455 - acc: 0.6360 - val_loss: 0.6374 - val_acc: 0.6520\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6382 - val_loss: 0.6376 - val_acc: 0.6499\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6373 - val_loss: 0.6383 - val_acc: 0.6408\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6455 - acc: 0.6364 - val_loss: 0.6374 - val_acc: 0.6499\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6454 - acc: 0.6345 - val_loss: 0.6377 - val_acc: 0.6457\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6454 - acc: 0.6368 - val_loss: 0.6377 - val_acc: 0.6506\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6453 - acc: 0.6369 - val_loss: 0.6375 - val_acc: 0.6474\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 112us/step - loss: 0.7394 - acc: 0.5344 - val_loss: 0.6924 - val_acc: 0.5705\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6797 - acc: 0.5833 - val_loss: 0.6651 - val_acc: 0.6033\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6623 - acc: 0.6086 - val_loss: 0.6528 - val_acc: 0.6182\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6543 - acc: 0.6216 - val_loss: 0.6471 - val_acc: 0.6432\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6507 - acc: 0.6298 - val_loss: 0.6437 - val_acc: 0.6466\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6488 - acc: 0.6315 - val_loss: 0.6422 - val_acc: 0.6419\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6477 - acc: 0.6348 - val_loss: 0.6410 - val_acc: 0.6480\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6471 - acc: 0.6377 - val_loss: 0.6409 - val_acc: 0.6427\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 39us/step - loss: 0.6466 - acc: 0.6384 - val_loss: 0.6396 - val_acc: 0.6514\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6464 - acc: 0.6378 - val_loss: 0.6394 - val_acc: 0.6463\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6464 - acc: 0.6360 - val_loss: 0.6392 - val_acc: 0.6453\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6461 - acc: 0.6385 - val_loss: 0.6392 - val_acc: 0.6451\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6460 - acc: 0.6378 - val_loss: 0.6390 - val_acc: 0.6453\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6460 - acc: 0.6360 - val_loss: 0.6391 - val_acc: 0.6438\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6458 - acc: 0.6356 - val_loss: 0.6384 - val_acc: 0.6508\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6457 - acc: 0.6366 - val_loss: 0.6383 - val_acc: 0.6485\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6457 - acc: 0.6375 - val_loss: 0.6391 - val_acc: 0.6455\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6459 - acc: 0.6353 - val_loss: 0.6389 - val_acc: 0.6440\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6458 - acc: 0.6365 - val_loss: 0.6381 - val_acc: 0.6468\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6459 - acc: 0.6351 - val_loss: 0.6384 - val_acc: 0.6440\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 124us/step - loss: 0.7518 - acc: 0.5689 - val_loss: 0.6906 - val_acc: 0.5807\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6778 - acc: 0.5897 - val_loss: 0.6618 - val_acc: 0.6088\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6614 - acc: 0.6045 - val_loss: 0.6515 - val_acc: 0.6201\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6544 - acc: 0.6177 - val_loss: 0.6462 - val_acc: 0.6328\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6511 - acc: 0.6286 - val_loss: 0.6431 - val_acc: 0.6419\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6491 - acc: 0.6329 - val_loss: 0.6414 - val_acc: 0.6485\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6482 - acc: 0.6359 - val_loss: 0.6408 - val_acc: 0.6527\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6477 - acc: 0.6362 - val_loss: 0.6400 - val_acc: 0.6512\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6470 - acc: 0.6382 - val_loss: 0.6396 - val_acc: 0.6501\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6467 - acc: 0.6370 - val_loss: 0.6400 - val_acc: 0.6463\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6466 - acc: 0.6368 - val_loss: 0.6390 - val_acc: 0.6501\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6464 - acc: 0.6365 - val_loss: 0.6413 - val_acc: 0.6442\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6465 - acc: 0.6362 - val_loss: 0.6390 - val_acc: 0.6453\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6463 - acc: 0.6381 - val_loss: 0.6398 - val_acc: 0.6377\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6462 - acc: 0.6390 - val_loss: 0.6386 - val_acc: 0.6491\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6462 - acc: 0.6358 - val_loss: 0.6390 - val_acc: 0.6459\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6460 - acc: 0.6365 - val_loss: 0.6383 - val_acc: 0.6520\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6458 - acc: 0.6349 - val_loss: 0.6397 - val_acc: 0.6444\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6461 - acc: 0.6363 - val_loss: 0.6382 - val_acc: 0.6440\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6460 - acc: 0.6358 - val_loss: 0.6385 - val_acc: 0.6444\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 120us/step - loss: 0.7366 - acc: 0.5386 - val_loss: 0.6870 - val_acc: 0.5849\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6774 - acc: 0.5962 - val_loss: 0.6636 - val_acc: 0.6131\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6613 - acc: 0.6069 - val_loss: 0.6528 - val_acc: 0.6205\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6546 - acc: 0.6161 - val_loss: 0.6486 - val_acc: 0.6273\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6514 - acc: 0.6266 - val_loss: 0.6452 - val_acc: 0.6383\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6493 - acc: 0.6306 - val_loss: 0.6426 - val_acc: 0.6453\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6482 - acc: 0.6336 - val_loss: 0.6419 - val_acc: 0.6506\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6474 - acc: 0.6342 - val_loss: 0.6408 - val_acc: 0.6480\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6469 - acc: 0.6350 - val_loss: 0.6399 - val_acc: 0.6474\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6465 - acc: 0.6336 - val_loss: 0.6395 - val_acc: 0.6510\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6463 - acc: 0.6349 - val_loss: 0.6397 - val_acc: 0.6474\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6460 - acc: 0.6382 - val_loss: 0.6395 - val_acc: 0.6457\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6349 - val_loss: 0.6384 - val_acc: 0.6542\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6458 - acc: 0.6360 - val_loss: 0.6381 - val_acc: 0.6520\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6457 - acc: 0.6380 - val_loss: 0.6384 - val_acc: 0.6451\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6457 - acc: 0.6378 - val_loss: 0.6383 - val_acc: 0.6465\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6381 - val_loss: 0.6384 - val_acc: 0.6461\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6458 - acc: 0.6343 - val_loss: 0.6380 - val_acc: 0.6508\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6455 - acc: 0.6376 - val_loss: 0.6381 - val_acc: 0.6472\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6456 - acc: 0.6386 - val_loss: 0.6379 - val_acc: 0.6436\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 109us/step - loss: 0.7197 - acc: 0.5335 - val_loss: 0.6896 - val_acc: 0.5597\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6798 - acc: 0.5734 - val_loss: 0.6657 - val_acc: 0.5936\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6639 - acc: 0.6021 - val_loss: 0.6538 - val_acc: 0.6190\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6559 - acc: 0.6135 - val_loss: 0.6473 - val_acc: 0.6241\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6517 - acc: 0.6210 - val_loss: 0.6442 - val_acc: 0.6364\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6494 - acc: 0.6315 - val_loss: 0.6425 - val_acc: 0.6377\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6479 - acc: 0.6306 - val_loss: 0.6409 - val_acc: 0.6512\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6472 - acc: 0.6384 - val_loss: 0.6401 - val_acc: 0.6512\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6468 - acc: 0.6359 - val_loss: 0.6395 - val_acc: 0.6497\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6360 - val_loss: 0.6392 - val_acc: 0.6457\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6383 - val_loss: 0.6388 - val_acc: 0.6518\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6460 - acc: 0.6375 - val_loss: 0.6387 - val_acc: 0.6491\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6459 - acc: 0.6361 - val_loss: 0.6387 - val_acc: 0.6444\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 28us/step - loss: 0.6458 - acc: 0.6389 - val_loss: 0.6387 - val_acc: 0.6432\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6456 - acc: 0.6366 - val_loss: 0.6383 - val_acc: 0.6499\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6457 - acc: 0.6370 - val_loss: 0.6384 - val_acc: 0.6449\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6457 - acc: 0.6381 - val_loss: 0.6384 - val_acc: 0.6423\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6369 - val_loss: 0.6385 - val_acc: 0.6446\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6375 - val_loss: 0.6386 - val_acc: 0.6461\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6455 - acc: 0.6375 - val_loss: 0.6380 - val_acc: 0.6442\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 102us/step - loss: 0.7232 - acc: 0.5691 - val_loss: 0.6768 - val_acc: 0.5889\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6711 - acc: 0.5889 - val_loss: 0.6598 - val_acc: 0.6131\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6596 - acc: 0.6060 - val_loss: 0.6506 - val_acc: 0.6232\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6536 - acc: 0.6189 - val_loss: 0.6456 - val_acc: 0.6381\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6503 - acc: 0.6267 - val_loss: 0.6429 - val_acc: 0.6417\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6484 - acc: 0.6328 - val_loss: 0.6419 - val_acc: 0.6455\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6476 - acc: 0.6349 - val_loss: 0.6406 - val_acc: 0.6466\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6471 - acc: 0.6357 - val_loss: 0.6397 - val_acc: 0.6508\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6467 - acc: 0.6363 - val_loss: 0.6397 - val_acc: 0.6455\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6464 - acc: 0.6381 - val_loss: 0.6400 - val_acc: 0.6461\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 43us/step - loss: 0.6463 - acc: 0.6362 - val_loss: 0.6389 - val_acc: 0.6455\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6463 - acc: 0.6369 - val_loss: 0.6387 - val_acc: 0.6512\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6460 - acc: 0.6353 - val_loss: 0.6387 - val_acc: 0.6484\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6464 - acc: 0.6366 - val_loss: 0.6387 - val_acc: 0.6453\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6461 - acc: 0.6360 - val_loss: 0.6394 - val_acc: 0.6448\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6359 - val_loss: 0.6384 - val_acc: 0.6491\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6459 - acc: 0.6363 - val_loss: 0.6385 - val_acc: 0.6478\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6459 - acc: 0.6360 - val_loss: 0.6390 - val_acc: 0.6448\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6460 - acc: 0.6356 - val_loss: 0.6384 - val_acc: 0.6453\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6460 - acc: 0.6372 - val_loss: 0.6384 - val_acc: 0.6457\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 119us/step - loss: 0.7935 - acc: 0.5045 - val_loss: 0.7069 - val_acc: 0.5388\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6927 - acc: 0.5566 - val_loss: 0.6746 - val_acc: 0.5784\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6716 - acc: 0.5859 - val_loss: 0.6591 - val_acc: 0.6097\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6607 - acc: 0.6077 - val_loss: 0.6503 - val_acc: 0.6269\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6547 - acc: 0.6194 - val_loss: 0.6454 - val_acc: 0.6357\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6511 - acc: 0.6264 - val_loss: 0.6427 - val_acc: 0.6448\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6494 - acc: 0.6312 - val_loss: 0.6417 - val_acc: 0.6423\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6482 - acc: 0.6358 - val_loss: 0.6403 - val_acc: 0.6423\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6477 - acc: 0.6343 - val_loss: 0.6401 - val_acc: 0.6366\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6472 - acc: 0.6372 - val_loss: 0.6393 - val_acc: 0.6455\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6467 - acc: 0.6360 - val_loss: 0.6388 - val_acc: 0.6548\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6466 - acc: 0.6376 - val_loss: 0.6390 - val_acc: 0.6491\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6464 - acc: 0.6382 - val_loss: 0.6389 - val_acc: 0.6442\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6462 - acc: 0.6360 - val_loss: 0.6395 - val_acc: 0.6438\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6461 - acc: 0.6370 - val_loss: 0.6388 - val_acc: 0.6442\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6460 - acc: 0.6354 - val_loss: 0.6385 - val_acc: 0.6463\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6461 - acc: 0.6367 - val_loss: 0.6387 - val_acc: 0.6453\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6461 - acc: 0.6367 - val_loss: 0.6390 - val_acc: 0.6457\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6460 - acc: 0.6362 - val_loss: 0.6381 - val_acc: 0.6506\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6383 - val_loss: 0.6382 - val_acc: 0.6430\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 112us/step - loss: 0.7335 - acc: 0.5318 - val_loss: 0.6916 - val_acc: 0.5603\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 41us/step - loss: 0.6827 - acc: 0.5729 - val_loss: 0.6683 - val_acc: 0.5898\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6662 - acc: 0.5960 - val_loss: 0.6567 - val_acc: 0.6178\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6575 - acc: 0.6139 - val_loss: 0.6495 - val_acc: 0.6258\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6528 - acc: 0.6239 - val_loss: 0.6457 - val_acc: 0.6343\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6498 - acc: 0.6296 - val_loss: 0.6438 - val_acc: 0.6381\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6483 - acc: 0.6308 - val_loss: 0.6417 - val_acc: 0.6455\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6475 - acc: 0.6324 - val_loss: 0.6407 - val_acc: 0.6512\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6468 - acc: 0.6344 - val_loss: 0.6401 - val_acc: 0.6497\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6363 - val_loss: 0.6396 - val_acc: 0.6448\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6463 - acc: 0.6354 - val_loss: 0.6395 - val_acc: 0.6459\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6459 - acc: 0.6369 - val_loss: 0.6391 - val_acc: 0.6442\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6458 - acc: 0.6366 - val_loss: 0.6385 - val_acc: 0.6506\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6456 - acc: 0.6377 - val_loss: 0.6386 - val_acc: 0.6502\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6455 - acc: 0.6366 - val_loss: 0.6394 - val_acc: 0.6442\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6456 - acc: 0.6374 - val_loss: 0.6383 - val_acc: 0.6461\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6453 - acc: 0.6374 - val_loss: 0.6381 - val_acc: 0.6506\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6454 - acc: 0.6354 - val_loss: 0.6379 - val_acc: 0.6499\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6454 - acc: 0.6396 - val_loss: 0.6379 - val_acc: 0.6478\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6453 - acc: 0.6363 - val_loss: 0.6380 - val_acc: 0.6457\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 113us/step - loss: 0.8268 - acc: 0.4828 - val_loss: 0.7338 - val_acc: 0.5261\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 39us/step - loss: 0.7132 - acc: 0.5374 - val_loss: 0.6904 - val_acc: 0.5568\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6809 - acc: 0.5736 - val_loss: 0.6665 - val_acc: 0.6040\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6643 - acc: 0.6053 - val_loss: 0.6536 - val_acc: 0.6146\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6556 - acc: 0.6149 - val_loss: 0.6476 - val_acc: 0.6372\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6515 - acc: 0.6257 - val_loss: 0.6438 - val_acc: 0.6412\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6491 - acc: 0.6323 - val_loss: 0.6423 - val_acc: 0.6362\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6480 - acc: 0.6342 - val_loss: 0.6408 - val_acc: 0.6485\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6474 - acc: 0.6381 - val_loss: 0.6423 - val_acc: 0.6319\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6470 - acc: 0.6354 - val_loss: 0.6401 - val_acc: 0.6429\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6468 - acc: 0.6349 - val_loss: 0.6394 - val_acc: 0.6531\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6467 - acc: 0.6363 - val_loss: 0.6393 - val_acc: 0.6480\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6466 - acc: 0.6363 - val_loss: 0.6390 - val_acc: 0.6461\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6464 - acc: 0.6382 - val_loss: 0.6390 - val_acc: 0.6438\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6464 - acc: 0.6364 - val_loss: 0.6391 - val_acc: 0.6423\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6463 - acc: 0.6351 - val_loss: 0.6392 - val_acc: 0.6478\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6461 - acc: 0.6355 - val_loss: 0.6400 - val_acc: 0.6455\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6462 - acc: 0.6359 - val_loss: 0.6398 - val_acc: 0.6463\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6464 - acc: 0.6355 - val_loss: 0.6390 - val_acc: 0.6463\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6461 - acc: 0.6360 - val_loss: 0.6386 - val_acc: 0.6440\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 113us/step - loss: 0.7144 - acc: 0.5590 - val_loss: 0.6768 - val_acc: 0.5936\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6707 - acc: 0.5991 - val_loss: 0.6564 - val_acc: 0.6205\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6580 - acc: 0.6207 - val_loss: 0.6473 - val_acc: 0.6372\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6525 - acc: 0.6281 - val_loss: 0.6436 - val_acc: 0.6419\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6497 - acc: 0.6313 - val_loss: 0.6411 - val_acc: 0.6398\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6484 - acc: 0.6330 - val_loss: 0.6399 - val_acc: 0.6457\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6475 - acc: 0.6352 - val_loss: 0.6395 - val_acc: 0.6451\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6472 - acc: 0.6343 - val_loss: 0.6404 - val_acc: 0.6440\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6469 - acc: 0.6357 - val_loss: 0.6386 - val_acc: 0.6461\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6467 - acc: 0.6356 - val_loss: 0.6388 - val_acc: 0.6448\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6465 - acc: 0.6362 - val_loss: 0.6385 - val_acc: 0.6482\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6466 - acc: 0.6372 - val_loss: 0.6382 - val_acc: 0.6510\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6465 - acc: 0.6363 - val_loss: 0.6386 - val_acc: 0.6459\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6464 - acc: 0.6375 - val_loss: 0.6383 - val_acc: 0.6461\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6463 - acc: 0.6348 - val_loss: 0.6383 - val_acc: 0.6525\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6462 - acc: 0.6357 - val_loss: 0.6384 - val_acc: 0.6430\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6463 - acc: 0.6370 - val_loss: 0.6382 - val_acc: 0.6502\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6462 - acc: 0.6376 - val_loss: 0.6381 - val_acc: 0.6485\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6462 - acc: 0.6384 - val_loss: 0.6384 - val_acc: 0.6436\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6462 - acc: 0.6351 - val_loss: 0.6381 - val_acc: 0.6510\n"
     ]
    }
   ],
   "source": [
    "FC2_history=Do_experiments(x_FC2,y,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 123us/step - loss: 0.7099 - acc: 0.5636 - val_loss: 0.6776 - val_acc: 0.5928\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6696 - acc: 0.6063 - val_loss: 0.6573 - val_acc: 0.6226\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6571 - acc: 0.6246 - val_loss: 0.6485 - val_acc: 0.6374\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6516 - acc: 0.6305 - val_loss: 0.6440 - val_acc: 0.6313\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6490 - acc: 0.6318 - val_loss: 0.6418 - val_acc: 0.6487\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6476 - acc: 0.6354 - val_loss: 0.6402 - val_acc: 0.6427\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6469 - acc: 0.6351 - val_loss: 0.6400 - val_acc: 0.6506\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6465 - acc: 0.6380 - val_loss: 0.6392 - val_acc: 0.6430\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6464 - acc: 0.6351 - val_loss: 0.6388 - val_acc: 0.6457\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6461 - acc: 0.6374 - val_loss: 0.6399 - val_acc: 0.6466\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6463 - acc: 0.6357 - val_loss: 0.6386 - val_acc: 0.6508\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6458 - acc: 0.6367 - val_loss: 0.6385 - val_acc: 0.6491\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6458 - acc: 0.6378 - val_loss: 0.6381 - val_acc: 0.6518\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6459 - acc: 0.6358 - val_loss: 0.6384 - val_acc: 0.6489\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6460 - acc: 0.6387 - val_loss: 0.6385 - val_acc: 0.6448\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6458 - acc: 0.6390 - val_loss: 0.6380 - val_acc: 0.6495\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6459 - acc: 0.6363 - val_loss: 0.6392 - val_acc: 0.6457\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6458 - acc: 0.6381 - val_loss: 0.6383 - val_acc: 0.6451\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6457 - acc: 0.6376 - val_loss: 0.6384 - val_acc: 0.6504\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6373 - val_loss: 0.6382 - val_acc: 0.6446\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 115us/step - loss: 0.7847 - acc: 0.5321 - val_loss: 0.6991 - val_acc: 0.5483\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6864 - acc: 0.5782 - val_loss: 0.6720 - val_acc: 0.6048\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6679 - acc: 0.6012 - val_loss: 0.6576 - val_acc: 0.6103\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6584 - acc: 0.6077 - val_loss: 0.6501 - val_acc: 0.6286\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6533 - acc: 0.6154 - val_loss: 0.6455 - val_acc: 0.6300\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6503 - acc: 0.6271 - val_loss: 0.6424 - val_acc: 0.6400\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6486 - acc: 0.6307 - val_loss: 0.6421 - val_acc: 0.6300\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6476 - acc: 0.6329 - val_loss: 0.6405 - val_acc: 0.6394\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6470 - acc: 0.6358 - val_loss: 0.6394 - val_acc: 0.6448\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6469 - acc: 0.6361 - val_loss: 0.6391 - val_acc: 0.6480\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6464 - acc: 0.6355 - val_loss: 0.6389 - val_acc: 0.6489\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6464 - acc: 0.6369 - val_loss: 0.6387 - val_acc: 0.6514\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6465 - acc: 0.6359 - val_loss: 0.6391 - val_acc: 0.6453\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6462 - acc: 0.6384 - val_loss: 0.6384 - val_acc: 0.6444\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6461 - acc: 0.6361 - val_loss: 0.6386 - val_acc: 0.6470\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6462 - acc: 0.6360 - val_loss: 0.6385 - val_acc: 0.6438\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6459 - acc: 0.6361 - val_loss: 0.6385 - val_acc: 0.6449\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6461 - acc: 0.6372 - val_loss: 0.6383 - val_acc: 0.6468\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6460 - acc: 0.6372 - val_loss: 0.6380 - val_acc: 0.6484\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6459 - acc: 0.6386 - val_loss: 0.6387 - val_acc: 0.6430\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 113us/step - loss: 0.8083 - acc: 0.4910 - val_loss: 0.7204 - val_acc: 0.5254\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6929 - acc: 0.5553 - val_loss: 0.6712 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6675 - acc: 0.5944 - val_loss: 0.6579 - val_acc: 0.6101\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6582 - acc: 0.6138 - val_loss: 0.6515 - val_acc: 0.6216\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6529 - acc: 0.6196 - val_loss: 0.6461 - val_acc: 0.6343\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6501 - acc: 0.6275 - val_loss: 0.6435 - val_acc: 0.6358\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6486 - acc: 0.6294 - val_loss: 0.6425 - val_acc: 0.6330\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6477 - acc: 0.6321 - val_loss: 0.6409 - val_acc: 0.6451\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6471 - acc: 0.6316 - val_loss: 0.6401 - val_acc: 0.6455\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6468 - acc: 0.6372 - val_loss: 0.6397 - val_acc: 0.6484\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6466 - acc: 0.6338 - val_loss: 0.6394 - val_acc: 0.6489\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6465 - acc: 0.6368 - val_loss: 0.6394 - val_acc: 0.6415\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6464 - acc: 0.6357 - val_loss: 0.6393 - val_acc: 0.6417\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6464 - acc: 0.6347 - val_loss: 0.6392 - val_acc: 0.6425\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6360 - val_loss: 0.6388 - val_acc: 0.6491\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6462 - acc: 0.6375 - val_loss: 0.6392 - val_acc: 0.6404\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6461 - acc: 0.6351 - val_loss: 0.6391 - val_acc: 0.6472\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6462 - acc: 0.6374 - val_loss: 0.6385 - val_acc: 0.6419\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6461 - acc: 0.6362 - val_loss: 0.6384 - val_acc: 0.6472\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6459 - acc: 0.6365 - val_loss: 0.6392 - val_acc: 0.6457\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 114us/step - loss: 0.7271 - acc: 0.5655 - val_loss: 0.6853 - val_acc: 0.5665\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6759 - acc: 0.5797 - val_loss: 0.6622 - val_acc: 0.5995\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6517 - val_acc: 0.6256\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6545 - acc: 0.6235 - val_loss: 0.6463 - val_acc: 0.6311\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6510 - acc: 0.6276 - val_loss: 0.6435 - val_acc: 0.6377\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6490 - acc: 0.6301 - val_loss: 0.6414 - val_acc: 0.6404\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6478 - acc: 0.6323 - val_loss: 0.6404 - val_acc: 0.6461\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6470 - acc: 0.6358 - val_loss: 0.6404 - val_acc: 0.6448\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6469 - acc: 0.6367 - val_loss: 0.6393 - val_acc: 0.6499\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6463 - acc: 0.6362 - val_loss: 0.6389 - val_acc: 0.6501\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6460 - acc: 0.6375 - val_loss: 0.6387 - val_acc: 0.6491\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6458 - acc: 0.6358 - val_loss: 0.6385 - val_acc: 0.6493\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6458 - acc: 0.6367 - val_loss: 0.6383 - val_acc: 0.6472\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6457 - acc: 0.6372 - val_loss: 0.6380 - val_acc: 0.6432\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6455 - acc: 0.6366 - val_loss: 0.6381 - val_acc: 0.6453\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6458 - acc: 0.6347 - val_loss: 0.6381 - val_acc: 0.6472\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6455 - acc: 0.6389 - val_loss: 0.6379 - val_acc: 0.6499\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6361 - val_loss: 0.6377 - val_acc: 0.6512\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6453 - acc: 0.6369 - val_loss: 0.6381 - val_acc: 0.6449\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6455 - acc: 0.6381 - val_loss: 0.6377 - val_acc: 0.6502\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 117us/step - loss: 0.7251 - acc: 0.5558 - val_loss: 0.6790 - val_acc: 0.5894\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6736 - acc: 0.5992 - val_loss: 0.6583 - val_acc: 0.6277\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6595 - acc: 0.6200 - val_loss: 0.6502 - val_acc: 0.6362\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6533 - acc: 0.6284 - val_loss: 0.6457 - val_acc: 0.6482\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6502 - acc: 0.6331 - val_loss: 0.6426 - val_acc: 0.6446\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6484 - acc: 0.6347 - val_loss: 0.6410 - val_acc: 0.6501\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6473 - acc: 0.6339 - val_loss: 0.6400 - val_acc: 0.6540\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6468 - acc: 0.6382 - val_loss: 0.6391 - val_acc: 0.6518\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6466 - acc: 0.6363 - val_loss: 0.6389 - val_acc: 0.6531\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6463 - acc: 0.6354 - val_loss: 0.6388 - val_acc: 0.6512\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6459 - acc: 0.6370 - val_loss: 0.6381 - val_acc: 0.6523\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6380 - val_loss: 0.6380 - val_acc: 0.6453\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6388 - val_loss: 0.6378 - val_acc: 0.6527\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6456 - acc: 0.6408 - val_loss: 0.6377 - val_acc: 0.6472\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6455 - acc: 0.6378 - val_loss: 0.6375 - val_acc: 0.6518\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6454 - acc: 0.6409 - val_loss: 0.6377 - val_acc: 0.6520\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6455 - acc: 0.6381 - val_loss: 0.6379 - val_acc: 0.6474\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6455 - acc: 0.6363 - val_loss: 0.6376 - val_acc: 0.6495\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6453 - acc: 0.6412 - val_loss: 0.6379 - val_acc: 0.6459\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6453 - acc: 0.6399 - val_loss: 0.6377 - val_acc: 0.6474\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 113us/step - loss: 0.7157 - acc: 0.5666 - val_loss: 0.6807 - val_acc: 0.5845\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6733 - acc: 0.5884 - val_loss: 0.6579 - val_acc: 0.6127\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6594 - acc: 0.6101 - val_loss: 0.6487 - val_acc: 0.6362\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6528 - acc: 0.6223 - val_loss: 0.6432 - val_acc: 0.6470\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6495 - acc: 0.6326 - val_loss: 0.6408 - val_acc: 0.6468\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6477 - acc: 0.6370 - val_loss: 0.6396 - val_acc: 0.6514\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6473 - acc: 0.6386 - val_loss: 0.6393 - val_acc: 0.6533\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6466 - acc: 0.6382 - val_loss: 0.6389 - val_acc: 0.6531\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6463 - acc: 0.6400 - val_loss: 0.6385 - val_acc: 0.6497\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6461 - acc: 0.6371 - val_loss: 0.6382 - val_acc: 0.6508\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6461 - acc: 0.6378 - val_loss: 0.6380 - val_acc: 0.6535\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6458 - acc: 0.6380 - val_loss: 0.6379 - val_acc: 0.6525\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6381 - val_loss: 0.6388 - val_acc: 0.6455\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6458 - acc: 0.6379 - val_loss: 0.6380 - val_acc: 0.6510\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6457 - acc: 0.6364 - val_loss: 0.6385 - val_acc: 0.6404\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6392 - val_loss: 0.6382 - val_acc: 0.6468\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 57us/step - loss: 0.6457 - acc: 0.6373 - val_loss: 0.6380 - val_acc: 0.6466\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6456 - acc: 0.6375 - val_loss: 0.6381 - val_acc: 0.6463\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6456 - acc: 0.6371 - val_loss: 0.6379 - val_acc: 0.6485\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6458 - acc: 0.6351 - val_loss: 0.6380 - val_acc: 0.6499\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 126us/step - loss: 0.7544 - acc: 0.5520 - val_loss: 0.7039 - val_acc: 0.5483\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6926 - acc: 0.5597 - val_loss: 0.6731 - val_acc: 0.5900\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6709 - acc: 0.5897 - val_loss: 0.6576 - val_acc: 0.6171\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6597 - acc: 0.6084 - val_loss: 0.6492 - val_acc: 0.6262\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6539 - acc: 0.6162 - val_loss: 0.6446 - val_acc: 0.6340\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6505 - acc: 0.6267 - val_loss: 0.6423 - val_acc: 0.6355\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6487 - acc: 0.6346 - val_loss: 0.6405 - val_acc: 0.6389\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6476 - acc: 0.6341 - val_loss: 0.6399 - val_acc: 0.6436\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6469 - acc: 0.6358 - val_loss: 0.6408 - val_acc: 0.6440\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6465 - acc: 0.6360 - val_loss: 0.6385 - val_acc: 0.6523\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6460 - acc: 0.6372 - val_loss: 0.6386 - val_acc: 0.6463\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6458 - acc: 0.6386 - val_loss: 0.6385 - val_acc: 0.6506\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 57us/step - loss: 0.6457 - acc: 0.6366 - val_loss: 0.6390 - val_acc: 0.6453\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6458 - acc: 0.6373 - val_loss: 0.6379 - val_acc: 0.6525\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6384 - val_loss: 0.6382 - val_acc: 0.6487\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6454 - acc: 0.6378 - val_loss: 0.6379 - val_acc: 0.6468\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6454 - acc: 0.6358 - val_loss: 0.6378 - val_acc: 0.6521\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6454 - acc: 0.6389 - val_loss: 0.6377 - val_acc: 0.6436\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6454 - acc: 0.6381 - val_loss: 0.6381 - val_acc: 0.6455\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6454 - acc: 0.6362 - val_loss: 0.6374 - val_acc: 0.6448\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 2s 111us/step - loss: 0.7341 - acc: 0.5492 - val_loss: 0.7003 - val_acc: 0.5521\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 37us/step - loss: 0.6859 - acc: 0.5749 - val_loss: 0.6714 - val_acc: 0.5959\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6663 - acc: 0.6019 - val_loss: 0.6569 - val_acc: 0.6161\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6566 - acc: 0.6129 - val_loss: 0.6492 - val_acc: 0.6294\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6518 - acc: 0.6234 - val_loss: 0.6448 - val_acc: 0.6353\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6493 - acc: 0.6303 - val_loss: 0.6427 - val_acc: 0.6389\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6478 - acc: 0.6294 - val_loss: 0.6411 - val_acc: 0.6448\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6470 - acc: 0.6333 - val_loss: 0.6403 - val_acc: 0.6427\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6467 - acc: 0.6343 - val_loss: 0.6398 - val_acc: 0.6451\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6463 - acc: 0.6367 - val_loss: 0.6398 - val_acc: 0.6413\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6460 - acc: 0.6348 - val_loss: 0.6392 - val_acc: 0.6457\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 0.6459 - acc: 0.6390 - val_loss: 0.6392 - val_acc: 0.6427\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6375 - val_loss: 0.6391 - val_acc: 0.6434\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6386 - val_loss: 0.6382 - val_acc: 0.6501\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6455 - acc: 0.6385 - val_loss: 0.6382 - val_acc: 0.6427\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6455 - acc: 0.6364 - val_loss: 0.6380 - val_acc: 0.6432\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6453 - acc: 0.6375 - val_loss: 0.6378 - val_acc: 0.6497\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6453 - acc: 0.6383 - val_loss: 0.6380 - val_acc: 0.6442\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6453 - acc: 0.6357 - val_loss: 0.6384 - val_acc: 0.6451\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6454 - acc: 0.6378 - val_loss: 0.6375 - val_acc: 0.6520\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 121us/step - loss: 0.7659 - acc: 0.5679 - val_loss: 0.6993 - val_acc: 0.5811\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6802 - acc: 0.6002 - val_loss: 0.6680 - val_acc: 0.6040\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6626 - acc: 0.6079 - val_loss: 0.6550 - val_acc: 0.6209\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6549 - acc: 0.6152 - val_loss: 0.6487 - val_acc: 0.6336\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6512 - acc: 0.6260 - val_loss: 0.6453 - val_acc: 0.6419\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6492 - acc: 0.6288 - val_loss: 0.6438 - val_acc: 0.6400\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6481 - acc: 0.6330 - val_loss: 0.6422 - val_acc: 0.6406\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6474 - acc: 0.6326 - val_loss: 0.6416 - val_acc: 0.6442\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6470 - acc: 0.6326 - val_loss: 0.6405 - val_acc: 0.6455\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6467 - acc: 0.6357 - val_loss: 0.6403 - val_acc: 0.6449\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6464 - acc: 0.6356 - val_loss: 0.6395 - val_acc: 0.6427\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6460 - acc: 0.6347 - val_loss: 0.6392 - val_acc: 0.6487\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6460 - acc: 0.6374 - val_loss: 0.6390 - val_acc: 0.6518\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6381 - val_loss: 0.6387 - val_acc: 0.6438\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6459 - acc: 0.6358 - val_loss: 0.6387 - val_acc: 0.6493\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6458 - acc: 0.6358 - val_loss: 0.6383 - val_acc: 0.6487\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6455 - acc: 0.6378 - val_loss: 0.6381 - val_acc: 0.6451\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6455 - acc: 0.6362 - val_loss: 0.6387 - val_acc: 0.6438\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6455 - acc: 0.6375 - val_loss: 0.6381 - val_acc: 0.6463\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6455 - acc: 0.6365 - val_loss: 0.6384 - val_acc: 0.6448\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 119us/step - loss: 0.7805 - acc: 0.5006 - val_loss: 0.7067 - val_acc: 0.5432\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6964 - acc: 0.5622 - val_loss: 0.6817 - val_acc: 0.5765\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6765 - acc: 0.5896 - val_loss: 0.6650 - val_acc: 0.6048\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6644 - acc: 0.6060 - val_loss: 0.6547 - val_acc: 0.6228\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6570 - acc: 0.6185 - val_loss: 0.6483 - val_acc: 0.6355\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6526 - acc: 0.6243 - val_loss: 0.6448 - val_acc: 0.6446\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6500 - acc: 0.6298 - val_loss: 0.6423 - val_acc: 0.6444\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6484 - acc: 0.6342 - val_loss: 0.6411 - val_acc: 0.6432\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6476 - acc: 0.6345 - val_loss: 0.6399 - val_acc: 0.6457\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6470 - acc: 0.6357 - val_loss: 0.6394 - val_acc: 0.6440\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6465 - acc: 0.6381 - val_loss: 0.6395 - val_acc: 0.6396\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6462 - acc: 0.6363 - val_loss: 0.6392 - val_acc: 0.6463\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6461 - acc: 0.6391 - val_loss: 0.6386 - val_acc: 0.6457\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6460 - acc: 0.6365 - val_loss: 0.6380 - val_acc: 0.6518\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6460 - acc: 0.6377 - val_loss: 0.6382 - val_acc: 0.6478\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 43us/step - loss: 0.6457 - acc: 0.6387 - val_loss: 0.6379 - val_acc: 0.6485\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6378 - val_loss: 0.6378 - val_acc: 0.6482\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6457 - acc: 0.6384 - val_loss: 0.6379 - val_acc: 0.6504\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6456 - acc: 0.6382 - val_loss: 0.6378 - val_acc: 0.6444\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6455 - acc: 0.6353 - val_loss: 0.6384 - val_acc: 0.6476\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 120us/step - loss: 0.7197 - acc: 0.5351 - val_loss: 0.6816 - val_acc: 0.5674\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 0.6759 - acc: 0.5769 - val_loss: 0.6575 - val_acc: 0.6053\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6603 - acc: 0.6045 - val_loss: 0.6481 - val_acc: 0.6334\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6535 - acc: 0.6196 - val_loss: 0.6429 - val_acc: 0.6408\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6503 - acc: 0.6304 - val_loss: 0.6408 - val_acc: 0.6417\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 0.6485 - acc: 0.6339 - val_loss: 0.6393 - val_acc: 0.6436\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6475 - acc: 0.6355 - val_loss: 0.6392 - val_acc: 0.6487\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6472 - acc: 0.6379 - val_loss: 0.6391 - val_acc: 0.6425\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6466 - acc: 0.6350 - val_loss: 0.6384 - val_acc: 0.6489\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6464 - acc: 0.6352 - val_loss: 0.6380 - val_acc: 0.6508\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6462 - acc: 0.6374 - val_loss: 0.6384 - val_acc: 0.6512\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6461 - acc: 0.6359 - val_loss: 0.6381 - val_acc: 0.6508\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6460 - acc: 0.6365 - val_loss: 0.6380 - val_acc: 0.6508\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6459 - acc: 0.6378 - val_loss: 0.6381 - val_acc: 0.6491\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6459 - acc: 0.6356 - val_loss: 0.6384 - val_acc: 0.6455\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6364 - val_loss: 0.6385 - val_acc: 0.6425\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6362 - val_loss: 0.6383 - val_acc: 0.6459\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 57us/step - loss: 0.6457 - acc: 0.6381 - val_loss: 0.6384 - val_acc: 0.6461\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6370 - val_loss: 0.6380 - val_acc: 0.6482\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6456 - acc: 0.6383 - val_loss: 0.6379 - val_acc: 0.6493\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 129us/step - loss: 0.7734 - acc: 0.5755 - val_loss: 0.6917 - val_acc: 0.6023\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6737 - acc: 0.5982 - val_loss: 0.6566 - val_acc: 0.6108\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6567 - acc: 0.6172 - val_loss: 0.6470 - val_acc: 0.6389\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6512 - acc: 0.6272 - val_loss: 0.6429 - val_acc: 0.6408\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6488 - acc: 0.6307 - val_loss: 0.6408 - val_acc: 0.6412\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6477 - acc: 0.6338 - val_loss: 0.6398 - val_acc: 0.6489\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6472 - acc: 0.6356 - val_loss: 0.6390 - val_acc: 0.6491\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6468 - acc: 0.6355 - val_loss: 0.6389 - val_acc: 0.6446\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6466 - acc: 0.6361 - val_loss: 0.6387 - val_acc: 0.6472\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6463 - acc: 0.6353 - val_loss: 0.6387 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6464 - acc: 0.6361 - val_loss: 0.6383 - val_acc: 0.6514\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6461 - acc: 0.6372 - val_loss: 0.6384 - val_acc: 0.6501\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6461 - acc: 0.6338 - val_loss: 0.6390 - val_acc: 0.6404\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6462 - acc: 0.6361 - val_loss: 0.6382 - val_acc: 0.6455\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6461 - acc: 0.6351 - val_loss: 0.6387 - val_acc: 0.6453\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6458 - acc: 0.6371 - val_loss: 0.6390 - val_acc: 0.6404\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6459 - acc: 0.6355 - val_loss: 0.6394 - val_acc: 0.6451\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 57us/step - loss: 0.6461 - acc: 0.6339 - val_loss: 0.6380 - val_acc: 0.6478\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6459 - acc: 0.6366 - val_loss: 0.6382 - val_acc: 0.6438\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6460 - acc: 0.6363 - val_loss: 0.6383 - val_acc: 0.6438\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 125us/step - loss: 0.7442 - acc: 0.5383 - val_loss: 0.6701 - val_acc: 0.5947\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6662 - acc: 0.6033 - val_loss: 0.6523 - val_acc: 0.6218\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6553 - acc: 0.6157 - val_loss: 0.6453 - val_acc: 0.6262\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6508 - acc: 0.6198 - val_loss: 0.6419 - val_acc: 0.6334\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6491 - acc: 0.6266 - val_loss: 0.6403 - val_acc: 0.6326\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6479 - acc: 0.6290 - val_loss: 0.6397 - val_acc: 0.6429\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6475 - acc: 0.6338 - val_loss: 0.6387 - val_acc: 0.6432\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6469 - acc: 0.6351 - val_loss: 0.6387 - val_acc: 0.6427\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6467 - acc: 0.6353 - val_loss: 0.6389 - val_acc: 0.6394\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6465 - acc: 0.6385 - val_loss: 0.6388 - val_acc: 0.6521\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6463 - acc: 0.6378 - val_loss: 0.6379 - val_acc: 0.6540\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.6464 - acc: 0.6386 - val_loss: 0.6379 - val_acc: 0.6472\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6460 - acc: 0.6347 - val_loss: 0.6381 - val_acc: 0.6442\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6459 - acc: 0.6351 - val_loss: 0.6379 - val_acc: 0.6495\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6460 - acc: 0.6369 - val_loss: 0.6377 - val_acc: 0.6485\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6459 - acc: 0.6365 - val_loss: 0.6377 - val_acc: 0.6493\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6459 - acc: 0.6378 - val_loss: 0.6376 - val_acc: 0.6535\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6458 - acc: 0.6359 - val_loss: 0.6382 - val_acc: 0.6421\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6458 - acc: 0.6352 - val_loss: 0.6376 - val_acc: 0.6504\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6457 - acc: 0.6391 - val_loss: 0.6377 - val_acc: 0.6457\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 122us/step - loss: 0.7255 - acc: 0.5531 - val_loss: 0.6945 - val_acc: 0.5654\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6800 - acc: 0.5794 - val_loss: 0.6685 - val_acc: 0.5974\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6636 - acc: 0.6031 - val_loss: 0.6565 - val_acc: 0.6237\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6559 - acc: 0.6149 - val_loss: 0.6501 - val_acc: 0.6311\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6519 - acc: 0.6216 - val_loss: 0.6460 - val_acc: 0.6292\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6496 - acc: 0.6269 - val_loss: 0.6437 - val_acc: 0.6376\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6483 - acc: 0.6311 - val_loss: 0.6428 - val_acc: 0.6391\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6476 - acc: 0.6326 - val_loss: 0.6413 - val_acc: 0.6412\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6470 - acc: 0.6338 - val_loss: 0.6405 - val_acc: 0.6449\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6470 - acc: 0.6342 - val_loss: 0.6399 - val_acc: 0.6427\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6465 - acc: 0.6342 - val_loss: 0.6396 - val_acc: 0.6449\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6466 - acc: 0.6345 - val_loss: 0.6397 - val_acc: 0.6453\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6465 - acc: 0.6355 - val_loss: 0.6391 - val_acc: 0.6516\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6464 - acc: 0.6359 - val_loss: 0.6389 - val_acc: 0.6474\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6463 - acc: 0.6344 - val_loss: 0.6388 - val_acc: 0.6444\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6461 - acc: 0.6370 - val_loss: 0.6389 - val_acc: 0.6442\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6461 - acc: 0.6350 - val_loss: 0.6385 - val_acc: 0.6484\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6461 - acc: 0.6361 - val_loss: 0.6385 - val_acc: 0.6455\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6460 - acc: 0.6347 - val_loss: 0.6383 - val_acc: 0.6487\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6460 - acc: 0.6370 - val_loss: 0.6382 - val_acc: 0.6512\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 127us/step - loss: 0.8381 - acc: 0.4906 - val_loss: 0.6877 - val_acc: 0.5796\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6835 - acc: 0.5753 - val_loss: 0.6658 - val_acc: 0.6050\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6672 - acc: 0.5906 - val_loss: 0.6540 - val_acc: 0.6171\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6582 - acc: 0.6069 - val_loss: 0.6474 - val_acc: 0.6302\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6535 - acc: 0.6233 - val_loss: 0.6443 - val_acc: 0.6448\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6508 - acc: 0.6284 - val_loss: 0.6420 - val_acc: 0.6520\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6493 - acc: 0.6342 - val_loss: 0.6406 - val_acc: 0.6546\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6373 - val_loss: 0.6396 - val_acc: 0.6520\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6475 - acc: 0.6353 - val_loss: 0.6392 - val_acc: 0.6480\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6471 - acc: 0.6397 - val_loss: 0.6393 - val_acc: 0.6455\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6468 - acc: 0.6369 - val_loss: 0.6387 - val_acc: 0.6491\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6464 - acc: 0.6388 - val_loss: 0.6389 - val_acc: 0.6466\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6463 - acc: 0.6376 - val_loss: 0.6382 - val_acc: 0.6544\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6462 - acc: 0.6376 - val_loss: 0.6380 - val_acc: 0.6501\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6461 - acc: 0.6399 - val_loss: 0.6385 - val_acc: 0.6451\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6460 - acc: 0.6356 - val_loss: 0.6381 - val_acc: 0.6434\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6458 - acc: 0.6378 - val_loss: 0.6382 - val_acc: 0.6502\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6457 - acc: 0.6384 - val_loss: 0.6379 - val_acc: 0.6472\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6458 - acc: 0.6383 - val_loss: 0.6393 - val_acc: 0.6470\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 32us/step - loss: 0.6457 - acc: 0.6381 - val_loss: 0.6378 - val_acc: 0.6485\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 128us/step - loss: 0.7300 - acc: 0.5470 - val_loss: 0.6875 - val_acc: 0.5796\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6792 - acc: 0.5998 - val_loss: 0.6625 - val_acc: 0.6146\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 0.6628 - acc: 0.6149 - val_loss: 0.6504 - val_acc: 0.6273\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 31us/step - loss: 0.6547 - acc: 0.6251 - val_loss: 0.6449 - val_acc: 0.6412\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6509 - acc: 0.6270 - val_loss: 0.6418 - val_acc: 0.6468\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6486 - acc: 0.6331 - val_loss: 0.6400 - val_acc: 0.6480\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6474 - acc: 0.6344 - val_loss: 0.6390 - val_acc: 0.6493\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6467 - acc: 0.6378 - val_loss: 0.6385 - val_acc: 0.6495\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6463 - acc: 0.6386 - val_loss: 0.6383 - val_acc: 0.6436\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6461 - acc: 0.6354 - val_loss: 0.6384 - val_acc: 0.6525\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6459 - acc: 0.6387 - val_loss: 0.6380 - val_acc: 0.6474\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6351 - val_loss: 0.6379 - val_acc: 0.6550\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6379 - val_loss: 0.6378 - val_acc: 0.6502\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6456 - acc: 0.6370 - val_loss: 0.6377 - val_acc: 0.6478\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6391 - val_loss: 0.6375 - val_acc: 0.6518\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6396 - val_loss: 0.6382 - val_acc: 0.6478\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6456 - acc: 0.6374 - val_loss: 0.6377 - val_acc: 0.6423\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6454 - acc: 0.6357 - val_loss: 0.6375 - val_acc: 0.6501\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6454 - acc: 0.6374 - val_loss: 0.6380 - val_acc: 0.6457\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6370 - val_loss: 0.6375 - val_acc: 0.6506\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 128us/step - loss: 0.7418 - acc: 0.5370 - val_loss: 0.6725 - val_acc: 0.5947\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6695 - acc: 0.5930 - val_loss: 0.6569 - val_acc: 0.6216\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6594 - acc: 0.6136 - val_loss: 0.6494 - val_acc: 0.6340\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6547 - acc: 0.6195 - val_loss: 0.6456 - val_acc: 0.6387\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6519 - acc: 0.6253 - val_loss: 0.6434 - val_acc: 0.6408\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6503 - acc: 0.6279 - val_loss: 0.6422 - val_acc: 0.6434\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 0.6490 - acc: 0.6322 - val_loss: 0.6423 - val_acc: 0.6370\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6486 - acc: 0.6320 - val_loss: 0.6418 - val_acc: 0.6413\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6480 - acc: 0.6343 - val_loss: 0.6401 - val_acc: 0.6466\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6474 - acc: 0.6378 - val_loss: 0.6401 - val_acc: 0.6493\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6472 - acc: 0.6360 - val_loss: 0.6396 - val_acc: 0.6461\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6471 - acc: 0.6362 - val_loss: 0.6397 - val_acc: 0.6417\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6468 - acc: 0.6354 - val_loss: 0.6392 - val_acc: 0.6438\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6467 - acc: 0.6368 - val_loss: 0.6393 - val_acc: 0.6421\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6466 - acc: 0.6357 - val_loss: 0.6392 - val_acc: 0.6423\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6465 - acc: 0.6362 - val_loss: 0.6388 - val_acc: 0.6482\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6466 - acc: 0.6358 - val_loss: 0.6389 - val_acc: 0.6506\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6466 - acc: 0.6365 - val_loss: 0.6385 - val_acc: 0.6516\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6463 - acc: 0.6376 - val_loss: 0.6402 - val_acc: 0.6438\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6464 - acc: 0.6356 - val_loss: 0.6386 - val_acc: 0.6493\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 122us/step - loss: 0.7269 - acc: 0.5443 - val_loss: 0.6922 - val_acc: 0.5667\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 42us/step - loss: 0.6773 - acc: 0.5833 - val_loss: 0.6651 - val_acc: 0.6042\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6611 - acc: 0.6094 - val_loss: 0.6526 - val_acc: 0.6199\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6537 - acc: 0.6232 - val_loss: 0.6466 - val_acc: 0.6322\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 42us/step - loss: 0.6498 - acc: 0.6292 - val_loss: 0.6430 - val_acc: 0.6347\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6479 - acc: 0.6314 - val_loss: 0.6410 - val_acc: 0.6457\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6468 - acc: 0.6353 - val_loss: 0.6397 - val_acc: 0.6501\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6462 - acc: 0.6381 - val_loss: 0.6395 - val_acc: 0.6455\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6459 - acc: 0.6348 - val_loss: 0.6387 - val_acc: 0.6476\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6457 - acc: 0.6373 - val_loss: 0.6383 - val_acc: 0.6449\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6369 - val_loss: 0.6385 - val_acc: 0.6385\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6452 - acc: 0.6355 - val_loss: 0.6383 - val_acc: 0.6489\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 0.6454 - acc: 0.6387 - val_loss: 0.6378 - val_acc: 0.6485\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6453 - acc: 0.6365 - val_loss: 0.6376 - val_acc: 0.6516\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6453 - acc: 0.6400 - val_loss: 0.6375 - val_acc: 0.6518\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6452 - acc: 0.6381 - val_loss: 0.6381 - val_acc: 0.6474\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6452 - acc: 0.6365 - val_loss: 0.6378 - val_acc: 0.6516\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6453 - acc: 0.6386 - val_loss: 0.6376 - val_acc: 0.6482\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6452 - acc: 0.6383 - val_loss: 0.6379 - val_acc: 0.6518\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6452 - acc: 0.6384 - val_loss: 0.6374 - val_acc: 0.6512\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 119us/step - loss: 0.7712 - acc: 0.5331 - val_loss: 0.6798 - val_acc: 0.5908\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 40us/step - loss: 0.6742 - acc: 0.5979 - val_loss: 0.6563 - val_acc: 0.6239\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6595 - acc: 0.6157 - val_loss: 0.6477 - val_acc: 0.6366\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6529 - acc: 0.6261 - val_loss: 0.6424 - val_acc: 0.6377\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6497 - acc: 0.6315 - val_loss: 0.6402 - val_acc: 0.6434\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6482 - acc: 0.6327 - val_loss: 0.6392 - val_acc: 0.6468\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6472 - acc: 0.6350 - val_loss: 0.6395 - val_acc: 0.6442\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6467 - acc: 0.6354 - val_loss: 0.6381 - val_acc: 0.6472\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6463 - acc: 0.6362 - val_loss: 0.6380 - val_acc: 0.6461\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6462 - acc: 0.6360 - val_loss: 0.6387 - val_acc: 0.6453\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6460 - acc: 0.6363 - val_loss: 0.6383 - val_acc: 0.6451\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6459 - acc: 0.6374 - val_loss: 0.6381 - val_acc: 0.6436\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6458 - acc: 0.6361 - val_loss: 0.6382 - val_acc: 0.6419\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6459 - acc: 0.6361 - val_loss: 0.6377 - val_acc: 0.6482\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6458 - acc: 0.6374 - val_loss: 0.6380 - val_acc: 0.6446\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6457 - acc: 0.6352 - val_loss: 0.6378 - val_acc: 0.6466\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.6457 - acc: 0.6350 - val_loss: 0.6379 - val_acc: 0.6455\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6456 - acc: 0.6364 - val_loss: 0.6390 - val_acc: 0.6436\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6455 - acc: 0.6333 - val_loss: 0.6388 - val_acc: 0.6476\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6456 - acc: 0.6375 - val_loss: 0.6380 - val_acc: 0.6434\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 123us/step - loss: 0.7094 - acc: 0.5297 - val_loss: 0.6733 - val_acc: 0.5841\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 41us/step - loss: 0.6680 - acc: 0.5933 - val_loss: 0.6547 - val_acc: 0.6097\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6569 - acc: 0.6095 - val_loss: 0.6465 - val_acc: 0.6207\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6516 - acc: 0.6221 - val_loss: 0.6422 - val_acc: 0.6394\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6489 - acc: 0.6323 - val_loss: 0.6395 - val_acc: 0.6412\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.6472 - acc: 0.6346 - val_loss: 0.6395 - val_acc: 0.6448\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6465 - acc: 0.6365 - val_loss: 0.6383 - val_acc: 0.6495\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6460 - acc: 0.6384 - val_loss: 0.6377 - val_acc: 0.6482\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6458 - acc: 0.6384 - val_loss: 0.6373 - val_acc: 0.6512\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6457 - acc: 0.6387 - val_loss: 0.6382 - val_acc: 0.6465\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6455 - acc: 0.6360 - val_loss: 0.6371 - val_acc: 0.6504\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6456 - acc: 0.6392 - val_loss: 0.6377 - val_acc: 0.6474\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6454 - acc: 0.6377 - val_loss: 0.6374 - val_acc: 0.6472\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6454 - acc: 0.6368 - val_loss: 0.6374 - val_acc: 0.6476\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6452 - acc: 0.6378 - val_loss: 0.6381 - val_acc: 0.6453\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6452 - acc: 0.6368 - val_loss: 0.6378 - val_acc: 0.6466\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 43us/step - loss: 0.6452 - acc: 0.6382 - val_loss: 0.6372 - val_acc: 0.6510\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6452 - acc: 0.6366 - val_loss: 0.6375 - val_acc: 0.6459\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6453 - acc: 0.6376 - val_loss: 0.6376 - val_acc: 0.6455\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6453 - acc: 0.6401 - val_loss: 0.6375 - val_acc: 0.6451\n"
     ]
    }
   ],
   "source": [
    "LSTM_history=Do_experiments(x_LSTM,y,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 130us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 37us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 34us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 30us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 129us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 124us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 121us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 127us/step - loss: 1.1993 - acc: 0.8815 - val_loss: 0.8815 - val_acc: 0.9013\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.8128 - acc: 0.9100 - val_loss: 0.8879 - val_acc: 0.9075\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.8116 - acc: 0.9106 - val_loss: 0.8747 - val_acc: 0.9068\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.8082 - acc: 0.9103 - val_loss: 0.8974 - val_acc: 0.9083\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.8049 - acc: 0.9098 - val_loss: 0.8595 - val_acc: 0.9026\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.7958 - acc: 0.9115 - val_loss: 0.8554 - val_acc: 0.9072\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.7872 - acc: 0.9103 - val_loss: 0.8815 - val_acc: 0.9087\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 0.7873 - acc: 0.9093 - val_loss: 0.8364 - val_acc: 0.8992\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.7808 - acc: 0.9106 - val_loss: 0.8283 - val_acc: 0.8960\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.7737 - acc: 0.9106 - val_loss: 0.8378 - val_acc: 0.9089\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.7584 - acc: 0.9114 - val_loss: 0.8121 - val_acc: 0.9075\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.7511 - acc: 0.9114 - val_loss: 0.8024 - val_acc: 0.9077\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.7455 - acc: 0.9110 - val_loss: 0.7890 - val_acc: 0.9017\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.7354 - acc: 0.9108 - val_loss: 0.7857 - val_acc: 0.9087\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.7255 - acc: 0.9107 - val_loss: 0.7688 - val_acc: 0.9049\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.7155 - acc: 0.9098 - val_loss: 0.7583 - val_acc: 0.9000\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.7068 - acc: 0.9110 - val_loss: 0.7758 - val_acc: 0.8884\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.7037 - acc: 0.9105 - val_loss: 0.7371 - val_acc: 0.9077\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.6860 - acc: 0.9120 - val_loss: 0.7347 - val_acc: 0.9096\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.6791 - acc: 0.9117 - val_loss: 0.7156 - val_acc: 0.9017\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 128us/step - loss: 1.8020 - acc: 0.6649 - val_loss: 1.4603 - val_acc: 0.7003\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 1.3937 - acc: 0.7033 - val_loss: 1.2598 - val_acc: 0.7294\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 1.1831 - acc: 0.7396 - val_loss: 1.0742 - val_acc: 0.7664\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 1.0274 - acc: 0.7746 - val_loss: 1.0038 - val_acc: 0.7956\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 0.9133 - acc: 0.8067 - val_loss: 0.8599 - val_acc: 0.8251\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.8365 - acc: 0.8290 - val_loss: 0.8037 - val_acc: 0.8446\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.7793 - acc: 0.8460 - val_loss: 0.7616 - val_acc: 0.8581\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.7373 - acc: 0.8601 - val_loss: 0.7210 - val_acc: 0.8653\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 0.7061 - acc: 0.8691 - val_loss: 0.7081 - val_acc: 0.8816\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6864 - acc: 0.8767 - val_loss: 0.6753 - val_acc: 0.8827\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.6658 - acc: 0.8823 - val_loss: 0.6586 - val_acc: 0.8863\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6462 - acc: 0.8880 - val_loss: 0.6466 - val_acc: 0.8875\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6317 - acc: 0.8926 - val_loss: 0.6349 - val_acc: 0.8911\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6239 - acc: 0.8936 - val_loss: 0.6432 - val_acc: 0.8751\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.6118 - acc: 0.8968 - val_loss: 0.6238 - val_acc: 0.8863\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.6022 - acc: 0.8993 - val_loss: 0.6078 - val_acc: 0.8992\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.5933 - acc: 0.9015 - val_loss: 0.6008 - val_acc: 0.8984\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.5911 - acc: 0.9014 - val_loss: 0.6231 - val_acc: 0.8765\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.5782 - acc: 0.9044 - val_loss: 0.5954 - val_acc: 0.9070\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.5754 - acc: 0.9052 - val_loss: 0.5865 - val_acc: 0.8967\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 124us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 43us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 129us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 42us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 57us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 133us/step - loss: 6.3591 - acc: 0.4442 - val_loss: 3.7586 - val_acc: 0.5582\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 3.7031 - acc: 0.5412 - val_loss: 3.5285 - val_acc: 0.4860\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 3.3729 - acc: 0.5576 - val_loss: 3.0897 - val_acc: 0.5966\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 2.9058 - acc: 0.5613 - val_loss: 2.5312 - val_acc: 0.5697\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 2.2793 - acc: 0.5896 - val_loss: 1.9347 - val_acc: 0.6523\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 1.7244 - acc: 0.6460 - val_loss: 1.4886 - val_acc: 0.6294\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 1.3270 - acc: 0.7077 - val_loss: 1.1693 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 1.0662 - acc: 0.7607 - val_loss: 0.9599 - val_acc: 0.7829\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.8871 - acc: 0.7867 - val_loss: 0.8152 - val_acc: 0.7956\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 57us/step - loss: 0.7571 - acc: 0.7990 - val_loss: 0.6975 - val_acc: 0.8122\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.6409 - acc: 0.8161 - val_loss: 0.6027 - val_acc: 0.8264\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.5615 - acc: 0.8327 - val_loss: 0.5335 - val_acc: 0.8374\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.5012 - acc: 0.8524 - val_loss: 0.4912 - val_acc: 0.8479\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.4623 - acc: 0.8739 - val_loss: 0.4585 - val_acc: 0.8704\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.4361 - acc: 0.8886 - val_loss: 0.4384 - val_acc: 0.8829\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.4205 - acc: 0.8973 - val_loss: 0.4470 - val_acc: 0.8897\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.4083 - acc: 0.9021 - val_loss: 0.4145 - val_acc: 0.8981\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.3982 - acc: 0.9064 - val_loss: 0.4265 - val_acc: 0.8947\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.3943 - acc: 0.9088 - val_loss: 0.3969 - val_acc: 0.9047\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.3836 - acc: 0.9107 - val_loss: 0.4260 - val_acc: 0.8992\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 128us/step - loss: 6.6466 - acc: 0.5827 - val_loss: 6.6056 - val_acc: 0.5836\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 41us/step - loss: 6.6423 - acc: 0.5809 - val_loss: 6.6097 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6506 - acc: 0.5787 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6478 - acc: 0.5830 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6463 - acc: 0.5717 - val_loss: 6.6031 - val_acc: 0.5830\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6362 - acc: 0.5787 - val_loss: 6.6062 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6371 - acc: 0.5791 - val_loss: 6.6010 - val_acc: 0.5845\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6243 - acc: 0.5679 - val_loss: 6.4567 - val_acc: 0.4521\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.0118 - acc: 0.4418 - val_loss: 5.3917 - val_acc: 0.4498\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 5.0516 - acc: 0.4712 - val_loss: 4.7091 - val_acc: 0.5233\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 4.5062 - acc: 0.5196 - val_loss: 4.3084 - val_acc: 0.4864\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 4.1338 - acc: 0.5435 - val_loss: 3.9380 - val_acc: 0.5515\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 3.7994 - acc: 0.5563 - val_loss: 3.6230 - val_acc: 0.5136\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 3.3364 - acc: 0.5487 - val_loss: 3.0132 - val_acc: 0.5292\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 2.6975 - acc: 0.5750 - val_loss: 2.3996 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 2.0986 - acc: 0.6014 - val_loss: 1.8652 - val_acc: 0.6631\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 1.5988 - acc: 0.6351 - val_loss: 1.3862 - val_acc: 0.6667\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 1.2100 - acc: 0.6710 - val_loss: 1.0501 - val_acc: 0.6969\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 0.9343 - acc: 0.7164 - val_loss: 0.8532 - val_acc: 0.7442\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.7508 - acc: 0.7551 - val_loss: 0.6979 - val_acc: 0.7730\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 133us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 135us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 45us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 139us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 42us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 44us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 136us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 34us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 57us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 41us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 133us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 138us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 57us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3960 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 149us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 39us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 135us/step - loss: 9.3953 - acc: 0.4170 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 43us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 49us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 56us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 46us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 9.3952 - acc: 0.4171 - val_loss: 9.4333 - val_acc: 0.4147\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 147us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 47us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 48us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 6.6488 - acc: 0.5829 - val_loss: 6.6120 - val_acc: 0.5853\n",
      "Train on 21110 samples, validate on 5278 samples\n",
      "Epoch 1/20\n",
      "21110/21110 [==============================] - 3s 137us/step - loss: 6.6450 - acc: 0.5830 - val_loss: 6.6089 - val_acc: 0.5854\n",
      "Epoch 2/20\n",
      "21110/21110 [==============================] - 1s 38us/step - loss: 3.6299 - acc: 0.4960 - val_loss: 2.2315 - val_acc: 0.5248\n",
      "Epoch 3/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 1.8841 - acc: 0.5934 - val_loss: 1.5404 - val_acc: 0.6660\n",
      "Epoch 4/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 1.3803 - acc: 0.6715 - val_loss: 1.2040 - val_acc: 0.6745\n",
      "Epoch 5/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 1.0895 - acc: 0.7173 - val_loss: 0.9589 - val_acc: 0.7355\n",
      "Epoch 6/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.9001 - acc: 0.7489 - val_loss: 0.8039 - val_acc: 0.7717\n",
      "Epoch 7/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.7582 - acc: 0.7758 - val_loss: 0.6951 - val_acc: 0.8117\n",
      "Epoch 8/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.6572 - acc: 0.8055 - val_loss: 0.6094 - val_acc: 0.8314\n",
      "Epoch 9/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.5874 - acc: 0.8299 - val_loss: 0.5591 - val_acc: 0.8261\n",
      "Epoch 10/20\n",
      "21110/21110 [==============================] - 1s 51us/step - loss: 0.5350 - acc: 0.8529 - val_loss: 0.5392 - val_acc: 0.8329\n",
      "Epoch 11/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.5034 - acc: 0.8704 - val_loss: 0.4908 - val_acc: 0.8670\n",
      "Epoch 12/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.4797 - acc: 0.8803 - val_loss: 0.4679 - val_acc: 0.8772\n",
      "Epoch 13/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.4643 - acc: 0.8861 - val_loss: 0.4783 - val_acc: 0.8782\n",
      "Epoch 14/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.4490 - acc: 0.8936 - val_loss: 0.4536 - val_acc: 0.8875\n",
      "Epoch 15/20\n",
      "21110/21110 [==============================] - 1s 54us/step - loss: 0.4434 - acc: 0.8968 - val_loss: 0.4473 - val_acc: 0.8892\n",
      "Epoch 16/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.4315 - acc: 0.9005 - val_loss: 0.4366 - val_acc: 0.8962\n",
      "Epoch 17/20\n",
      "21110/21110 [==============================] - 1s 50us/step - loss: 0.4271 - acc: 0.9021 - val_loss: 0.4399 - val_acc: 0.9019\n",
      "Epoch 18/20\n",
      "21110/21110 [==============================] - 1s 52us/step - loss: 0.4197 - acc: 0.9058 - val_loss: 0.4452 - val_acc: 0.8952\n",
      "Epoch 19/20\n",
      "21110/21110 [==============================] - 1s 55us/step - loss: 0.4195 - acc: 0.9073 - val_loss: 0.4200 - val_acc: 0.9011\n",
      "Epoch 20/20\n",
      "21110/21110 [==============================] - 1s 53us/step - loss: 0.4100 - acc: 0.9102 - val_loss: 0.4124 - val_acc: 0.9056\n"
     ]
    }
   ],
   "source": [
    "final_history=Do_experiments(x_FINAL,y,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('decoder_history.npz',input_history=input_history,FC1_history=FC1_history,FC2_history=FC2_history,LSTM_history=LSTM_history,final_history=final_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('decoder_history.npz')\n",
    "input_history=data['input_history']\n",
    "FC1_history=data['FC1_history']\n",
    "FC2_history=data['FC2_history']\n",
    "LSTM_history=data['LSTM_history']\n",
    "final_history=data['final_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(val,index):\n",
    "    mean = np.mean(val[:,index,:],axis=0)\n",
    "    std = np.std(val[:,index,:],axis=0)\n",
    "    return mean,std/np.sqrt(20)\n",
    "\n",
    "def draw(tag='val_acc'):\n",
    "    plt.figure(figsize=(13,7))\n",
    "    ls = [input_history,FC1_history,FC2_history,LSTM_history,final_history]\n",
    "    colors = ['blue','red','black','g','m']\n",
    "    labels = ['input','FC1','FC2','LSTM','output']\n",
    "    tag_manual={'val_loss':0,'val_acc':1,'loss':2,'acc':3}\n",
    "    ax= plt.subplot(1,1,1)\n",
    "    ax.set_title(tag)\n",
    "    for i in range(5):\n",
    "        element=ls[i]\n",
    "        avlm,avls = calculate(element,tag_manual[tag])\n",
    "        ax.plot(np.arange(20),avlm,color=colors[i],label=labels[i])\n",
    "        ax.fill_between(np.arange(20),avlm+avls,avlm-avls,alpha=0.2)\n",
    "        ax.set_xticks(np.arange(20),minor=True)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(tag='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
